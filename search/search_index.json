{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TensorFlow Data Validation: Checking and analyzing your data","text":"<p>Once your data is in a TFX pipeline, you can use TFX components to analyze and transform it. You can use these tools even before you train a model.</p> <p>There are many reasons to analyze and transform your data:</p> <ul> <li>To find problems in your data. Common problems include:<ul> <li>Missing data, such as features with empty values.</li> <li>Labels treated as features, so that your model gets to peek at     the right answer during training.</li> <li>Features with values outside the range you expect.</li> <li>Data anomalies.</li> <li>Transfer learned model has preprocessing that does not match the     training data.</li> </ul> </li> <li>To engineer more effective feature sets. For example, you can     identify:<ul> <li>Especially informative features.</li> <li>Redundant features.</li> <li>Features that vary so widely in scale that they may slow     learning.</li> <li>Features with little or no unique predictive information.</li> </ul> </li> </ul> <p>TFX tools can both help find data bugs, and help with feature engineering.</p>"},{"location":"#tensorflow-data-validation","title":"TensorFlow Data Validation","text":"<ul> <li>Overview</li> <li>Schema Based Example Validation</li> <li>Training-Serving Skew Detection</li> <li>Drift Detection</li> </ul>"},{"location":"#overview","title":"Overview","text":"<p>TensorFlow Data Validation identifies anomalies in training and serving data, and can automatically create a schema by examining the data. The component can be configured to detect different classes of anomalies in the data. It can</p> <ol> <li>Perform validity checks by comparing data statistics against a     schema that codifies expectations of the user.</li> <li>Detect training-serving skew by comparing examples in training and     serving data.</li> <li>Detect data drift by looking at a series of data.</li> </ol> <p>We document each of these functionalities independently:</p> <ul> <li>Schema Based Example Validation</li> <li>Training-Serving Skew Detection</li> <li>Drift Detection</li> </ul>"},{"location":"#schema-based-example-validation","title":"Schema Based Example Validation","text":"<p>TensorFlow Data Validation identifies any anomalies in the input data by comparing data statistics against a schema. The schema codifies properties which the input data is expected to satisfy, such as data types or categorical values, and can be modified or replaced by the user.</p> <p>Tensorflow Data Validation is typically invoked multiple times within the context of the TFX pipeline: (i) for every split obtained from ExampleGen, (ii) for all pre-transformed data used by Transform and (iii) for all post-transform data generated by Transform. When invoked in the context of Transform (ii-iii), statistics options and schema-based constraints can be set by defining the <code>stats_options_updater_fn</code>. This is particilarly useful when validating unstructured data (e.g. text features). See the user code for an example.</p>"},{"location":"#advanced-schema-features","title":"Advanced Schema Features","text":"<p>This section covers more advanced schema configuration that can help with special setups.</p>"},{"location":"#sparse-features","title":"Sparse Features","text":"<p>Encoding sparse features in Examples usually introduces multiple Features that are expected to have the same valency for all Examples. For example the sparse feature:</p> <pre><code>WeightedCategories = [('CategoryA', 0.3), ('CategoryX', 0.7)]\n</code></pre> <p>would be encoded using separate Features for index and value:</p> <pre><code>WeightedCategoriesIndex = ['CategoryA', 'CategoryX']\nWeightedCategoriesValue = [0.3, 0.7]\n</code></pre> <p>with the restriction that the valency of the index and value feature should match for all Examples. This restriction can be made explicit in the schema by defining a sparse_feature:</p> <pre><code>sparse_feature {\n  name: 'WeightedCategories'\n  index_feature { name: 'WeightedCategoriesIndex' }\n  value_feature { name: 'WeightedCategoriesValue' }\n}\n</code></pre> <p>The sparse feature definition requires one or more index and one value feature which refer to features that exist in the schema. Explicitly defining sparse features enables TFDV to check that the valencies of all referred features match.</p> <p>Some use cases introduce similar valency restrictions between Features, but do not necessarily encode a sparse feature. Using sparse feature should unblock you, but is not ideal.</p>"},{"location":"#schema-environments","title":"Schema Environments","text":"<p>By default validations assume that all Examples in a pipeline adhere to a single schema. In some cases introducing slight schema variations is necessary, for instance features used as labels are required during training (and should be validated), but are missing during serving. Environments can be used to express such requirements, in particular <code>default_environment()</code>, <code>in_environment()</code>, and <code>not_in_environment()</code>.</p> <p>For example, assume a feature named <code>'LABEL'</code> is required for training, but is expected to be missing from serving. This can be expressed by:</p> <ul> <li>Define two distinct environments in the schema: <code>[\"SERVING\",     \"TRAINING\"]</code> and associate <code>'LABEL'</code> only with environment     <code>\"TRAINING\"</code>.</li> <li>Associate the training data with environment <code>\"TRAINING\"</code> and the     serving data with environment <code>\"SERVING\"</code>.</li> </ul>"},{"location":"#schema-generation","title":"Schema Generation","text":"<p>The input data schema is specified as an instance of the TensorFlow Schema.</p> <p>Instead of constructing a schema manually from scratch, a developer can rely on TensorFlow Data Validation's automatic schema construction. Specifically, TensorFlow Data Validation automatically constructs an initial schema based on statistics computed over training data available in the pipeline. Users can simply review this autogenerated schema, modify it as needed, check it into a version control system, and push it explicitly into the pipeline for further validation.</p> <p>TFDV includes <code>infer_schema()</code> to generate a schema automatically. For example:</p> <pre><code>schema = tfdv.infer_schema(statistics=train_stats)\ntfdv.display_schema(schema=schema)\n</code></pre> <p>This triggers an automatic schema generation based on the following rules:</p> <ul> <li> <p>If a schema has already been auto-generated then it is used as is.</p> </li> <li> <p>Otherwise, TensorFlow Data Validation examines the available data     statistics and computes a suitable schema for the data.</p> </li> </ul> <p>Note: The auto-generated schema is best-effort and only tries to infer basic properties of the data. It is expected that users review and modify it as needed.</p>"},{"location":"#training-serving-skew-detection","title":"Training-Serving Skew Detection","text":""},{"location":"#overview_1","title":"Overview","text":"<p>TensorFlow Data Validation can detect distribution skew between training and serving data. Distribution skew occurs when the distribution of feature values for training data is significantly different from serving data. One of the key causes for distribution skew is using either a completely different corpus for training data generation to overcome lack of initial data in the desired corpus. Another reason is a faulty sampling mechanism that only chooses a subsample of the serving data to train on.</p>"},{"location":"#example-scenario","title":"Example Scenario","text":"<p>Note: For instance, in order to compensate for an underrepresented slice of data, if a biased sampling is used without upweighting the downsampled examples appropriately, the distribution of feature values between training and serving data gets artificially skewed.</p> <p>See the TensorFlow Data Validation Get Started Guide for information about configuring training-serving skew detection.</p>"},{"location":"#drift-detection","title":"Drift Detection","text":"<p>Drift detection is supported between consecutive spans of data (i.e., between span N and span N+1), such as between different days of training data. We express drift in terms of L-infinity distance for categorical features and approximate Jensen-Shannon divergence for numeric features. You can set the threshold distance so that you receive warnings when the drift is higher than is acceptable. Setting the correct distance is typically an iterative process requiring domain knowledge and experimentation.</p> <p>See the TensorFlow Data Validation Get Started Guide for information about configuring drift detection.</p>"},{"location":"#using-visualizations-to-check-your-data","title":"Using Visualizations to Check Your Data","text":"<p>TensorFlow Data Validation provides tools for visualizing the distribution of feature values. By examining these distributions in a Jupyter notebook using Facets you can catch common problems with data.</p> <p></p>"},{"location":"#identifying-suspicious-distributions","title":"Identifying Suspicious Distributions","text":"<p>You can identify common bugs in your data by using a Facets Overview display to look for suspicious distributions of feature values.</p>"},{"location":"#unbalanced-data","title":"Unbalanced Data","text":"<p>An unbalanced feature is a feature for which one value predominates. Unbalanced features can occur naturally, but if a feature always has the same value you may have a data bug. To detect unbalanced features in a Facets Overview, choose \"Non-uniformity\" from the \"Sort by\" dropdown.</p> <p>The most unbalanced features will be listed at the top of each feature-type list. For example, the following screenshot shows one feature that is all zeros, and a second that is highly unbalanced, at the top of the \"Numeric Features\" list:</p> <p></p>"},{"location":"#uniformly-distributed-data","title":"Uniformly Distributed Data","text":"<p>A uniformly distributed feature is one for which all possible values appear with close to the same frequency. As with unbalanced data, this distribution can occur naturally, but can also be produced by data bugs.</p> <p>To detect uniformly distributed features in a Facets Overview, choose \"Non- uniformity\" from the \"Sort by\" dropdown and check the \"Reverse order\" checkbox:</p> <p></p> <p>String data is represented using bar charts if there are 20 or fewer unique values, and as a cumulative distribution graph if there are more than 20 unique values. So for string data, uniform distributions can appear as either flat bar graphs like the one above or straight lines like the one below:</p> <p></p>"},{"location":"#bugs-that-can-produce-uniformly-distributed-data","title":"Bugs That Can Produce Uniformly Distributed Data","text":"<p>Here are some common bugs that can produce uniformly distributed data:</p> <ul> <li> <p>Using strings to represent non-string data types such as dates. For     example, you will have many unique values for a datetime feature     with representations like <code>2017-03-01-11-45-03</code>. Unique values     will be distributed uniformly.</p> </li> <li> <p>Including indices like \"row number\" as features. Here again you     have many unique values.</p> </li> </ul>"},{"location":"#missing-data","title":"Missing Data","text":"<p>To check whether a feature is missing values entirely:</p> <ol> <li>Choose \"Amount missing/zero\" from the \"Sort by\" drop-down.</li> <li>Check the \"Reverse order\" checkbox.</li> <li>Look at the \"missing\" column to see the percentage of instances     with missing values for a feature.</li> </ol> <p>A data bug can also cause incomplete feature values. For example you may expect a feature's value list to always have three elements and discover that sometimes it only has one. To check for incomplete values or other cases where feature value lists don\\'t have the expected number of elements:</p> <ol> <li> <p>Choose \"Value list length\" from the \"Chart to show\" drop-down     menu on the right.</p> </li> <li> <p>Look at the chart to the right of each feature row. The chart shows     the range of value list lengths for the feature. For example, the     highlighted row in the screenshot below shows a feature that has     some zero-length value lists:</p> </li> </ol> <p></p>"},{"location":"#large-differences-in-scale-between-features","title":"Large Differences in Scale Between Features","text":"<p>If your features vary widely in scale, then the model may have difficulties learning. For example, if some features vary from 0 to 1 and others vary from 0 to 1,000,000,000, you have a big difference in scale. Compare the \"max\" and \"min\" columns across features to find widely varying scales.</p> <p>Consider normalizing feature values to reduce these wide variations.</p>"},{"location":"#labels-with-invalid-labels","title":"Labels with Invalid Labels","text":"<p>TensorFlow's Estimators have restrictions on the type of data they accept as labels. For example, binary classifiers typically only work with {0, 1} labels.</p> <p>Review the label values in the Facets Overview and make sure they conform to the requirements of Estimators.</p>"},{"location":"anomalies/","title":"TensorFlow Data Validation Anomalies Reference","text":"<p>TFDV checks for anomalies by comparing a schema and statistics proto(s). The following chart lists the anomaly types that TFDV can detect, the schema and statistics fields that are used to detect each anomaly type, and the condition(s) under which each anomaly type is detected.</p> <ul> <li> <p><code>BOOL_TYPE_BIG_INT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.bool_domain</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.num_stats.max</code></li> <li><code>features.type</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.bool_domain</code> is specified and</li> <li><code>features.type</code> == <code>INT</code> and</li> <li><code>features.num_stats.max</code> &gt; 1</li> </ul> </li> </ul> </li> <li> <p><code>BOOL_TYPE_BYTES_NOT_INT</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>BOOL_TYPE_BYTES_NOT_STRING</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>BOOL_TYPE_FLOAT_NOT_INT</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>BOOL_TYPE_FLOAT_NOT_STRING</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>BOOL_TYPE_INT_NOT_STRING</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>BOOL_TYPE_SMALL_INT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.bool_domain</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.num_stats.min</code></li> <li><code>features.type</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.type</code> == <code>INT</code> and</li> <li><code>feature.bool_domain</code> is specified and</li> <li><code>features.num_stats.min</code> &lt; 0</li> </ul> </li> </ul> </li> <li> <p><code>BOOL_TYPE_STRING_NOT_INT</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>BOOL_TYPE_UNEXPECTED_STRING</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.bool_domain</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.string_stats.rank_histogram</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.type</code> == <code>STRING</code> and</li> <li><code>feature.bool_domain</code> is specified and</li> <li>at least one value in <code>rank_histogram</code>* is not     <code>feature.bool_domain.true_value</code> or     <code>feature.bool_domain.false_value</code></li> </ul> </li> </ul> </li> <li> <p><code>BOOL_TYPE_UNEXPECTED_FLOAT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.bool_domain</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.num_stats.min</code></li> <li><code>features.num_stats.max</code></li> <li><code>features.num_stats.histograms.num_nan</code></li> <li><code>features.num_stats.histograms.buckets.low_value</code></li> <li><code>features.num_stats.histograms.buckets.high_value</code></li> <li><code>features.type</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.type</code> == <code>FLOAT</code> and</li> <li><code>feature.bool_domain</code> is specified and either<ul> <li>(<code>features.num_stats.min</code> != 0 or <code>features.num_stats.min</code> != 1)     or</li> <li>(<code>features.num_stats.max</code> != 0 or <code>features.num_stats.max</code> != 1)     or</li> <li><code>features.num_stats.histograms.num_nan</code> &gt; 0 or</li> <li>(<code>features.num_stats.histograms.buckets.low_value</code> != 0 or     <code>features.num_stats.histograms.buckets.high_value</code> != 1) and     <code>features.num_stats.histograms.buckets.sample_count</code> &gt; 0</li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>BOOL_TYPE_INVALID_CONFIG</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.bool_domain</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> </ul> </li> <li>Detection Condition:<ul> <li>If <code>features.type</code> == <code>INT</code> or <code>FLOAT</code>,<ul> <li><code>feature.bool_domain</code> is specified and</li> <li><code>feature.bool_domain.true_value</code> or     <code>feature.bool_domain.false_value</code> is specified, or</li> </ul> </li> <li>if <code>features.type</code> == <code>STRING</code>,<ul> <li><code>feature.bool_domain</code> is specified and</li> <li><code>feature.bool_domain.true_value</code> and     <code>feature.bool_domain.false_value</code> are not specified</li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>ENUM_TYPE_BYTES_NOT_STRING</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>ENUM_TYPE_FLOAT_NOT_STRING</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>ENUM_TYPE_INT_NOT_STRING</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>ENUM_TYPE_INVALID_UTF8</code></p> <ul> <li>Statistics Fields:<ul> <li><code>features.string_stats.invalid_utf8_count</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>invalid_utf8_count</code> &gt; 0</li> </ul> </li> </ul> </li> <li> <p><code>ENUM_TYPE_UNEXPECTED_STRING_VALUES</code></p> <ul> <li>Schema Fields:<ul> <li><code>string_domain</code> and <code>feature.domain</code>; or <code>feature.string_domain</code></li> <li><code>feature.distribution_constraints.min_domain_mass</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.string_stats.rank_histogram</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li>Either (number of values in <code>rank_histogram</code>* that are not in domain     / total number of values) &gt; (1 -     <code>feature.distribution_constraints.min_domain_mass</code>) or</li> <li><code>feature.distribution_constraints.min_domain_mass</code> == 1.0 and there     are values in the histogram that are not in the domain</li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_TYPE_HIGH_NUMBER_VALUES</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.value_count.max</code></li> <li><code>feature.value_counts.value_count.max</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.common_stats.max_num_values</code></li> <li><code>features.common_stats.presence_and_valency_stats.max_num_values</code></li> </ul> </li> <li>Detection Condition:<ul> <li>If <code>feature.value_count.max</code> is specified<ul> <li><code>features.common_stats.max_num_values</code> &gt;     <code>feature.value_count.max</code>; or</li> </ul> </li> <li>if <code>feature.value_counts</code> is specified<ul> <li><code>feature.value_counts.value_count.max</code> &lt;     <code>features.common_stats.presence_and_valency_stats.max_num_values</code>     at a given nestedness level</li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_TYPE_LOW_FRACTION_PRESENT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.presence.min_fraction</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.common_stats.num_non_missing</code>*</li> <li><code>num_examples</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.presence.min_fraction</code> is specified and     (<code>features.common_stats.num_non_missing</code> / <code>num_examples</code>) &lt;     <code>feature.presence.min_fraction</code> or</li> <li><code>feature.presence.min_fraction</code> == 1.0 and     <code>common_stats.num_missing</code> != 0</li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_TYPE_LOW_NUMBER_PRESENT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.presence.min_count</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.common_stats.num_non_missing</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.presence.min_count</code> is specified and either<ul> <li><code>features.common_stats.num_non_missing</code>* == 0 or</li> <li><code>features.common_stats.num_non_missing</code>* &lt;     <code>feature.presence.min_count</code></li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_TYPE_LOW_NUMBER_VALUES</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.value_count.min</code></li> <li><code>feature.value_counts.value_count.min</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.common_stats.min_num_values</code></li> <li><code>features.common_stats.presence_and_valency_stats.min_num_values</code></li> </ul> </li> <li>Detection Condition:<ul> <li>If <code>feature.value_count.min</code> is specified<ul> <li><code>features.common_stats.min_num_values</code> &lt;     <code>feature.value_count.min</code>; or</li> </ul> </li> <li>if <code>feature.value_counts</code> is specified<ul> <li><code>features.common_stats.presence_and_valency_stats.min_num_values</code>     &lt; <code>feature.value_counts.value_count.min</code> at a given nestedness     level</li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_TYPE_NOT_PRESENT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.in_environment</code> or <code>feature.not_in_environment</code> or     <code>schema.default_environment</code></li> <li><code>feature.lifecycle_stage</code></li> <li><code>feature.presence.min_count</code> or <code>feature.presence.min_fraction</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.common_stats.num_non_missing</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.lifecycle_stage</code> not in [<code>PLANNED</code>, <code>ALPHA</code>, <code>DEBUG</code>,     <code>DEPRECATED</code>] and</li> <li><code>common_stats.num_non_missing</code>* == 0 and</li> <li>(<code>feature.presence.min_count</code> &gt; 0 or     <code>feature.presence.min_fraction</code> &gt; 0) and either<ul> <li><code>feature.in_environment</code> == current environment or</li> <li><code>feature.not_in_environment</code> != current environment or</li> <li><code>schema.default_environment</code> != current environment</li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_TYPE_NO_VALUES</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>FEATURE_TYPE_UNEXPECTED_REPEATED</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>FEATURE_TYPE_HIGH_UNIQUE</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.unique_constraints.max</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.string_stats.unique</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.string_stats.unique</code> &gt; <code>feature.unique_constraints.max</code></li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_TYPE_LOW_UNIQUE</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.unique_constraints.min</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.string_stats.unique</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.string_stats.unique</code> &lt; <code>feature.unique_constraints.min</code></li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_TYPE_NO_UNIQUE</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.unique_constraints</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.string_stats.unique</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.unique_constraints</code> specified but no     <code>features.string_stats.unique</code> present (as is the case where the     feature is not a string or categorical)</li> </ul> </li> </ul> </li> <li> <p><code>FLOAT_TYPE_BIG_FLOAT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.float_domain.max</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> <li><code>features.num_stats.max</code> or <code>features.string_stats.rank_histogram</code></li> </ul> </li> <li>Detection Condition:<ul> <li>If <code>features.type</code> == <code>FLOAT</code>,<ul> <li><code>features.num_stats.max</code> &gt; <code>feature.float_domain.max</code>; or</li> </ul> </li> <li>if <code>features.type</code> == <code>BYTES</code> or <code>STRING</code>,<ul> <li>maximum value in <code>features.string_stats.rank_histogram</code> (when     converted to float) &gt; <code>feature.float_domain.max</code></li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>FLOAT_TYPE_NOT_FLOAT</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>FLOAT_TYPE_SMALL_FLOAT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.float_domain.min</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> <li><code>features.num_stats.min</code> or <code>features.string_stats.rank_histogram</code></li> </ul> </li> <li>Detection Condition:<ul> <li>If <code>features.type</code> == <code>FLOAT</code>,<ul> <li><code>features.num_stats.min</code> &lt; <code>feature.float_domain.min</code>; or</li> </ul> </li> <li>if <code>features.type</code> == <code>BYTES</code> or <code>STRING</code>,<ul> <li>minimum value in <code>features.string_stats.rank_histogram</code> (when     converted to float) &lt; <code>feature.float_domain.min</code></li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>FLOAT_TYPE_STRING_NOT_FLOAT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.float_domain</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> <li><code>features.string_stats.rank_histogram</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.type</code> == <code>BYTES</code> or <code>STRING</code> and</li> <li><code>features.string_stats.rank_histogram</code> has at least one value that     cannot be converted to a float</li> </ul> </li> </ul> </li> <li> <p><code>FLOAT_TYPE_NON_STRING</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>FLOAT_TYPE_UNKNOWN_TYPE_NUMBER</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>FLOAT_TYPE_HAS_NAN</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.float_domain.disallow_nan</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> <li><code>features.num_stats.histograms.num_nan</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>float_domain.disallow_nan</code> is true and</li> <li><code>features.num_stats.histograms.num_nan</code> &gt; 0</li> </ul> </li> </ul> </li> <li> <p><code>FLOAT_TYPE_HAS_INF</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.float_domain.disallow_inf</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> <li><code>features.num_stats.min</code></li> <li><code>features.num_stats.max</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.type</code> == <code>FLOAT</code></li> <li><code>float_domain.disallow_inf</code> is true and either<ul> <li><code>features.num_stats.min</code> == <code>inf/-inf</code> or</li> <li><code>features.num_stats.max</code> == <code>inf/-inf</code></li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>INT_TYPE_BIG_INT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.int_domain.max</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> <li><code>features.num_stats.max</code></li> <li><code>features.string_stats.rank_histogram</code></li> </ul> </li> <li>Detection Condition:<ul> <li>If <code>features.type</code> == <code>INT</code>,<ul> <li><code>features.num_stats.max</code> &gt; <code>feature.int_domain.max</code>; or</li> </ul> </li> <li>if <code>features.type</code> == <code>BYTES</code> or <code>STRING</code>,<ul> <li>maximum value in <code>features.string_stats.rank_histogram</code> (when     converted to int) &gt; <code>feature.int_domain.max</code></li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>INT_TYPE_INT_EXPECTED</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>INT_TYPE_NOT_INT_STRING</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.int_domain</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> <li><code>features.string_stats.rank_histogram</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.type</code> == <code>BYTES</code> or <code>STRING</code> and</li> <li><code>features.string_stats.rank_histogram</code> has at least one value that     cannot be converted to an int</li> </ul> </li> </ul> </li> <li> <p><code>INT_TYPE_NOT_STRING</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>INT_TYPE_SMALL_INT</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.int_domain.min</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> <li><code>features.num_stats.min</code></li> <li><code>features.string_stats.rank_histogram</code></li> </ul> </li> <li>Detection Condition:<ul> <li>If <code>features.type</code> == <code>INT</code>,<ul> <li><code>features.num_stats.min</code> &lt; <code>feature.int_domain.min</code>; or</li> </ul> </li> <li>if <code>features.type</code> == <code>BYTES</code> or <code>STRING</code>,<ul> <li>minimum value in <code>features.string_stats.rank_histogram</code> (when     converted to int) &lt; <code>feature.int_domain.min</code></li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>INT_TYPE_STRING_EXPECTED</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>INT_TYPE_UNKNOWN_TYPE_NUMBER</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>LOW_SUPPORTED_IMAGE_FRACTION</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.image_domain.minimum_supported_image_fraction</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats.rank_histogram</code> for the custom_stats with     name <code>image_format_histogram</code>. Note that semantic domain stats must     be enabled for the image_format_histogram to be generated and for     this validation to be performed. Semantic domain stats are not     generated by default.</li> </ul> </li> <li>Detection Condition:<ul> <li>The fraction of values that are supported Tensorflow image types to     all image types is less than     <code>feature.image_domain.minimum_supported_image_fraction</code>.</li> </ul> </li> </ul> </li> <li> <p><code>SCHEMA_MISSING_COLUMN</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.in_environment</code> or <code>feature.not_in_environment</code> or     <code>schema.default_environment</code></li> <li><code>feature.lifecycle_stage</code></li> <li><code>feature.presence.min_count</code> or <code>feature.presence.min_fraction</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.lifecycle_stage</code> != <code>PLANNED</code>, <code>ALPHA</code>, <code>DEBUG</code>, or     <code>DEPRECATED</code> and</li> <li><code>feature.presence.min_count</code> &gt; 0 or     <code>feature.presence.min_fraction</code> &gt; 0 and</li> <li><code>feature.in_environment</code> == current environment or     <code>feature.not_in_environment</code> != current environment or     <code>schema.default_environment</code> != current environment and</li> <li>no feature with the specified name/path is found in the statistics     proto</li> </ul> </li> </ul> </li> <li> <p><code>SCHEMA_NEW_COLUMN</code></p> <ul> <li>Detection Condition:<ul> <li>there is a feature in the statistics proto but no feature with its     name/path in the schema proto</li> </ul> </li> </ul> </li> <li> <p><code>SCHEMA_TRAINING_SERVING_SKEW</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>STRING_TYPE_NOW_FLOAT</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>STRING_TYPE_NOW_INT</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>COMPARATOR_CONTROL_DATA_MISSING</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.skew_comparator.infinity_norm.threshold</code></li> <li><code>feature.drift_comparator.infinity_norm.threshold</code></li> </ul> </li> <li>Detection Condition:<ul> <li>control statistics proto (i.e., serving statistics for skew or     previous statistics for drift) is available but does not contain the     specified feature</li> </ul> </li> </ul> </li> <li> <p><code>COMPARATOR_TREATMENT_DATA_MISSING</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>COMPARATOR_L_INFTY_HIGH</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.skew_comparator.infinity_norm.threshold</code></li> <li><code>feature.drift_comparator.infinity_norm.threshold</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.string_stats.rank_histogram</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li>L-infinity norm of the vector that represents the difference between     the normalized counts from the     <code>features.string_stats.rank_histogram</code>* in the control statistics     (i.e., serving statistics for skew or previous statistics for drift)     and the treatment statistics (i.e., training statistics for skew or     current statistics for drift) &gt;     <code>feature.skew_comparator.infinity_norm.threshold</code> or     <code>feature.drift_comparator.infinity_norm.threshold</code></li> </ul> </li> </ul> </li> <li> <p><code>COMPARATOR_NORMALIZED_ABSOLUTE_DIFFERENCE_HIGH</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.skew_comparator.normalized_abs_difference.threshold</code></li> <li><code>feature.drift_comparator.normalized_abs_difference.threshold</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.string_stats.rank_histogram</code></li> </ul> </li> <li>Detection Condition:<ul> <li>The normalized absolute count difference of value counts from the     <code>features.string_stats.rank_histogram</code> in the control statistics     (i.e., serving statistics for skew or previous statistics for drift)     and the treatment statistics (i.e., training statistics for skew or     current statistics for drift) exceeded     feature.skew_comparator.normalized_abs_difference.threshold or     feature.drift_comparator.normalized_abs_difference.threshold. Count     differences are normalized by the total count across both     conditions.</li> </ul> </li> </ul> </li> <li> <p><code>COMPARATOR_JENSEN_SHANNON_DIVERGENCE_HIGH</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.skew_comparator.jensen_shannon_divergence.threshold</code></li> <li><code>feature.drift_comparator.jensen_shannon_divergence.threshold</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.num_stats.histograms</code> of type <code>STANDARD</code></li> <li><code>features.string_stats.rank_histogram</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li>Approximate Jensen-Shannon divergence computed between in the     control statistics (i.e., serving statistics for skew or previous     statistics for drift) and the treatment statistics (i.e., training     statistics for skew or current statistics for drift) &gt;     <code>feature.skew_comparator.jensen_shannon_divergence.threshold</code> or     <code>feature.drift_comparator.jensen_shannon_divergence.threshold</code>. The     approximate Jensen-Shannon divergence is computed based on the     normalized sample counts in both <code>features.num_stats.histograms</code>     standard histogram and <code>features.string_stats.rank_histogram</code>*.</li> </ul> </li> </ul> </li> <li> <p><code>NO_DATA_IN_SPAN</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>SPARSE_FEATURE_MISSING_VALUE</code></p> <ul> <li>Schema Fields:<ul> <li><code>sparse_feature.value_feature</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.custom_stats</code> with \"missing_value\" as name and</li> <li><code>missing_value</code> custom stat != 0</li> </ul> </li> </ul> </li> <li> <p><code>SPARSE_FEATURE_MISSING_INDEX</code></p> <ul> <li>Schema Fields:<ul> <li><code>sparse_feature.index_feature</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.custom_stats</code> with \"missing_index\" as name and</li> <li><code>missing_index</code> custom stat contains any value != 0</li> </ul> </li> </ul> </li> <li> <p><code>SPARSE_FEATURE_LENGTH_MISMATCH</code></p> <ul> <li>Schema Fields:<ul> <li><code>sparse_feature.value_feature</code></li> <li><code>sparse_feature.index_feature</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.custom_stats</code> with \"min_length_diff\" or \"max_length_diff\"     as name</li> <li><code>min_length_diff</code> or <code>max_length_diff</code> custom stat contains any     value != 0</li> </ul> </li> </ul> </li> <li> <p><code>SPARSE_FEATURE_NAME_COLLISION</code></p> <ul> <li>Schema Fields:<ul> <li><code>sparse_feature.name</code></li> <li><code>sparse_feature.lifecycle_stage</code></li> <li><code>feature.name</code></li> <li><code>feature.lifecycle_stage</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>sparse_feature.lifecycle_stage</code> != <code>PLANNED</code>, <code>ALPHA</code>, <code>DEBUG</code>, or     <code>DEPRECATED</code>, and</li> <li><code>feature.lifecycle_stage</code> != <code>PLANNED</code>, <code>ALPHA</code>, <code>DEBUG</code>, or     <code>DEPRECATED</code>, and</li> <li><code>sparse_feature.name</code> == <code>feature.name</code></li> </ul> </li> </ul> </li> <li> <p><code>SEMANTIC_DOMAIN_UPDATE</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.domain_info</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.custom_stats</code> with \"domain_info\" as name and</li> <li><code>feature.domain_info</code> is not already set in the schema and</li> <li>there is a single <code>domain_info</code> custom stat for the feature</li> </ul> </li> </ul> </li> <li> <p><code>COMPARATOR_LOW_NUM_EXAMPLES</code></p> <ul> <li>Schema Fields:<ul> <li><code>schema.dataset_constraints.num_examples_drift_comparator.min_fraction_threshold</code></li> <li><code>schema.dataset_constraints.num_examples_version_comparator.min_fraction_threshold</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>num_examples</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li><code>num_examples</code>* &gt; 0 and</li> <li>previous statistics proto is available and</li> <li><code>num_examples</code> / previous statistics <code>num_examples</code> &lt; comparator     <code>min_fraction_threshold</code></li> </ul> </li> </ul> </li> <li> <p><code>COMPARATOR_HIGH_NUM_EXAMPLES</code></p> <ul> <li>Schema Fields:<ul> <li><code>schema.dataset_constraints.num_examples_drift_comparator.max_fraction_threshold</code></li> <li><code>schema.dataset_constraints.num_examples_version_comparator.max_fraction_threshold</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>num_examples</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li><code>num_examples</code>* &gt; 0 and</li> <li>previous statistics proto is available and</li> <li><code>num_examples</code> / previous statistics <code>num_examples</code> &gt; comparator     <code>max_fraction_threshold</code></li> </ul> </li> </ul> </li> <li> <p><code>DATASET_LOW_NUM_EXAMPLES</code></p> <ul> <li>Schema Fields:<ul> <li><code>schema.dataset_constraints.min_examples_count</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>num_examples</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li><code>num_examples</code>* &lt; <code>dataset_constraints.min_examples_count</code></li> </ul> </li> </ul> </li> <li> <p><code>DATASET_HIGH_NUM_EXAMPLES</code></p> <ul> <li>Schema Fields:<ul> <li><code>schema.dataset_constraints.max_examples_count</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>num_examples</code>*</li> </ul> </li> <li>Detection Condition:<ul> <li><code>num_examples</code>* &gt; <code>dataset_constraints.max_examples_count</code></li> </ul> </li> </ul> </li> <li> <p><code>WEIGHTED_FEATURE_NAME_COLLISION</code></p> <ul> <li>Schema Fields:<ul> <li><code>weighted_feature.name</code></li> <li><code>weighted_feature.lifecycle_stage</code></li> <li><code>sparse_feature.name</code></li> <li><code>sparse_feature.lifecycle_stage</code></li> <li><code>feature.name</code></li> <li><code>feature.lifecycle_stage</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>weighted_feature.lifecycle_stage</code> != <code>PLANNED</code>, <code>ALPHA</code>, <code>DEBUG</code>,     or <code>DEPRECATED</code> and either<ul> <li>if <code>feature.lifecycle_stage</code> != <code>PLANNED</code>, <code>ALPHA</code>, <code>DEBUG</code>, or     <code>DEPRECATED</code>,<ul> <li><code>weighted_feature.name</code> == <code>feature.name</code>; or</li> </ul> </li> <li>if <code>sparse_feature.lifecycle_stage</code> != <code>PLANNED</code>, <code>ALPHA</code>,     <code>DEBUG</code>, or <code>DEPRECATED</code>,<ul> <li><code>weighted_feature.name</code> == <code>sparse_feature.name</code></li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>WEIGHTED_FEATURE_MISSING_VALUE</code></p> <ul> <li>Schema Fields:<ul> <li><code>weighted_feature.feature</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.custom_stats</code> with \"missing_value\" as name and</li> <li><code>missing_value</code> custom stat != 0</li> </ul> </li> </ul> </li> <li> <p><code>WEIGHTED_FEATURE_MISSING_WEIGHT</code></p> <ul> <li>Schema Fields:<ul> <li><code>weighted_feature.weight_feature</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.custom_stats</code> with \"missing_weight\" as name and</li> <li><code>missing_weight</code> custom stat != 0</li> </ul> </li> </ul> </li> <li> <p><code>WEIGHTED_FEATURE_LENGTH_MISMATCH</code></p> <ul> <li>Schema Fields:<ul> <li><code>weighted_feature.feature</code></li> <li><code>weighted_feature.weight_feature</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.custom_stats</code> with \"min_weighted_length_diff\" or     \"max_weight_length_diff\" as name, and</li> <li><code>min_weight_length_diff</code> or <code>max_weight_length_diff</code> custom stat !=     0</li> </ul> </li> </ul> </li> <li> <p><code>VALUE_NESTEDNESS_MISMATCH</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.value_count</code></li> <li><code>feature.value_counts</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.common_stats.presence_and_valency_stats</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.value_count</code> is specified, and there is a repeated     <code>presence_and_valency_stats</code> of the feature (which indicates a     nestedness level that is greater than one) and</li> <li><code>feature.value_counts</code> is specified, and the number of times the     <code>presence_and_valency_stats</code> of the feature is repeated does not     match the number of times <code>value_count</code> is repeated within     <code>feature.value_counts</code></li> </ul> </li> </ul> </li> <li> <p><code>DOMAIN_INVALID_FOR_TYPE</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.type</code></li> <li><code>feature.domain_info</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> </ul> </li> <li>Detection Condition:<ul> <li>If <code>features.type</code> == <code>BYTES</code>,<ul> <li><code>feature.domain_info</code> is of an incompatible type; or</li> </ul> </li> <li>if <code>features.type</code> != <code>BYTES</code>,<ul> <li><code>feature.domain_info</code> does not match <code>feature.type</code> (e.g.,     <code>int_domain</code> is specified, but feature's <code>type</code> is <code>FLOAT</code>)</li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_MISSING_NAME</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.name</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.name</code> is not specified</li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_MISSING_TYPE</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.type</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.type</code> is not specified</li> </ul> </li> </ul> </li> <li> <p><code>INVALID_SCHEMA_SPECIFICATION</code></p> <p>NOTE: There are various different reasons why an anomaly of <code>INVALID_SCHEMA_SPECIFICATION</code> may be generated. Each bullet in the Detection Condition below lists an independent reason.</p> <ul> <li>Schema Fields:<ul> <li><code>feature.domain_info</code></li> <li><code>feature.presence.min_fraction</code></li> <li><code>feature.value_count.min</code></li> <li><code>feature.value_count.max</code></li> <li><code>feature.distribution_constraints</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.presence.min_fraction</code> &lt; 0.0 or &gt; 1.0, or</li> <li><code>feature.value_count.min</code> &lt; 0 or &gt; <code>feature.value_count.max</code>, or</li> <li>a bool, int, float, struct, or semantic domain is specified for a     feature and <code>feature.distribution_constraints</code> is also specified for     that feature, or</li> <li><code>feature.distribution_constraints</code> is specified for a feature, but     neither a schema-level domain nor <code>feature.string_domain</code> is     specified for that feature</li> </ul> </li> </ul> </li> <li> <p><code>INVALID_DOMAIN_SPECIFICATION</code></p> <p>NOTE: There are various different reasons why an anomaly of <code>INVALID_DOMAIN_SPECIFICATION</code> may be generated. Each bullet in the Detection Condition below lists an independent reason.</p> <ul> <li>Schema Fields:<ul> <li><code>feature.domain_info</code></li> <li><code>feature.bool_domain</code></li> <li><code>feature.string_domain</code></li> </ul> </li> <li>Detection Condition:<ul> <li>Unknown <code>feature.domain_info</code> type is specified or</li> <li><code>feature.domain</code> is specified, but there is no matching domain     specified at the schema level, or</li> <li>if <code>feature.bool_domain</code>, <code>feature.bool_domain.true_value</code>, and     <code>feature.bool_domain.false_value</code> are specified,<ul> <li><code>feature.bool_domain.true_value</code> ==     <code>feature.bool_domain.false_value</code>, or</li> </ul> </li> <li>if <code>feature.string_domain</code> is specified,<ul> <li>has duplicated <code>feature.string_domain.values</code> or</li> <li><code>feature.string_domain</code> exceeds the maximum size</li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>UNEXPECTED_DATA_TYPE</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.type</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.type</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.type</code> is not of type specified in <code>feature.type</code></li> </ul> </li> </ul> </li> <li> <p><code>SEQUENCE_VALUE_TOO_FEW_OCCURRENCES</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.natural_language_domain.token_constraints.min_per_sequence</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats.nl_statistics.token_statistics.per_sequence_min_frequency</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>min_per_sequence</code> &gt; <code>per_sequence_min_frequency</code></li> </ul> </li> </ul> </li> <li> <p><code>SEQUENCE_VALUE_TOO_MANY_OCCURRENCES</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.natural_language_domain.token_constraints.max_per_sequence</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats.nl_statistics.token_statistics.per_sequence_max_frequency</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>max_per_sequence</code> &lt; <code>per_sequence_max_frequency</code></li> </ul> </li> </ul> </li> <li> <p><code>SEQUENCE_VALUE_TOO_SMALL_FRACTION</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.natural_language_domain.token_constraints.min_fraction_of_sequences</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats.nl_statistics.token_statistics.fraction_of_sequences</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>min_fraction_of_sequences</code> &gt; <code>fraction_of_sequences</code></li> </ul> </li> </ul> </li> <li> <p><code>SEQUENCE_VALUE_TOO_LARGE_FRACTION</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.natural_language_domain.token_constraints.max_fraction_of_sequences</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats.nl_statistics.token_statistics.fraction_of_sequences</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>max_fraction_of_sequences</code> &lt; <code>fraction_of_sequences</code></li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_COVERAGE_TOO_LOW</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.natural_language_domain.coverage.min_coverage</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats.nl_statistics.feature_coverage</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature_coverage</code> &lt; <code>coverage.min_coverage</code></li> </ul> </li> </ul> </li> <li> <p><code>FEATURE_COVERAGE_TOO_SHORT_AVG_TOKEN_LENGTH</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.natural_language_domain.coverage.min_avg_token_length</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.custom_stats.nl_statistics.avg_token_length</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>avg_token_length</code> &lt; <code>min_avg_token_length</code></li> </ul> </li> </ul> </li> <li> <p><code>NLP_WRONG_LOCATION</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>EMBEDDING_SHAPE_INVALID</code></p> <ul> <li>Anomaly type not detected in TFDV</li> </ul> </li> <li> <p><code>MAX_IMAGE_BYTE_SIZE_EXCEEDED</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.image_domain.max_image_byte_size</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.bytes_stats.max_num_bytes_int</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>max_num_bytes_int</code> &gt; <code>max_image_byte_size</code></li> </ul> </li> </ul> </li> <li> <p><code>INVALID_FEATURE_SHAPE</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.shape</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.common_stats.num_missing</code></li> <li><code>features.common_stats.min_num_values</code></li> <li><code>features.common_stats.max_num_values</code></li> <li><code>features.common_stats.presence_and_valency_stats.num_missing</code></li> <li><code>features.common_stats.presence_and_valency_stats.min_num_values</code></li> <li><code>features.common_stats.presence_and_valency_stats.max_num_values</code></li> <li><code>features.common_stats.weighted_presence_and_valency_stats</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.shape</code> is specified, and either<ul> <li>the feature may be missing (<code>num_missing</code> != 0) at some nest     level or</li> <li>the feature may have variable number of values (<code>min_num_values</code>     != <code>max_num_values</code>) at some nest level or</li> <li>the specified shape is not compatible with the feature's value     count stats. For example, shape <code>[16]</code> is compatible with     (<code>min_num_values</code> == <code>max_num_values</code> == <code>[2, 2, 4]</code> (for a     3-nested feature))</li> </ul> </li> </ul> </li> </ul> </li> <li> <p><code>STATS_NOT_AVAILBLE</code></p> <ul> <li>Anomaly occurs when stats needed to validate constraints are not     present.</li> </ul> </li> <li> <p><code>DERIVED_FEATURE_BAD_LIFECYCLE</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.lifecycle_stage</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.validation_derived_source</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>feature.lifecycle_stage</code> is not one of <code>DERIVED</code> or <code>DISABLED</code>, and     <code>features.validation_derived_source</code> is present, indicating that     this is a derived feature.</li> </ul> </li> </ul> </li> <li> <p><code>DERIVED_FEATURE_INVALID_SOURCE</code></p> <ul> <li>Schema Fields:<ul> <li><code>feature.validation_derived_source</code></li> </ul> </li> <li>Statistics Fields:<ul> <li><code>features.validation_derived_source</code></li> </ul> </li> <li>Detection Condition:<ul> <li><code>features.validation_derived_source</code> is present for a feature, but     the corresponding <code>feature.validation_derived_source</code> is not.</li> </ul> </li> </ul> </li> </ul> <p>* If a weighted statistic is available for this field, it will be used instead of the non-weighted statistic.</p>"},{"location":"api/","title":"TensorFlow Data Validation API Documentation","text":""},{"location":"api/#tensorflow_data_validation","title":"tensorflow_data_validation","text":"<p>Init module for TensorFlow Data Validation.</p>"},{"location":"api/#tensorflow_data_validation-attributes","title":"Attributes","text":""},{"location":"api/#tensorflow_data_validation.FeaturePath","title":"FeaturePath  <code>module-attribute</code>","text":"<pre><code>FeaturePath = FeaturePath\n</code></pre>"},{"location":"api/#tensorflow_data_validation.__version__","title":"__version__  <code>module-attribute</code>","text":"<pre><code>__version__ = '1.18.0.dev'\n</code></pre>"},{"location":"api/#tensorflow_data_validation-classes","title":"Classes","text":""},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator","title":"CombinerStatsGenerator","text":"<pre><code>CombinerStatsGenerator(\n    name: str, schema: Optional[Schema] = None\n)\n</code></pre> <p>               Bases: <code>Generic[ACCTYPE]</code>, <code>StatsGenerator</code></p> <p>A StatsGenerator which computes statistics using a combiner function.</p> <p>This class computes statistics using a combiner function. It emits partial states processing a batch of examples at a time, merges the partial states, and finally computes the statistics from the merged partial state at the end.</p> <p>This object mirrors a beam.CombineFn except for the add_input interface, which is expected to be defined by its sub-classes. Specifically, the generator must implement the following four methods:</p> <p>Initializes an accumulator to store the partial state and returns it.     create_accumulator()</p> <p>Incorporates a batch of input examples (represented as an arrow RecordBatch) into the current accumulator and returns the updated accumulator.     add_input(accumulator, input_record_batch)</p> <p>Merge the partial states in the accumulators and returns the accumulator containing the merged state.     merge_accumulators(accumulators)</p> <p>Compute statistics from the partial state in the accumulator and return the result as a DatasetFeatureStatistics proto.     extract_output(accumulator)</p> <p>Initializes a statistics generator.</p> <p>name: A unique name associated with the statistics generator.   schema: An optional schema for the dataset.</p> Source code in <code>tensorflow_data_validation/statistics/generators/stats_generator.py</code> <pre><code>def __init__(self, name: str, schema: Optional[schema_pb2.Schema] = None) -&gt; None:\n    \"\"\"Initializes a statistics generator.\n\n    Args:\n    ----\n      name: A unique name associated with the statistics generator.\n      schema: An optional schema for the dataset.\n    \"\"\"\n    self._name = name\n    self._schema = schema\n</code></pre>"},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator-attributes","title":"Attributes","text":""},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator.name","title":"name  <code>property</code>","text":"<pre><code>name\n</code></pre>"},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator.schema","title":"schema  <code>property</code>","text":"<pre><code>schema\n</code></pre>"},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator.add_input","title":"add_input","text":"<pre><code>add_input(\n    accumulator: ACCTYPE, input_record_batch: RecordBatch\n) -&gt; ACCTYPE\n</code></pre> <p>Returns result of folding a batch of inputs into accumulator.</p> <p>accumulator: The current accumulator, which may be modified and returned     for efficiency.   input_record_batch: An Arrow RecordBatch whose columns are features and     rows are examples. The columns are of type List or Null (If a     feature's value is None across all the examples in the batch, its     corresponding column is of Null type). <p>The accumulator after updating the statistics for the batch of inputs.</p> Source code in <code>tensorflow_data_validation/statistics/generators/stats_generator.py</code> <pre><code>def add_input(\n    self, accumulator: ACCTYPE, input_record_batch: pa.RecordBatch\n) -&gt; ACCTYPE:\n    \"\"\"Returns result of folding a batch of inputs into accumulator.\n\n    Args:\n    ----\n      accumulator: The current accumulator, which may be modified and returned\n        for efficiency.\n      input_record_batch: An Arrow RecordBatch whose columns are features and\n        rows are examples. The columns are of type List&lt;primitive&gt; or Null (If a\n        feature's value is None across all the examples in the batch, its\n        corresponding column is of Null type).\n\n    Returns:\n    -------\n      The accumulator after updating the statistics for the batch of inputs.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator.compact","title":"compact","text":"<pre><code>compact(accumulator: ACCTYPE) -&gt; ACCTYPE\n</code></pre> <p>Returns a compact representation of the accumulator.</p> <p>This is optionally called before an accumulator is sent across the wire. The base class is a no-op. This may be overwritten by the derived class.</p> <p>accumulator: The accumulator to compact.</p> <p>The compacted accumulator. By default is an identity.</p> Source code in <code>tensorflow_data_validation/statistics/generators/stats_generator.py</code> <pre><code>def compact(self, accumulator: ACCTYPE) -&gt; ACCTYPE:\n    \"\"\"Returns a compact representation of the accumulator.\n\n    This is optionally called before an accumulator is sent across the wire. The\n    base class is a no-op. This may be overwritten by the derived class.\n\n    Args:\n    ----\n      accumulator: The accumulator to compact.\n\n    Returns:\n    -------\n      The compacted accumulator. By default is an identity.\n    \"\"\"\n    return accumulator\n</code></pre>"},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator.create_accumulator","title":"create_accumulator","text":"<pre><code>create_accumulator() -&gt; ACCTYPE\n</code></pre> <p>Returns a fresh, empty accumulator.</p>"},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator.create_accumulator--returns","title":"Returns","text":"<p>An empty accumulator.</p> Source code in <code>tensorflow_data_validation/statistics/generators/stats_generator.py</code> <pre><code>def create_accumulator(self) -&gt; ACCTYPE:\n    \"\"\"Returns a fresh, empty accumulator.\n\n    Returns\n    -------\n      An empty accumulator.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator.extract_output","title":"extract_output","text":"<pre><code>extract_output(\n    accumulator: ACCTYPE,\n) -&gt; DatasetFeatureStatistics\n</code></pre> <p>Returns result of converting accumulator into the output value.</p> <p>accumulator: The final accumulator value.</p> <p>A proto representing the result of this stats generator.</p> Source code in <code>tensorflow_data_validation/statistics/generators/stats_generator.py</code> <pre><code>def extract_output(\n    self, accumulator: ACCTYPE\n) -&gt; statistics_pb2.DatasetFeatureStatistics:\n    \"\"\"Returns result of converting accumulator into the output value.\n\n    Args:\n    ----\n      accumulator: The final accumulator value.\n\n    Returns:\n    -------\n      A proto representing the result of this stats generator.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator.merge_accumulators","title":"merge_accumulators","text":"<pre><code>merge_accumulators(\n    accumulators: Iterable[ACCTYPE],\n) -&gt; ACCTYPE\n</code></pre> <p>Merges several accumulators to a single accumulator value.</p> <p>Note: mutating any element in <code>accumulators</code> except for the first is not allowed. The first element may be modified and returned for efficiency.</p> <p>accumulators: The accumulators to merge.</p> <p>The merged accumulator.</p> Source code in <code>tensorflow_data_validation/statistics/generators/stats_generator.py</code> <pre><code>def merge_accumulators(self, accumulators: Iterable[ACCTYPE]) -&gt; ACCTYPE:\n    \"\"\"Merges several accumulators to a single accumulator value.\n\n    Note: mutating any element in `accumulators` except for the first is not\n    allowed. The first element may be modified and returned for efficiency.\n\n    Args:\n    ----\n      accumulators: The accumulators to merge.\n\n    Returns:\n    -------\n      The merged accumulator.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/#tensorflow_data_validation.CombinerStatsGenerator.setup","title":"setup","text":"<pre><code>setup() -&gt; None\n</code></pre> <p>Prepares an instance for combining.</p> <p>Subclasses should put costly initializations here instead of in init(), so that 1) the cost is properly recognized by Beam as setup cost (per worker) and 2) the cost is not paid at the pipeline construction time.</p> Source code in <code>tensorflow_data_validation/statistics/generators/stats_generator.py</code> <pre><code>def setup(self) -&gt; None:\n    \"\"\"Prepares an instance for combining.\n\n    Subclasses should put costly initializations here instead of in\n    __init__(), so that 1) the cost is properly recognized by Beam as\n    setup cost (per worker) and 2) the cost is not paid at the pipeline\n    construction time.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#tensorflow_data_validation.CrossFeatureView","title":"CrossFeatureView","text":"<pre><code>CrossFeatureView(stats_proto: CrossFeatureStatistics)\n</code></pre> <p>View of a single cross feature.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def __init__(self, stats_proto: statistics_pb2.CrossFeatureStatistics):\n    self._statistics = stats_proto\n</code></pre>"},{"location":"api/#tensorflow_data_validation.CrossFeatureView-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.CrossFeatureView.proto","title":"proto","text":"<pre><code>proto() -&gt; CrossFeatureStatistics\n</code></pre> <p>Retrieve the underlying proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def proto(self) -&gt; statistics_pb2.CrossFeatureStatistics:\n    \"\"\"Retrieve the underlying proto.\"\"\"\n    return self._statistics\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetListView","title":"DatasetListView","text":"<pre><code>DatasetListView(stats_proto: DatasetFeatureStatisticsList)\n</code></pre> <p>View of statistics for multiple datasets (slices).</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def __init__(self, stats_proto: statistics_pb2.DatasetFeatureStatisticsList):\n    self._statistics = stats_proto\n    self._slice_map = {}  # type: Dict[str, DatasetView]\n    self._initialized = False\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetListView-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.DatasetListView.get_default_slice","title":"get_default_slice","text":"<pre><code>get_default_slice() -&gt; Optional[DatasetView]\n</code></pre> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def get_default_slice(self) -&gt; Optional[\"DatasetView\"]:\n    self._init_index()\n    if len(self._slice_map) == 1:\n        for _, v in self._slice_map.items():\n            return v\n    return self._slice_map.get(constants.DEFAULT_SLICE_KEY, None)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetListView.get_default_slice_or_die","title":"get_default_slice_or_die","text":"<pre><code>get_default_slice_or_die() -&gt; DatasetView\n</code></pre> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def get_default_slice_or_die(self) -&gt; \"DatasetView\":\n    # TODO(b/221453427): Update uses, or consider changing get_default_slice.\n    default_slice = self.get_default_slice()\n    if default_slice is None:\n        raise ValueError(\"Missing default slice\")\n    return default_slice\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetListView.get_slice","title":"get_slice","text":"<pre><code>get_slice(slice_key: str) -&gt; Optional[DatasetView]\n</code></pre> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def get_slice(self, slice_key: str) -&gt; Optional[\"DatasetView\"]:\n    self._init_index()\n    return self._slice_map.get(slice_key, None)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetListView.list_slices","title":"list_slices","text":"<pre><code>list_slices() -&gt; Iterable[str]\n</code></pre> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def list_slices(self) -&gt; Iterable[str]:\n    self._init_index()\n    return self._slice_map.keys()\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetListView.proto","title":"proto","text":"<pre><code>proto() -&gt; DatasetFeatureStatisticsList\n</code></pre> <p>Retrieve the underlying proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def proto(self) -&gt; statistics_pb2.DatasetFeatureStatisticsList:\n    \"\"\"Retrieve the underlying proto.\"\"\"\n    return self._statistics\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetView","title":"DatasetView","text":"<pre><code>DatasetView(stats_proto: DatasetFeatureStatistics)\n</code></pre> <p>View of statistics for a dataset (slice).</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def __init__(self, stats_proto: statistics_pb2.DatasetFeatureStatistics):\n    self._feature_map = {}  # type: Dict[types.FeaturePath, int]\n    self._cross_feature_map = {}  # type: Dict[Tuple[types.FeaturePath, types.FeaturePath], int]\n    self._statistics = stats_proto\n    self._initialized = False\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetView-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.DatasetView.get_cross_feature","title":"get_cross_feature","text":"<pre><code>get_cross_feature(\n    x_path: Union[str, FeaturePath, Iterable[str]],\n    y_path: Union[str, FeaturePath, Iterable[str]],\n) -&gt; Optional[CrossFeatureView]\n</code></pre> <p>Retrieve a cross-feature if it exists, or None.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def get_cross_feature(\n    self,\n    x_path: Union[str, types.FeaturePath, Iterable[str]],\n    y_path: Union[str, types.FeaturePath, Iterable[str]],\n) -&gt; Optional[\"CrossFeatureView\"]:\n    \"\"\"Retrieve a cross-feature if it exists, or None.\"\"\"\n    x_path = _normalize_feature_id(x_path)\n    y_path = _normalize_feature_id(y_path)\n    self._init_index()\n    feature_id = (x_path, y_path)\n    index = self._cross_feature_map.get(feature_id, None)\n    if index is None:\n        return None\n    return CrossFeatureView(self._statistics.cross_features[index])\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetView.get_derived_feature","title":"get_derived_feature","text":"<pre><code>get_derived_feature(\n    deriver_name: str, source_paths: Sequence[FeaturePath]\n) -&gt; Optional[FeatureView]\n</code></pre> <p>Retrieve a derived feature based on a deriver name and its inputs.</p> <p>deriver_name: The name of a deriver. Matches validation_derived_source     deriver_name.   source_paths: Source paths for derived features. Matches     validation_derived_source.source_path.</p> <p>FeatureView of derived feature.</p> <p>ValueError if multiple derived features match.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def get_derived_feature(\n    self, deriver_name: str, source_paths: Sequence[types.FeaturePath]\n) -&gt; Optional[\"FeatureView\"]:\n    \"\"\"Retrieve a derived feature based on a deriver name and its inputs.\n\n    Args:\n    ----\n      deriver_name: The name of a deriver. Matches validation_derived_source\n        deriver_name.\n      source_paths: Source paths for derived features. Matches\n        validation_derived_source.source_path.\n\n    Returns:\n    -------\n      FeatureView of derived feature.\n\n    Raises:\n    ------\n      ValueError if multiple derived features match.\n    \"\"\"\n    # TODO(b/221453427): Consider indexing if performance becomes an issue.\n    results = []\n    for feature in self.proto().features:\n        if feature.validation_derived_source is None:\n            continue\n        if feature.validation_derived_source.deriver_name != deriver_name:\n            continue\n        if len(source_paths) != len(feature.validation_derived_source.source_path):\n            continue\n        all_match = True\n        for i in range(len(source_paths)):\n            if source_paths[i] != types.FeaturePath.from_proto(\n                feature.validation_derived_source.source_path[i]\n            ):\n                all_match = False\n                break\n        if all_match:\n            results.append(FeatureView(feature))\n        if len(results) &gt; 1:\n            raise ValueError(\"Ambiguous result, %d features matched\" % len(results))\n    if len(results) == 1:\n        return results.pop()\n    return None\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetView.get_feature","title":"get_feature","text":"<pre><code>get_feature(\n    feature_id: Union[str, FeaturePath, Iterable[str]],\n) -&gt; Optional[FeatureView]\n</code></pre> <p>Retrieve a feature if it exists.</p> <p>Features specified within the underlying proto by name (instead of path) are normalized to a length 1 path, and can be referred to as such.</p> <p>feature_id: A types.FeaturePath, Iterable[str] consisting of path steps,     or a str, which is converted to a length one path.</p> <p>A FeatureView, or None if feature_id is not present.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def get_feature(\n    self, feature_id: Union[str, types.FeaturePath, Iterable[str]]\n) -&gt; Optional[\"FeatureView\"]:\n    \"\"\"Retrieve a feature if it exists.\n\n    Features specified within the underlying proto by name (instead of path) are\n    normalized to a length 1 path, and can be referred to as such.\n\n    Args:\n    ----\n      feature_id: A types.FeaturePath, Iterable[str] consisting of path steps,\n        or a str, which is converted to a length one path.\n\n    Returns:\n    -------\n      A FeatureView, or None if feature_id is not present.\n    \"\"\"\n    feature_id = _normalize_feature_id(feature_id)\n    self._init_index()\n    index = self._feature_map.get(feature_id, None)\n    if index is None:\n        return None\n    return FeatureView(self._statistics.features[index])\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetView.list_cross_features","title":"list_cross_features","text":"<pre><code>list_cross_features() -&gt; Iterable[\n    Tuple[FeaturePath, FeaturePath]\n]\n</code></pre> <p>Lists cross-feature identifiers.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def list_cross_features(\n    self,\n) -&gt; Iterable[Tuple[types.FeaturePath, types.FeaturePath]]:\n    \"\"\"Lists cross-feature identifiers.\"\"\"\n    self._init_index()\n    return self._cross_feature_map.keys()\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetView.list_features","title":"list_features","text":"<pre><code>list_features() -&gt; Iterable[FeaturePath]\n</code></pre> <p>Lists feature identifiers.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def list_features(self) -&gt; Iterable[types.FeaturePath]:\n    \"\"\"Lists feature identifiers.\"\"\"\n    self._init_index()\n    return self._feature_map.keys()\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DatasetView.proto","title":"proto","text":"<pre><code>proto() -&gt; DatasetFeatureStatistics\n</code></pre> <p>Retrieve the underlying proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def proto(self) -&gt; statistics_pb2.DatasetFeatureStatistics:\n    \"\"\"Retrieve the underlying proto.\"\"\"\n    return self._statistics\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DetectFeatureSkew","title":"DetectFeatureSkew","text":"<pre><code>DetectFeatureSkew(\n    identifier_features: List[FeatureName],\n    features_to_ignore: Optional[List[FeatureName]] = None,\n    sample_size: int = 0,\n    float_round_ndigits: Optional[int] = None,\n    allow_duplicate_identifiers: bool = False,\n)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>API for detecting feature skew between training and serving examples.</p>"},{"location":"api/#tensorflow_data_validation.DetectFeatureSkew--example","title":"Example:","text":"<pre><code>  with beam.Pipeline(runner=...) as p:\n     training_examples = p | 'ReadTrainingData' &gt;&gt;\n       beam.io.ReadFromTFRecord(\n          training_filepaths, coder=beam.coders.ProtoCoder(tf.train.Example))\n     serving_examples = p | 'ReadServingData' &gt;&gt;\n       beam.io.ReadFromTFRecord(\n          serving_filepaths, coder=beam.coders.ProtoCoder(tf.train.Example))\n     _ = ((training_examples, serving_examples) | 'DetectFeatureSkew' &gt;&gt;\n       DetectFeatureSkew(identifier_features=['id1'], sample_size=5)\n     | 'WriteFeatureSkewResultsOutput' &gt;&gt;\n       tfdv.WriteFeatureSkewResultsToTFRecord(output_path)\n     | 'WriteFeatureSkwePairsOutput' &gt;&gt;\n     tfdv.WriteFeatureSkewPairsToTFRecord(output_path))\n</code></pre> <p>See the documentation for DetectFeatureSkewImpl for more detail about feature skew detection.</p> <p>Initializes the feature skew detection PTransform.</p> <p>identifier_features: Names of features to use as identifiers.   features_to_ignore: Names of features for which no feature skew detection     is done.   sample_size: Size of the sample of training-serving example pairs that     exhibit skew to include in the skew results.   float_round_ndigits: Number of digits precision after the decimal point to     which to round float values before comparing them.   allow_duplicate_identifiers: If set, skew detection will be done on     examples for which there are duplicate identifier feature values. In     this case, the counts in the FeatureSkew result are based on each     training-serving example pair analyzed. Examples with given identifier     feature values must all fit in memory.</p> Source code in <code>tensorflow_data_validation/api/validation_api.py</code> <pre><code>def __init__(\n    self,\n    identifier_features: List[types.FeatureName],\n    features_to_ignore: Optional[List[types.FeatureName]] = None,\n    sample_size: int = 0,\n    float_round_ndigits: Optional[int] = None,\n    allow_duplicate_identifiers: bool = False,\n) -&gt; None:\n    \"\"\"Initializes the feature skew detection PTransform.\n\n    Args:\n    ----\n      identifier_features: Names of features to use as identifiers.\n      features_to_ignore: Names of features for which no feature skew detection\n        is done.\n      sample_size: Size of the sample of training-serving example pairs that\n        exhibit skew to include in the skew results.\n      float_round_ndigits: Number of digits precision after the decimal point to\n        which to round float values before comparing them.\n      allow_duplicate_identifiers: If set, skew detection will be done on\n        examples for which there are duplicate identifier feature values. In\n        this case, the counts in the FeatureSkew result are based on each\n        training-serving example pair analyzed. Examples with given identifier\n        feature values must all fit in memory.\n    \"\"\"\n    self._identifier_features = identifier_features\n    self._features_to_ignore = features_to_ignore\n    self._sample_size = sample_size\n    self._float_round_ndigits = float_round_ndigits\n    self._allow_duplicate_identifiers = allow_duplicate_identifiers\n</code></pre>"},{"location":"api/#tensorflow_data_validation.DetectFeatureSkew-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.DetectFeatureSkew.expand","title":"expand","text":"<pre><code>expand(\n    datasets: Tuple[PCollection, PCollection],\n) -&gt; Tuple[PCollection, PCollection]\n</code></pre> Source code in <code>tensorflow_data_validation/api/validation_api.py</code> <pre><code>def expand(\n    self, datasets: Tuple[beam.pvalue.PCollection, beam.pvalue.PCollection]\n) -&gt; Tuple[beam.pvalue.PCollection, beam.pvalue.PCollection]:\n    result = (\n        datasets\n        | \"DetectFeatureSkew\"\n        &gt;&gt; feature_skew_detector.DetectFeatureSkewImpl(\n            self._identifier_features,\n            self._features_to_ignore,\n            self._sample_size,\n            self._float_round_ndigits,\n            self._allow_duplicate_identifiers,\n        )\n    )\n    return result[feature_skew_detector.SKEW_RESULTS_KEY], result[\n        feature_skew_detector.SKEW_PAIRS_KEY\n    ]\n</code></pre>"},{"location":"api/#tensorflow_data_validation.FeatureView","title":"FeatureView","text":"<pre><code>FeatureView(stats_proto: FeatureNameStatistics)\n</code></pre> <p>View of a single feature.</p> <p>This class provides accessor methods, as well as access to the underlying proto. Where possible, accessors should be used in place of proto access (for example, x.numeric_statistics() instead of x.proto().num_stats) in order to support future extension of the proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def __init__(self, stats_proto: statistics_pb2.FeatureNameStatistics):\n    self._statistics = stats_proto\n</code></pre>"},{"location":"api/#tensorflow_data_validation.FeatureView-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.FeatureView.bytes_statistics","title":"bytes_statistics","text":"<pre><code>bytes_statistics() -&gt; Optional[BytesStatistics]\n</code></pre> <p>Retrieve byte statistics if available.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def bytes_statistics(self) -&gt; Optional[statistics_pb2.BytesStatistics]:\n    \"\"\"Retrieve byte statistics if available.\"\"\"\n    if self._statistics.WhichOneof(\"stats\") == \"bytes_stats\":\n        return self._statistics.bytes_stats\n    return None\n</code></pre>"},{"location":"api/#tensorflow_data_validation.FeatureView.common_statistics","title":"common_statistics","text":"<pre><code>common_statistics() -&gt; Optional[CommonStatistics]\n</code></pre> <p>Retrieve common statistics if available.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def common_statistics(self) -&gt; Optional[statistics_pb2.CommonStatistics]:\n    \"\"\"Retrieve common statistics if available.\"\"\"\n    which = self._statistics.WhichOneof(\"stats\")\n    if which == \"num_stats\":\n        return self._statistics.num_stats.common_stats\n    if which == \"string_stats\":\n        return self._statistics.string_stats.common_stats\n    if which == \"bytes_stats\":\n        return self._statistics.bytes_stats.common_stats\n    if which == \"struct_stats\":\n        return self._statistics.struct_stats.common_stats\n    return None\n</code></pre>"},{"location":"api/#tensorflow_data_validation.FeatureView.custom_statistic","title":"custom_statistic","text":"<pre><code>custom_statistic(name: str) -&gt; Optional[CustomStatistic]\n</code></pre> <p>Retrieve a custom_statistic by name.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def custom_statistic(self, name: str) -&gt; Optional[statistics_pb2.CustomStatistic]:\n    \"\"\"Retrieve a custom_statistic by name.\"\"\"\n    result = None\n    for stat in self._statistics.custom_stats:\n        if stat.name == name:\n            if result is None:\n                result = stat\n            else:\n                raise ValueError(\"Duplicate custom_stats for name %s\" % name)\n    return result\n</code></pre>"},{"location":"api/#tensorflow_data_validation.FeatureView.numeric_statistics","title":"numeric_statistics","text":"<pre><code>numeric_statistics() -&gt; Optional[NumericStatistics]\n</code></pre> <p>Retrieve numeric statistics if available.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def numeric_statistics(self) -&gt; Optional[statistics_pb2.NumericStatistics]:\n    \"\"\"Retrieve numeric statistics if available.\"\"\"\n    if self._statistics.WhichOneof(\"stats\") == \"num_stats\":\n        return self._statistics.num_stats\n    return None\n</code></pre>"},{"location":"api/#tensorflow_data_validation.FeatureView.proto","title":"proto","text":"<pre><code>proto() -&gt; FeatureNameStatistics\n</code></pre> <p>Retrieve the underlying proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def proto(self) -&gt; statistics_pb2.FeatureNameStatistics:\n    \"\"\"Retrieve the underlying proto.\"\"\"\n    return self._statistics\n</code></pre>"},{"location":"api/#tensorflow_data_validation.FeatureView.string_statistics","title":"string_statistics","text":"<pre><code>string_statistics() -&gt; Optional[StringStatistics]\n</code></pre> <p>Retrieve string statistics if available.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def string_statistics(self) -&gt; Optional[statistics_pb2.StringStatistics]:\n    \"\"\"Retrieve string statistics if available.\"\"\"\n    if self._statistics.WhichOneof(\"stats\") == \"string_stats\":\n        return self._statistics.string_stats\n    return None\n</code></pre>"},{"location":"api/#tensorflow_data_validation.FeatureView.struct_statistics","title":"struct_statistics","text":"<pre><code>struct_statistics() -&gt; Optional[StructStatistics]\n</code></pre> <p>Retrieve struct statistics if available.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def struct_statistics(self) -&gt; Optional[statistics_pb2.StructStatistics]:\n    \"\"\"Retrieve struct statistics if available.\"\"\"\n    if self._statistics.WhichOneof(\"stats\") == \"struct_stats\":\n        return self._statistics.struct_stats\n    return None\n</code></pre>"},{"location":"api/#tensorflow_data_validation.GenerateStatistics","title":"GenerateStatistics","text":"<pre><code>GenerateStatistics(options: StatsOptions = StatsOptions())\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>API for generating data statistics.</p>"},{"location":"api/#tensorflow_data_validation.GenerateStatistics--example","title":"Example:","text":"<pre><code>  with beam.Pipeline(runner=...) as p:\n    _ = (p\n         | 'ReadData' &gt;&gt; tfx_bsl.public.tfxio.TFExampleRecord(data_location)\n             .BeamSource()\n         | 'GenerateStatistics' &gt;&gt; GenerateStatistics()\n         | 'WriteStatsOutput' &gt;&gt; tfdv.WriteStatisticsToTFRecord(output_path))\n</code></pre> <p>Initializes the transform.</p> <p>options: <code>tfdv.StatsOptions</code> for generating data statistics.</p> <p>TypeError: If options is not of the expected type.</p> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def __init__(\n    self, options: stats_options.StatsOptions = stats_options.StatsOptions()\n) -&gt; None:\n    \"\"\"Initializes the transform.\n\n    Args:\n    ----\n      options: `tfdv.StatsOptions` for generating data statistics.\n\n    Raises:\n    ------\n      TypeError: If options is not of the expected type.\n    \"\"\"\n    if not isinstance(options, stats_options.StatsOptions):\n        raise TypeError(\n            \"options is of type %s, should be a StatsOptions.\"\n            % type(options).__name__\n        )\n    self._options = options\n</code></pre>"},{"location":"api/#tensorflow_data_validation.GenerateStatistics-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.GenerateStatistics.expand","title":"expand","text":"<pre><code>expand(\n    dataset: PCollection[RecordBatch],\n) -&gt; PCollection[DatasetFeatureStatisticsList]\n</code></pre> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def expand(\n    self, dataset: beam.PCollection[pa.RecordBatch]\n) -&gt; beam.PCollection[statistics_pb2.DatasetFeatureStatisticsList]:\n    if self._options.sample_rate is not None:\n        dataset |= (\n            \"SampleExamplesAtRate(%s)\" % self._options.sample_rate\n            &gt;&gt; beam.FlatMap(_sample_at_rate, sample_rate=self._options.sample_rate)\n        )\n\n    return dataset | \"RunStatsGenerators\" &gt;&gt; stats_impl.GenerateStatisticsImpl(\n        self._options\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation.MergeDatasetFeatureStatisticsList","title":"MergeDatasetFeatureStatisticsList","text":"<p>               Bases: <code>PTransform</code></p> <p>API for merging sharded DatasetFeatureStatisticsList.</p>"},{"location":"api/#tensorflow_data_validation.MergeDatasetFeatureStatisticsList-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.MergeDatasetFeatureStatisticsList.expand","title":"expand","text":"<pre><code>expand(stats: PCollection)\n</code></pre> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def expand(self, stats: beam.PCollection):\n    return stats | \"MergeDatasetFeatureStatisticsProtos\" &gt;&gt; beam.CombineGlobally(\n        merge_util.merge_dataset_feature_statistics_list\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions","title":"StatsOptions","text":"<pre><code>StatsOptions(\n    generators: Optional[List[StatsGenerator]] = None,\n    schema: Optional[Schema] = None,\n    label_feature: Optional[FeatureName] = None,\n    weight_feature: Optional[FeatureName] = None,\n    slice_functions: Optional[List[SliceFunction]] = None,\n    sample_rate: Optional[float] = None,\n    num_top_values: int = 20,\n    frequency_threshold: int = 1,\n    weighted_frequency_threshold: float = 1.0,\n    num_rank_histogram_buckets: int = 1000,\n    num_values_histogram_buckets: int = 10,\n    num_histogram_buckets: int = 10,\n    num_quantiles_histogram_buckets: int = 10,\n    epsilon: float = 0.01,\n    infer_type_from_schema: bool = False,\n    desired_batch_size: Optional[int] = None,\n    enable_semantic_domain_stats: bool = False,\n    semantic_domain_stats_sample_rate: Optional[\n        float\n    ] = None,\n    per_feature_weight_override: Optional[\n        Dict[FeaturePath, FeatureName]\n    ] = None,\n    vocab_paths: Optional[\n        Dict[VocabName, VocabPath]\n    ] = None,\n    add_default_generators: bool = True,\n    feature_allowlist: Optional[\n        Union[List[FeatureName], List[FeaturePath]]\n    ] = None,\n    experimental_use_sketch_based_topk_uniques: Optional[\n        bool\n    ] = None,\n    use_sketch_based_topk_uniques: Optional[bool] = None,\n    experimental_slice_functions: Optional[\n        List[SliceFunction]\n    ] = None,\n    experimental_result_partitions: int = 1,\n    experimental_num_feature_partitions: int = 1,\n    slicing_config: Optional[SlicingConfig] = None,\n    experimental_filter_read_paths: bool = False,\n    per_feature_stats_config: Optional[\n        PerFeatureStatsConfig\n    ] = None,\n)\n</code></pre> <p>Options for generating statistics.</p> <p>Initializes statistics options.</p> <p>generators: An optional list of statistics generators. A statistics     generator must extend either CombinerStatsGenerator or     TransformStatsGenerator.   schema: An optional tensorflow_metadata Schema proto. Currently we use the     schema to infer categorical and bytes features.   label_feature: An optional feature name which represents the label.   weight_feature: An optional feature name whose numeric value represents     the weight of an example.   slice_functions: DEPRECATED. Use <code>experimental_slice_functions</code>.   sample_rate: An optional sampling rate. If specified, statistics is     computed over the sample.   num_top_values: An optional number of most frequent feature values to keep     for string features.   frequency_threshold: An optional minimum number of examples the most     frequent values must be present in.   weighted_frequency_threshold: An optional minimum weighted number of     examples the most frequent weighted values must be present in. This     option is only relevant when a weight_feature is specified.   num_rank_histogram_buckets: An optional number of buckets in the rank     histogram for string features.   num_values_histogram_buckets: An optional number of buckets in a quantiles     histogram for the number of values per Feature, which is stored in     CommonStatistics.num_values_histogram.   num_histogram_buckets: An optional number of buckets in a standard     NumericStatistics.histogram with equal-width buckets.   num_quantiles_histogram_buckets: An optional number of buckets in a     quantiles NumericStatistics.histogram.   epsilon: An optional error tolerance for the computation of quantiles,     typically a small fraction close to zero (e.g. 0.01). Higher values of     epsilon increase the quantile approximation, and hence result in more     unequal buckets, but could improve performance, and resource     consumption.   infer_type_from_schema: A boolean to indicate whether the feature types     should be inferred from the schema. If set to True, an input schema must     be provided. This flag is used only when invoking TFDV through     <code>tfdv.generate_statistics_from_csv</code>.   desired_batch_size: An optional maximum number of examples to include in     each batch that is passed to the statistics generators. When invoking     TFDV using its end-to-end APIs (e.g.     <code>generate_statistics_from_tfrecord</code>), this option also controls the     decoder batch size -- if provided, the decoded RecordBatches that are to     be fed to TFDV will have the fixed batch size. When invoking TFDV using     <code>tfdv.GenerateStatistics</code>, this option only controls the maximum size of     RecordBatches constructed within StatsGenerators (a generator may     combine RecordBatches).   enable_semantic_domain_stats: If True statistics for semantic domains are     generated (e.g: image, text domains).   semantic_domain_stats_sample_rate: An optional sampling rate for semantic     domain statistics. If specified, semantic domain statistics is computed     over a sample.   per_feature_weight_override: If specified, the \"example weight\" paired     with a feature will be first looked up in this map and if not found,     fall back to <code>weight_feature</code>.   vocab_paths: An optional dictionary mapping vocab names to paths. Used in     the schema when specifying a NaturalLanguageDomain. The paths can either     be to GZIP-compressed TF record files that have a tfrecord.gz suffix or     to text files.   add_default_generators: Whether to invoke the default set of stats     generators in the run. Generators invoked consists of 1) the default     generators (controlled by this option); 2) user-provided generators (     controlled by the <code>generators</code> option); 3) semantic generators     (controlled by <code>enable_semantic_domain_stats</code>) and 4) schema-based     generators that are enabled based on information provided in the schema.   feature_allowlist: An optional list of names of the features to calculate     statistics for, or a list of paths.   experimental_use_sketch_based_topk_uniques: Deprecated, prefer     use_sketch_based_topk_uniques.   use_sketch_based_topk_uniques: if True, use the sketch based top-k and     uniques stats generator.   experimental_slice_functions: An optional list of functions that generate     slice keys for each example. Each slice function should take     pyarrow.RecordBatch as input and return an Iterable[Tuple[Text,     pyarrow.RecordBatch]]. Each tuple contains the slice key and the     corresponding sliced RecordBatch. Only one of     experimental_slice_functions must be     specified.   experimental_result_partitions: The number of feature partitions to     combine output DatasetFeatureStatisticsLists into. If set to 1 (default)     output is globally combined. If set to value greater than one, up to     that many shards are returned, each containing a subset of features.   experimental_num_feature_partitions: If &gt; 1, partitions computations by     supported generators to act on this many bundles of features. For best     results this should be set to at least several times less than the     number of features in a dataset, and never more than the available beam     parallelism.   slicing_config: an optional SlicingConfig. SlicingConfig includes     slicing_specs specified with feature keys or feature values     queries.   experimental_filter_read_paths: If provided, tries to push down either     paths passed via feature_allowlist or via the schema (in that priority)     to the underlying read operation. Support depends on the file reader.   per_feature_stats_config: Supports granular control of what statistics are     enabled per feature. Experimental.</p> Source code in <code>tensorflow_data_validation/statistics/stats_options.py</code> <pre><code>def __init__(\n    self,\n    generators: Optional[List[stats_generator.StatsGenerator]] = None,\n    schema: Optional[schema_pb2.Schema] = None,\n    label_feature: Optional[types.FeatureName] = None,\n    weight_feature: Optional[types.FeatureName] = None,\n    slice_functions: Optional[List[types.SliceFunction]] = None,\n    sample_rate: Optional[float] = None,\n    num_top_values: int = 20,\n    frequency_threshold: int = 1,\n    weighted_frequency_threshold: float = 1.0,\n    num_rank_histogram_buckets: int = 1000,\n    num_values_histogram_buckets: int = 10,\n    num_histogram_buckets: int = 10,\n    num_quantiles_histogram_buckets: int = 10,\n    epsilon: float = 0.01,\n    infer_type_from_schema: bool = False,\n    desired_batch_size: Optional[int] = None,\n    enable_semantic_domain_stats: bool = False,\n    semantic_domain_stats_sample_rate: Optional[float] = None,\n    per_feature_weight_override: Optional[\n        Dict[types.FeaturePath, types.FeatureName]\n    ] = None,\n    vocab_paths: Optional[Dict[types.VocabName, types.VocabPath]] = None,\n    add_default_generators: bool = True,\n    # TODO(b/255895499): Support \"from schema\" for feature_allowlist.\n    feature_allowlist: Optional[\n        Union[List[types.FeatureName], List[types.FeaturePath]]\n    ] = None,\n    experimental_use_sketch_based_topk_uniques: Optional[bool] = None,\n    use_sketch_based_topk_uniques: Optional[bool] = None,\n    experimental_slice_functions: Optional[List[types.SliceFunction]] = None,\n    experimental_result_partitions: int = 1,\n    experimental_num_feature_partitions: int = 1,\n    slicing_config: Optional[slicing_spec_pb2.SlicingConfig] = None,\n    experimental_filter_read_paths: bool = False,\n    per_feature_stats_config: Optional[types.PerFeatureStatsConfig] = None,\n):\n    \"\"\"Initializes statistics options.\n\n    Args:\n    ----\n      generators: An optional list of statistics generators. A statistics\n        generator must extend either CombinerStatsGenerator or\n        TransformStatsGenerator.\n      schema: An optional tensorflow_metadata Schema proto. Currently we use the\n        schema to infer categorical and bytes features.\n      label_feature: An optional feature name which represents the label.\n      weight_feature: An optional feature name whose numeric value represents\n        the weight of an example.\n      slice_functions: DEPRECATED. Use `experimental_slice_functions`.\n      sample_rate: An optional sampling rate. If specified, statistics is\n        computed over the sample.\n      num_top_values: An optional number of most frequent feature values to keep\n        for string features.\n      frequency_threshold: An optional minimum number of examples the most\n        frequent values must be present in.\n      weighted_frequency_threshold: An optional minimum weighted number of\n        examples the most frequent weighted values must be present in. This\n        option is only relevant when a weight_feature is specified.\n      num_rank_histogram_buckets: An optional number of buckets in the rank\n        histogram for string features.\n      num_values_histogram_buckets: An optional number of buckets in a quantiles\n        histogram for the number of values per Feature, which is stored in\n        CommonStatistics.num_values_histogram.\n      num_histogram_buckets: An optional number of buckets in a standard\n        NumericStatistics.histogram with equal-width buckets.\n      num_quantiles_histogram_buckets: An optional number of buckets in a\n        quantiles NumericStatistics.histogram.\n      epsilon: An optional error tolerance for the computation of quantiles,\n        typically a small fraction close to zero (e.g. 0.01). Higher values of\n        epsilon increase the quantile approximation, and hence result in more\n        unequal buckets, but could improve performance, and resource\n        consumption.\n      infer_type_from_schema: A boolean to indicate whether the feature types\n        should be inferred from the schema. If set to True, an input schema must\n        be provided. This flag is used only when invoking TFDV through\n        `tfdv.generate_statistics_from_csv`.\n      desired_batch_size: An optional maximum number of examples to include in\n        each batch that is passed to the statistics generators. When invoking\n        TFDV using its end-to-end APIs (e.g.\n        `generate_statistics_from_tfrecord`), this option also controls the\n        decoder batch size -- if provided, the decoded RecordBatches that are to\n        be fed to TFDV will have the fixed batch size. When invoking TFDV using\n        `tfdv.GenerateStatistics`, this option only controls the maximum size of\n        RecordBatches constructed within StatsGenerators (a generator may\n        combine RecordBatches).\n      enable_semantic_domain_stats: If True statistics for semantic domains are\n        generated (e.g: image, text domains).\n      semantic_domain_stats_sample_rate: An optional sampling rate for semantic\n        domain statistics. If specified, semantic domain statistics is computed\n        over a sample.\n      per_feature_weight_override: If specified, the \"example weight\" paired\n        with a feature will be first looked up in this map and if not found,\n        fall back to `weight_feature`.\n      vocab_paths: An optional dictionary mapping vocab names to paths. Used in\n        the schema when specifying a NaturalLanguageDomain. The paths can either\n        be to GZIP-compressed TF record files that have a tfrecord.gz suffix or\n        to text files.\n      add_default_generators: Whether to invoke the default set of stats\n        generators in the run. Generators invoked consists of 1) the default\n        generators (controlled by this option); 2) user-provided generators (\n        controlled by the `generators` option); 3) semantic generators\n        (controlled by `enable_semantic_domain_stats`) and 4) schema-based\n        generators that are enabled based on information provided in the schema.\n      feature_allowlist: An optional list of names of the features to calculate\n        statistics for, or a list of paths.\n      experimental_use_sketch_based_topk_uniques: Deprecated, prefer\n        use_sketch_based_topk_uniques.\n      use_sketch_based_topk_uniques: if True, use the sketch based top-k and\n        uniques stats generator.\n      experimental_slice_functions: An optional list of functions that generate\n        slice keys for each example. Each slice function should take\n        pyarrow.RecordBatch as input and return an Iterable[Tuple[Text,\n        pyarrow.RecordBatch]]. Each tuple contains the slice key and the\n        corresponding sliced RecordBatch. Only one of\n        experimental_slice_functions must be\n        specified.\n      experimental_result_partitions: The number of feature partitions to\n        combine output DatasetFeatureStatisticsLists into. If set to 1 (default)\n        output is globally combined. If set to value greater than one, up to\n        that many shards are returned, each containing a subset of features.\n      experimental_num_feature_partitions: If &gt; 1, partitions computations by\n        supported generators to act on this many bundles of features. For best\n        results this should be set to at least several times less than the\n        number of features in a dataset, and never more than the available beam\n        parallelism.\n      slicing_config: an optional SlicingConfig. SlicingConfig includes\n        slicing_specs specified with feature keys or feature values\n        queries.\n      experimental_filter_read_paths: If provided, tries to push down either\n        paths passed via feature_allowlist or via the schema (in that priority)\n        to the underlying read operation. Support depends on the file reader.\n      per_feature_stats_config: Supports granular control of what statistics are\n        enabled per feature. Experimental.\n    \"\"\"\n    self.generators = generators\n    self.feature_allowlist = feature_allowlist\n    self.schema = schema\n    self.label_feature = label_feature\n    self.weight_feature = weight_feature\n    if slice_functions is not None and experimental_slice_functions is not None:\n        raise ValueError(\n            \"Specify only one of slice_functions or experimental_slice_functions\"\n        )\n    self.experimental_slice_functions = None\n    if slice_functions is not None:\n        self.experimental_slice_functions = slice_functions\n    elif experimental_slice_functions is not None:\n        self.experimental_slice_functions = experimental_slice_functions\n    self.sample_rate = sample_rate\n    self.num_top_values = num_top_values\n    self.frequency_threshold = frequency_threshold\n    self.weighted_frequency_threshold = weighted_frequency_threshold\n    self.num_rank_histogram_buckets = num_rank_histogram_buckets\n    self.num_values_histogram_buckets = num_values_histogram_buckets\n    self.num_histogram_buckets = num_histogram_buckets\n    self.num_quantiles_histogram_buckets = num_quantiles_histogram_buckets\n    self.epsilon = epsilon\n    self.infer_type_from_schema = infer_type_from_schema\n    self.desired_batch_size = desired_batch_size\n    self.enable_semantic_domain_stats = enable_semantic_domain_stats\n    self.semantic_domain_stats_sample_rate = semantic_domain_stats_sample_rate\n    self._per_feature_weight_override = per_feature_weight_override\n    self.vocab_paths = vocab_paths\n    self.add_default_generators = add_default_generators\n    if (\n        use_sketch_based_topk_uniques is not None\n        and experimental_use_sketch_based_topk_uniques is not None\n    ):\n        raise ValueError(\n            \"Must set at most one of use_sketch_based_topk_uniques and\"\n            \" experimental_use_sketch_based_topk_uniques\"\n        )\n    # TODO(b/239609486): Change the None default to True.\n    if experimental_use_sketch_based_topk_uniques or use_sketch_based_topk_uniques:\n        self.use_sketch_based_topk_uniques = True\n    else:\n        self.use_sketch_based_topk_uniques = False\n    self.experimental_num_feature_partitions = experimental_num_feature_partitions\n    self.experimental_result_partitions = experimental_result_partitions\n    self.slicing_config = slicing_config\n    self.experimental_filter_read_paths = experimental_filter_read_paths\n    self.per_feature_stats_config = per_feature_stats_config\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions-attributes","title":"Attributes","text":""},{"location":"api/#tensorflow_data_validation.StatsOptions.add_default_generators","title":"add_default_generators  <code>property</code> <code>writable</code>","text":"<pre><code>add_default_generators: bool\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.desired_batch_size","title":"desired_batch_size  <code>property</code> <code>writable</code>","text":"<pre><code>desired_batch_size: Optional[int]\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.enable_semantic_domain_stats","title":"enable_semantic_domain_stats  <code>instance-attribute</code>","text":"<pre><code>enable_semantic_domain_stats = enable_semantic_domain_stats\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.epsilon","title":"epsilon  <code>instance-attribute</code>","text":"<pre><code>epsilon = epsilon\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.example_weight_map","title":"example_weight_map  <code>property</code>","text":"<pre><code>example_weight_map\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.experimental_filter_read_paths","title":"experimental_filter_read_paths  <code>property</code> <code>writable</code>","text":"<pre><code>experimental_filter_read_paths: bool\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.experimental_num_feature_partitions","title":"experimental_num_feature_partitions  <code>property</code> <code>writable</code>","text":"<pre><code>experimental_num_feature_partitions: int\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.experimental_result_partitions","title":"experimental_result_partitions  <code>property</code> <code>writable</code>","text":"<pre><code>experimental_result_partitions: int\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.experimental_slice_functions","title":"experimental_slice_functions  <code>property</code> <code>writable</code>","text":"<pre><code>experimental_slice_functions: Optional[List[SliceFunction]]\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.experimental_use_sketch_based_topk_uniques","title":"experimental_use_sketch_based_topk_uniques  <code>property</code> <code>writable</code>","text":"<pre><code>experimental_use_sketch_based_topk_uniques: bool\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.feature_allowlist","title":"feature_allowlist  <code>property</code> <code>writable</code>","text":"<pre><code>feature_allowlist: Optional[\n    Union[List[FeatureName], List[FeaturePath]]\n]\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.frequency_threshold","title":"frequency_threshold  <code>instance-attribute</code>","text":"<pre><code>frequency_threshold = frequency_threshold\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.generators","title":"generators  <code>property</code> <code>writable</code>","text":"<pre><code>generators: Optional[List[StatsGenerator]]\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.infer_type_from_schema","title":"infer_type_from_schema  <code>instance-attribute</code>","text":"<pre><code>infer_type_from_schema = infer_type_from_schema\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.label_feature","title":"label_feature  <code>instance-attribute</code>","text":"<pre><code>label_feature = label_feature\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.num_histogram_buckets","title":"num_histogram_buckets  <code>property</code> <code>writable</code>","text":"<pre><code>num_histogram_buckets: int\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.num_quantiles_histogram_buckets","title":"num_quantiles_histogram_buckets  <code>property</code> <code>writable</code>","text":"<pre><code>num_quantiles_histogram_buckets: int\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.num_rank_histogram_buckets","title":"num_rank_histogram_buckets  <code>instance-attribute</code>","text":"<pre><code>num_rank_histogram_buckets = num_rank_histogram_buckets\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.num_top_values","title":"num_top_values  <code>instance-attribute</code>","text":"<pre><code>num_top_values = num_top_values\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.num_values_histogram_buckets","title":"num_values_histogram_buckets  <code>property</code> <code>writable</code>","text":"<pre><code>num_values_histogram_buckets: int\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.per_feature_stats_config","title":"per_feature_stats_config  <code>property</code> <code>writable</code>","text":"<pre><code>per_feature_stats_config: PerFeatureStatsConfig\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.sample_rate","title":"sample_rate  <code>property</code> <code>writable</code>","text":"<pre><code>sample_rate: Optional[float]\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.schema","title":"schema  <code>property</code> <code>writable</code>","text":"<pre><code>schema: Optional[Schema]\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.semantic_domain_stats_sample_rate","title":"semantic_domain_stats_sample_rate  <code>property</code> <code>writable</code>","text":"<pre><code>semantic_domain_stats_sample_rate: Optional[float]\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.slicing_config","title":"slicing_config  <code>property</code> <code>writable</code>","text":"<pre><code>slicing_config: Optional[SlicingConfig]\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.use_sketch_based_topk_uniques","title":"use_sketch_based_topk_uniques  <code>property</code> <code>writable</code>","text":"<pre><code>use_sketch_based_topk_uniques: bool\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.vocab_paths","title":"vocab_paths  <code>property</code> <code>writable</code>","text":"<pre><code>vocab_paths: Optional[Dict[VocabName, VocabPath]]\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.weight_feature","title":"weight_feature  <code>instance-attribute</code>","text":"<pre><code>weight_feature = weight_feature\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.weighted_frequency_threshold","title":"weighted_frequency_threshold  <code>instance-attribute</code>","text":"<pre><code>weighted_frequency_threshold = weighted_frequency_threshold\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.StatsOptions.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(options_json: str) -&gt; StatsOptions\n</code></pre> <p>Construct an instance of stats options from a JSON representation.</p> <p>options_json: A JSON representation of the dict attribute of a     StatsOptions instance.</p> <p>A StatsOptions instance constructed by setting the dict attribute to   the deserialized value of options_json.</p> Source code in <code>tensorflow_data_validation/statistics/stats_options.py</code> <pre><code>@classmethod\ndef from_json(cls, options_json: str) -&gt; \"StatsOptions\":\n    \"\"\"Construct an instance of stats options from a JSON representation.\n\n    Args:\n    ----\n      options_json: A JSON representation of the __dict__ attribute of a\n        StatsOptions instance.\n\n    Returns:\n    -------\n      A StatsOptions instance constructed by setting the __dict__ attribute to\n      the deserialized value of options_json.\n    \"\"\"\n    options_dict = json.loads(options_json)\n    type_name = options_dict.pop(_TYPE_NAME_KEY, None)\n    if type_name is not None and type_name != \"StatsOptions\":\n        raise ValueError(\"JSON does not encode a StatsOptions\")\n    if _SCHEMA_JSON_KEY in options_dict:\n        options_dict[\"_schema\"] = json_format.Parse(\n            options_dict[_SCHEMA_JSON_KEY], schema_pb2.Schema()\n        )\n        del options_dict[_SCHEMA_JSON_KEY]\n    if _SLICING_CONFIG_JSON_KEY in options_dict:\n        options_dict[\"_slicing_config\"] = json_format.Parse(\n            options_dict[_SLICING_CONFIG_JSON_KEY], slicing_spec_pb2.SlicingConfig()\n        )\n        del options_dict[_SLICING_CONFIG_JSON_KEY]\n    per_feature_weight_override_json = options_dict.get(\n        _PER_FEATURE_WEIGHT_OVERRIDE_JSON_KEY\n    )\n    if per_feature_weight_override_json is not None:\n        options_dict[\"_per_feature_weight_override\"] = {\n            types.FeaturePath.from_json(k): v\n            for k, v in per_feature_weight_override_json.items()\n        }\n        del options_dict[_PER_FEATURE_WEIGHT_OVERRIDE_JSON_KEY]\n    options = cls()\n    options.__dict__ = options_dict\n    return options\n</code></pre>"},{"location":"api/#tensorflow_data_validation.StatsOptions.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Convert from an object to JSON representation of the dict attribute.</p> <p>Custom generators and slice_functions cannot being converted. As a result, a ValueError will be raised when these options are specified and TFDV is running in a setting where the stats options have been json-serialized, first. This will happen in the case where TFDV is run as a TFX component. The schema proto and slicing_config will be json_encoded.</p>"},{"location":"api/#tensorflow_data_validation.StatsOptions.to_json--returns","title":"Returns","text":"<p>A JSON representation of a filtered version of dict.</p> Source code in <code>tensorflow_data_validation/statistics/stats_options.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Convert from an object to JSON representation of the __dict__ attribute.\n\n    Custom generators and slice_functions cannot being converted. As a result,\n    a ValueError will be raised when these options are specified and TFDV is\n    running in a setting where the stats options have been json-serialized,\n    first. This will happen in the case where TFDV is run as a TFX component.\n    The schema proto and slicing_config will be json_encoded.\n\n    Returns\n    -------\n      A JSON representation of a filtered version of __dict__.\n    \"\"\"\n    options_dict = copy.copy(self.__dict__)\n    options_dict[_TYPE_NAME_KEY] = \"StatsOptions\"\n    if options_dict[\"_slice_functions\"] is not None:\n        raise ValueError(\n            \"StatsOptions cannot be converted with experimental_slice_functions.\"\n        )\n    if options_dict[\"_generators\"] is not None:\n        raise ValueError(\"StatsOptions cannot be converted with generators.\")\n    if self.schema is not None:\n        del options_dict[\"_schema\"]\n        options_dict[_SCHEMA_JSON_KEY] = json_format.MessageToJson(self.schema)\n    if self.slicing_config is not None:\n        del options_dict[\"_slicing_config\"]\n        options_dict[_SLICING_CONFIG_JSON_KEY] = json_format.MessageToJson(\n            self.slicing_config\n        )\n    if self._per_feature_weight_override is not None:\n        del options_dict[\"_per_feature_weight_override\"]\n        options_dict[_PER_FEATURE_WEIGHT_OVERRIDE_JSON_KEY] = {\n            k.to_json(): v for k, v in self._per_feature_weight_override.items()\n        }\n    if self._per_feature_stats_config is not None:\n        raise ValueError(\n            \"StatsOptions cannot be converted with per_feature_stats_config.\"\n        )\n    return json.dumps(options_dict)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.TransformStatsGenerator","title":"TransformStatsGenerator","text":"<pre><code>TransformStatsGenerator(\n    name: str,\n    ptransform: PTransform,\n    schema: Optional[Schema] = None,\n)\n</code></pre> <p>               Bases: <code>StatsGenerator</code></p> <p>A StatsGenerator which wraps an arbitrary Beam PTransform.</p> <p>This class computes statistics using a user-provided Beam PTransform. The PTransform must accept a Beam PCollection where each element is a tuple containing a slice key and an Arrow RecordBatch representing a batch of examples. It must return a PCollection where each element is a tuple containing a slice key and a DatasetFeatureStatistics proto representing the statistics of a slice.</p> <p>Initializes a statistics generator.</p> <p>name: A unique name associated with the statistics generator.   schema: An optional schema for the dataset.</p> Source code in <code>tensorflow_data_validation/statistics/generators/stats_generator.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    ptransform: beam.PTransform,\n    schema: Optional[schema_pb2.Schema] = None,\n) -&gt; None:\n    self._ptransform = ptransform\n    super(TransformStatsGenerator, self).__init__(name, schema)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.TransformStatsGenerator-attributes","title":"Attributes","text":""},{"location":"api/#tensorflow_data_validation.TransformStatsGenerator.name","title":"name  <code>property</code>","text":"<pre><code>name\n</code></pre>"},{"location":"api/#tensorflow_data_validation.TransformStatsGenerator.ptransform","title":"ptransform  <code>property</code>","text":"<pre><code>ptransform\n</code></pre>"},{"location":"api/#tensorflow_data_validation.TransformStatsGenerator.schema","title":"schema  <code>property</code>","text":"<pre><code>schema\n</code></pre>"},{"location":"api/#tensorflow_data_validation.TransformStatsGenerator-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.WriteStatisticsToBinaryFile","title":"WriteStatisticsToBinaryFile","text":"<pre><code>WriteStatisticsToBinaryFile(output_path: str)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>API for writing serialized data statistics to a binary file.</p> <p>Initializes the transform.</p> <p>output_path: Output path for writing data statistics.</p> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def __init__(self, output_path: str) -&gt; None:\n    \"\"\"Initializes the transform.\n\n    Args:\n    ----\n      output_path: Output path for writing data statistics.\n    \"\"\"\n    self._output_path = output_path\n</code></pre>"},{"location":"api/#tensorflow_data_validation.WriteStatisticsToBinaryFile-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.WriteStatisticsToBinaryFile.expand","title":"expand","text":"<pre><code>expand(stats: PCollection) -&gt; PDone\n</code></pre> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def expand(self, stats: beam.PCollection) -&gt; beam.pvalue.PDone:\n    return stats | \"WriteStats\" &gt;&gt; beam.io.WriteToText(\n        self._output_path,\n        shard_name_template=\"\",\n        append_trailing_newlines=False,\n        coder=beam.coders.ProtoCoder(statistics_pb2.DatasetFeatureStatisticsList),\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation.WriteStatisticsToRecordsAndBinaryFile","title":"WriteStatisticsToRecordsAndBinaryFile","text":"<pre><code>WriteStatisticsToRecordsAndBinaryFile(\n    binary_proto_path: str,\n    records_path_prefix: str,\n    columnar_path_prefix: Optional[str] = None,\n)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>API for writing statistics to both sharded records and binary pb.</p> <p>This PTransform assumes that input represents sharded statistics, which are written directly. These statistics are also merged and written to a binary proto.</p> <p>Currently Experimental.</p> <p>TODO(b/202910677): After full migration to sharded stats, clean this up.</p> <p>Initializes the transform.</p> <p>binary_proto_path: Output path for writing statistics as a binary proto.   records_path_prefix: File pattern for writing statistics to sharded     records.   columnar_path_prefix: Optional file pattern for writing statistics to     columnar outputs. If provided, columnar outputs will be written when     supported.</p> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def __init__(\n    self,\n    binary_proto_path: str,\n    records_path_prefix: str,\n    columnar_path_prefix: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Initializes the transform.\n\n    Args:\n    ----\n      binary_proto_path: Output path for writing statistics as a binary proto.\n      records_path_prefix: File pattern for writing statistics to sharded\n        records.\n      columnar_path_prefix: Optional file pattern for writing statistics to\n        columnar outputs. If provided, columnar outputs will be written when\n        supported.\n    \"\"\"\n    self._binary_proto_path = binary_proto_path\n    self._records_path_prefix = records_path_prefix\n    self._io_provider = artifacts_io_impl.get_io_provider()\n    self._columnar_path_prefix = columnar_path_prefix\n</code></pre>"},{"location":"api/#tensorflow_data_validation.WriteStatisticsToRecordsAndBinaryFile-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.WriteStatisticsToRecordsAndBinaryFile.expand","title":"expand","text":"<pre><code>expand(stats: PCollection) -&gt; PDone\n</code></pre> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def expand(self, stats: beam.PCollection) -&gt; beam.pvalue.PDone:\n    # Write sharded outputs, ignoring PDone.\n    _ = stats | \"WriteShardedStats\" &gt;&gt; self._io_provider.record_sink_impl(\n        output_path_prefix=self._records_path_prefix\n    )\n    if self._columnar_path_prefix is not None:\n        columnar_provider = artifacts_io_impl.get_default_columnar_provider()\n        if columnar_provider is not None:\n            _ = stats | \"WriteColumnarStats\" &gt;&gt; columnar_provider.record_sink_impl(\n                self._columnar_path_prefix\n            )\n    return (\n        stats\n        | \"MergeDatasetFeatureStatisticsProtos\"\n        &gt;&gt; beam.CombineGlobally(merge_util.merge_dataset_feature_statistics_list)\n        | \"WriteBinaryStats\" &gt;&gt; WriteStatisticsToBinaryFile(self._binary_proto_path)\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation.WriteStatisticsToTFRecord","title":"WriteStatisticsToTFRecord","text":"<pre><code>WriteStatisticsToTFRecord(\n    output_path: str, sharded_output=False\n)\n</code></pre> <p>               Bases: <code>PTransform</code></p> <p>API for writing serialized data statistics to TFRecord file.</p> <p>Initializes the transform.</p> <p>output_path: The output path or path prefix (if sharded_output=True).   sharded_output: If true, writes sharded TFRecords files in the form     output_path-SSSSS-of-NNNNN.</p> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def __init__(self, output_path: str, sharded_output=False) -&gt; None:\n    \"\"\"Initializes the transform.\n\n    Args:\n    ----\n      output_path: The output path or path prefix (if sharded_output=True).\n      sharded_output: If true, writes sharded TFRecords files in the form\n        output_path-SSSSS-of-NNNNN.\n    \"\"\"\n    self._output_path = output_path\n    self._sharded_output = sharded_output\n</code></pre>"},{"location":"api/#tensorflow_data_validation.WriteStatisticsToTFRecord-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.WriteStatisticsToTFRecord.expand","title":"expand","text":"<pre><code>expand(stats: PCollection) -&gt; PDone\n</code></pre> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def expand(self, stats: beam.PCollection) -&gt; beam.pvalue.PDone:\n    return stats | \"WriteStats\" &gt;&gt; beam.io.WriteToTFRecord(\n        self._output_path,\n        shard_name_template=\"\" if not self._sharded_output else None,\n        coder=beam.coders.ProtoCoder(statistics_pb2.DatasetFeatureStatisticsList),\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation-functions","title":"Functions","text":""},{"location":"api/#tensorflow_data_validation.compare_slices","title":"compare_slices","text":"<pre><code>compare_slices(\n    statistics: DatasetFeatureStatisticsList,\n    lhs_slice_key: str,\n    rhs_slice_key: str,\n)\n</code></pre> <p>Compare statistics of two slices using Facets.</p> <p>statistics: A DatasetFeatureStatisticsList protocol buffer.   lhs_slice_key: Slice key of the first slice.   rhs_slice_key: Slice key of the second slice.</p> <p>ValueError: If the input statistics proto does not have the specified slice     statistics.</p> Source code in <code>tensorflow_data_validation/utils/display_util.py</code> <pre><code>def compare_slices(\n    statistics: statistics_pb2.DatasetFeatureStatisticsList,\n    lhs_slice_key: str,\n    rhs_slice_key: str,\n):\n    \"\"\"Compare statistics of two slices using Facets.\n\n    Args:\n    ----\n      statistics: A DatasetFeatureStatisticsList protocol buffer.\n      lhs_slice_key: Slice key of the first slice.\n      rhs_slice_key: Slice key of the second slice.\n\n    Raises:\n    ------\n      ValueError: If the input statistics proto does not have the specified slice\n        statistics.\n    \"\"\"\n    lhs_stats = stats_util.get_slice_stats(statistics, lhs_slice_key)\n    rhs_stats = stats_util.get_slice_stats(statistics, rhs_slice_key)\n    visualize_statistics(\n        lhs_stats, rhs_stats, lhs_name=lhs_slice_key, rhs_name=rhs_slice_key\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation.default_sharded_output_suffix","title":"default_sharded_output_suffix","text":"<pre><code>default_sharded_output_suffix() -&gt; str\n</code></pre> <p>Returns the default sharded output suffix.</p> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def default_sharded_output_suffix() -&gt; str:\n    \"\"\"Returns the default sharded output suffix.\"\"\"\n    return artifacts_io_impl.get_io_provider().file_suffix()\n</code></pre>"},{"location":"api/#tensorflow_data_validation.default_sharded_output_supported","title":"default_sharded_output_supported","text":"<pre><code>default_sharded_output_supported() -&gt; bool\n</code></pre> <p>True if sharded output is supported by default.</p> Source code in <code>tensorflow_data_validation/api/stats_api.py</code> <pre><code>def default_sharded_output_supported() -&gt; bool:\n    \"\"\"True if sharded output is supported by default.\"\"\"\n    return artifacts_io_impl.should_write_sharded()\n</code></pre>"},{"location":"api/#tensorflow_data_validation.display_anomalies","title":"display_anomalies","text":"<pre><code>display_anomalies(anomalies: Anomalies) -&gt; None\n</code></pre> <p>Displays the input anomalies (for use in a Jupyter notebook).</p> <p>anomalies: An Anomalies protocol buffer.</p> Source code in <code>tensorflow_data_validation/utils/display_util.py</code> <pre><code>def display_anomalies(anomalies: anomalies_pb2.Anomalies) -&gt; None:\n    \"\"\"Displays the input anomalies (for use in a Jupyter notebook).\n\n    Args:\n    ----\n      anomalies: An Anomalies protocol buffer.\n    \"\"\"\n    anomalies_df = get_anomalies_dataframe(anomalies)\n    if anomalies_df.empty:\n        display(HTML('&lt;h4 style=\"color:green;\"&gt;No anomalies found.&lt;/h4&gt;'))\n    else:\n        display(anomalies_df)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.display_schema","title":"display_schema","text":"<pre><code>display_schema(schema: Schema) -&gt; None\n</code></pre> <p>Displays the input schema (for use in a Jupyter notebook).</p> <p>schema: A Schema protocol buffer.</p> Source code in <code>tensorflow_data_validation/utils/display_util.py</code> <pre><code>def display_schema(schema: schema_pb2.Schema) -&gt; None:\n    \"\"\"Displays the input schema (for use in a Jupyter notebook).\n\n    Args:\n    ----\n      schema: A Schema protocol buffer.\n    \"\"\"\n    features_df, domains_df = get_schema_dataframe(schema)\n    display(features_df)\n    # Do not truncate columns.\n    if not domains_df.empty:\n        pd.set_option(\"display.max_colwidth\", None)\n        display(domains_df)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.experimental_get_feature_value_slicer","title":"experimental_get_feature_value_slicer","text":"<pre><code>experimental_get_feature_value_slicer(\n    features: Dict[FeatureName, Optional[_ValueType]],\n) -&gt; SliceFunction\n</code></pre> <p>Returns a function that generates sliced record batches for a given one.</p> <p>The returned function returns sliced record batches based on the combination of all features specified in <code>features</code>. To slice on features separately ( e.g., slice on age feature and separately slice on interests feature), you must use separate slice functions.</p>"},{"location":"api/#tensorflow_data_validation.experimental_get_feature_value_slicer--examples","title":"Examples:","text":""},{"location":"api/#tensorflow_data_validation.experimental_get_feature_value_slicer--slice-on-each-value-of-the-specified-features","title":"Slice on each value of the specified features.","text":"<p>slice_fn = get_feature_value_slicer(     features={'age': None, 'interests': None})</p>"},{"location":"api/#tensorflow_data_validation.experimental_get_feature_value_slicer--slice-on-a-specified-feature-value","title":"Slice on a specified feature value.","text":"<p>slice_fn = get_feature_value_slicer(features={'interests': ['dogs']})</p>"},{"location":"api/#tensorflow_data_validation.experimental_get_feature_value_slicer--slice-on-each-value-of-one-feature-and-a-specified-value-of-another","title":"Slice on each value of one feature and a specified value of another.","text":"<p>slice_fn = get_feature_value_slicer(     features={'fruits': None, 'numbers': [1]})</p> <p>features: A mapping of features to an optional iterable of values that the     returned function will slice on. If values is None for a feature, then the     slice keys will reflect each distinct value found for that feature in the     input record batch. If values are specified for a feature, then the slice     keys will reflect only those values for the feature, if found in the input     record batch. Values must be an iterable of strings or integers.</p> <p>A function that takes as input a single record batch and returns a list of   sliced record batches (slice_key, record_batch).</p> <p>TypeError: If feature values are not specified in an iterable.   NotImplementedError: If a value of a type other than string or integer is     specified in the values iterable in <code>features</code>.</p> Source code in <code>tensorflow_data_validation/utils/slicing_util.py</code> <pre><code>def get_feature_value_slicer(\n    features: Dict[types.FeatureName, Optional[_ValueType]],\n) -&gt; types.SliceFunction:\n    \"\"\"Returns a function that generates sliced record batches for a given one.\n\n    The returned function returns sliced record batches based on the combination\n    of all features specified in `features`. To slice on features separately (\n    e.g., slice on age feature and separately slice on interests feature), you\n    must use separate slice functions.\n\n    Examples:\n    --------\n    # Slice on each value of the specified features.\n    slice_fn = get_feature_value_slicer(\n        features={'age': None, 'interests': None})\n\n    # Slice on a specified feature value.\n    slice_fn = get_feature_value_slicer(features={'interests': ['dogs']})\n\n    # Slice on each value of one feature and a specified value of another.\n    slice_fn = get_feature_value_slicer(\n        features={'fruits': None, 'numbers': [1]})\n\n    Args:\n    ----\n      features: A mapping of features to an optional iterable of values that the\n        returned function will slice on. If values is None for a feature, then the\n        slice keys will reflect each distinct value found for that feature in the\n        input record batch. If values are specified for a feature, then the slice\n        keys will reflect only those values for the feature, if found in the input\n        record batch. Values must be an iterable of strings or integers.\n\n    Returns:\n    -------\n      A function that takes as input a single record batch and returns a list of\n      sliced record batches (slice_key, record_batch).\n\n    Raises:\n    ------\n      TypeError: If feature values are not specified in an iterable.\n      NotImplementedError: If a value of a type other than string or integer is\n        specified in the values iterable in `features`.\n    \"\"\"\n    for values in features.values():\n        if values is not None:\n            if not isinstance(values, abc.Iterable):\n                raise TypeError(\"Feature values must be specified in an iterable.\")\n            for value in values:\n                if not isinstance(\n                    value, (six.string_types, six.binary_type)\n                ) and not isinstance(value, int):\n                    raise NotImplementedError(\n                        \"Only string and int values are supported as the slice value.\"\n                    )\n    # Extract the unique slice values per feature.\n    for feature_name in features:\n        if features[feature_name] is not None:\n            features[feature_name] = set(features[feature_name])\n\n    def feature_value_slicer(\n        record_batch: pa.RecordBatch,\n    ) -&gt; Iterable[types.SlicedRecordBatch]:\n        \"\"\"A function that generates sliced record batches.\n\n        The naive approach of doing this would be to iterate each row, identify\n        slice keys for the row and keep track of index ranges for each slice key.\n        And then generate an arrow record batch for each slice key based on the\n        index ranges. This would be expensive as we are identifying the slice keys\n        for each row individually and we would have to loop over the feature values\n        including crossing them when we have to slice on multiple features. The\n        current approach generates the slice keys for a batch by performing joins\n        over indices of individual features. And then groups the joined record batch\n        by slice key to get the row indices corresponding to a slice.\n\n        Args:\n        ----\n          record_batch: Arrow RecordBatch.\n\n        Yields:\n        ------\n          Sliced record batch (slice_key, record_batch) where record_batch contains\n          the rows corresponding to a slice.\n        \"\"\"\n        per_feature_parent_indices = []\n        for feature_name, values in six.iteritems(features):\n            feature_array = arrow_util.get_column(\n                record_batch, feature_name, missing_ok=True\n            )\n            # If the feature name does not appear in the schema for this record batch,\n            # drop it from the set of sliced features.\n            if feature_array is None:\n                continue\n\n            # convert values from list[str] to list[int] if the feature type\n            # is integer.\n            if values is not None:\n                feature_type = stats_util.get_feature_type_from_arrow_type(\n                    types.FeaturePath([feature_name]), feature_array.type\n                )\n                if feature_type == statistics_pb2.FeatureNameStatistics.INT:\n                    try:\n                        values = [int(value) for value in values]\n                    except ValueError as e:\n                        raise ValueError(\n                            \"The feature to slice on has integer values but \"\n                            \"the provided slice values are not valid integers.\"\n                        ) from e\n\n            flattened, value_parent_indices = array_util.flatten_nested(\n                feature_array, True\n            )\n            non_missing_values = np.asarray(flattened)\n            # Create dataframe with feature value and parent index.\n            df = pd.DataFrame(\n                {\n                    feature_name: non_missing_values,\n                    _PARENT_INDEX_COLUMN: value_parent_indices,\n                }\n            )\n            df = df.drop_duplicates()\n            # Filter based on slice values\n            if values is not None:\n                df = df.loc[df[feature_name].isin(values)]\n            per_feature_parent_indices.append(df)\n        # If there are no features to slice on, yield no output.\n        # TODO(b/200081813): Produce output with an appropriate placeholder key.\n        if not per_feature_parent_indices:\n            return\n        # Join dataframes based on parent indices.\n        # Note that we want the parent indices per slice key to be sorted in the\n        # merged dataframe. The individual dataframes have the parent indices in\n        # sorted order. We use \"inner\" join type to preserve the order of the left\n        # keys (also note that same parent index rows would be consecutive). Hence\n        # we expect the merged dataframe to have sorted parent indices per\n        # slice key.\n        merged_df = functools.reduce(\n            lambda base, update: base.merge(\n                update,\n                how=\"inner\",  # pylint: disable=g-long-lambda\n                on=_PARENT_INDEX_COLUMN,\n            ),\n            per_feature_parent_indices,\n        )\n\n        # Construct a new column in the merged dataframe with the slice keys.\n        merged_df[_SLICE_KEY_COLUMN] = \"\"\n        index = 0\n        for col_name in sorted(merged_df.columns):\n            if col_name in [_PARENT_INDEX_COLUMN, _SLICE_KEY_COLUMN]:\n                continue\n            feature_value_part = merged_df[col_name].apply(_to_slice_key)\n            if feature_value_part.empty:\n                feature_value_part = feature_value_part.astype(pd.StringDtype())\n            slice_key_col = _to_slice_key(col_name) + \"_\" + feature_value_part\n            if index == 0:\n                merged_df[_SLICE_KEY_COLUMN] = slice_key_col\n                index += 1\n            else:\n                merged_df[_SLICE_KEY_COLUMN] += \"_\" + slice_key_col\n\n        # Since the parent indices are sorted per slice key, the groupby would\n        # preserve the sorted order within each group.\n        per_slice_parent_indices = merged_df.groupby(_SLICE_KEY_COLUMN, sort=False)[\n            _PARENT_INDEX_COLUMN\n        ]\n        for slice_key, parent_indices in per_slice_parent_indices:\n            yield (\n                slice_key,\n                table_util.RecordBatchTake(\n                    record_batch, pa.array(parent_indices.to_numpy())\n                ),\n            )\n\n    return feature_value_slicer\n</code></pre>"},{"location":"api/#tensorflow_data_validation.generate_dummy_schema_with_paths","title":"generate_dummy_schema_with_paths","text":"<pre><code>generate_dummy_schema_with_paths(\n    paths: List[FeaturePath],\n) -&gt; Schema\n</code></pre> <p>Generate a schema with the requested paths and no other information.</p> Source code in <code>tensorflow_data_validation/utils/schema_util.py</code> <pre><code>def generate_dummy_schema_with_paths(\n    paths: List[types.FeaturePath],\n) -&gt; schema_pb2.Schema:\n    \"\"\"Generate a schema with the requested paths and no other information.\"\"\"\n    schema = schema_pb2.Schema()\n    tree = _paths_to_tree(paths)\n\n    def _add(container, name, children):\n        container.feature.add(name=name)\n        if children:\n            for child_name, grandchildren in children.items():\n                _add(container.feature[-1].struct_domain, child_name, grandchildren)\n\n    for name, children in tree.items():\n        _add(schema, name, children)\n    return schema\n</code></pre>"},{"location":"api/#tensorflow_data_validation.generate_statistics_from_csv","title":"generate_statistics_from_csv","text":"<pre><code>generate_statistics_from_csv(\n    data_location: str,\n    column_names: Optional[List[FeatureName]] = None,\n    delimiter: str = \",\",\n    output_path: Optional[bytes] = None,\n    stats_options: StatsOptions = StatsOptions(),\n    pipeline_options: Optional[PipelineOptions] = None,\n    compression_type: str = AUTO,\n) -&gt; DatasetFeatureStatisticsList\n</code></pre> <p>Compute data statistics from CSV files.</p> <p>Runs a Beam pipeline to compute the data statistics and return the result data statistics proto.</p> <p>This is a convenience method for users with data in CSV format. Users with data in unsupported file/data formats, or users who wish to create their own Beam pipelines need to use the 'GenerateStatistics' PTransform API directly instead.</p> <p>data_location: The location of the input data files.   column_names: A list of column names to be treated as the CSV header. Order     must match the order in the input CSV files. If this argument is not     specified, we assume the first line in the input CSV files as the     header. Note that this option is valid only for 'csv' input file format.   delimiter: A one-character string used to separate fields in a CSV file.   output_path: The file path to output data statistics result to. If None, we     use a temporary directory. It will be a TFRecord file containing a single     data statistics proto, and can be read with the 'load_statistics' API.     If you run this function on Google Cloud, you must specify an     output_path. Specifying None may cause an error.   stats_options: <code>tfdv.StatsOptions</code> for generating data statistics.   pipeline_options: Optional beam pipeline options. This allows users to     specify various beam pipeline execution parameters like pipeline runner     (DirectRunner or DataflowRunner), cloud dataflow service project id, etc.     See https://cloud.google.com/dataflow/pipelines/specifying-exec-params for     more details.   compression_type: Used to handle compressed input files. Default value is     CompressionTypes.AUTO, in which case the file_path's extension will be     used to detect the compression.</p> <p>A DatasetFeatureStatisticsList proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_gen_lib.py</code> <pre><code>def generate_statistics_from_csv(\n    data_location: str,\n    column_names: Optional[List[types.FeatureName]] = None,\n    delimiter: str = \",\",\n    output_path: Optional[bytes] = None,\n    stats_options: options.StatsOptions = options.StatsOptions(),\n    pipeline_options: Optional[PipelineOptions] = None,\n    compression_type: str = CompressionTypes.AUTO,\n) -&gt; statistics_pb2.DatasetFeatureStatisticsList:\n    \"\"\"Compute data statistics from CSV files.\n\n    Runs a Beam pipeline to compute the data statistics and return the result\n    data statistics proto.\n\n    This is a convenience method for users with data in CSV format.\n    Users with data in unsupported file/data formats, or users who wish\n    to create their own Beam pipelines need to use the 'GenerateStatistics'\n    PTransform API directly instead.\n\n    Args:\n    ----\n      data_location: The location of the input data files.\n      column_names: A list of column names to be treated as the CSV header. Order\n        must match the order in the input CSV files. If this argument is not\n        specified, we assume the first line in the input CSV files as the\n        header. Note that this option is valid only for 'csv' input file format.\n      delimiter: A one-character string used to separate fields in a CSV file.\n      output_path: The file path to output data statistics result to. If None, we\n        use a temporary directory. It will be a TFRecord file containing a single\n        data statistics proto, and can be read with the 'load_statistics' API.\n        If you run this function on Google Cloud, you must specify an\n        output_path. Specifying None may cause an error.\n      stats_options: `tfdv.StatsOptions` for generating data statistics.\n      pipeline_options: Optional beam pipeline options. This allows users to\n        specify various beam pipeline execution parameters like pipeline runner\n        (DirectRunner or DataflowRunner), cloud dataflow service project id, etc.\n        See https://cloud.google.com/dataflow/pipelines/specifying-exec-params for\n        more details.\n      compression_type: Used to handle compressed input files. Default value is\n        CompressionTypes.AUTO, in which case the file_path's extension will be\n        used to detect the compression.\n\n    Returns:\n    -------\n      A DatasetFeatureStatisticsList proto.\n    \"\"\"\n    if output_path is None:\n        output_path = os.path.join(tempfile.mkdtemp(), \"data_stats.tfrecord\")\n    output_dir_path = os.path.dirname(output_path)\n    if not tf.io.gfile.exists(output_dir_path):\n        tf.io.gfile.makedirs(output_dir_path)\n\n    batch_size = (\n        stats_options.desired_batch_size\n        if stats_options.desired_batch_size and stats_options.desired_batch_size &gt; 0\n        else constants.DEFAULT_DESIRED_INPUT_BATCH_SIZE\n    )\n    # PyLint doesn't understand Beam PTransforms.\n    # pylint: disable=no-value-for-parameter\n    with beam.Pipeline(options=pipeline_options) as p:\n        # If a header is not provided, assume the first line in a file\n        # to be the header.\n        skip_header_lines = 1 if column_names is None else 0\n        if column_names is None:\n            column_names = get_csv_header(data_location, delimiter, compression_type)\n        _ = (\n            p\n            | \"ReadData\"\n            &gt;&gt; beam.io.textio.ReadFromText(\n                file_pattern=data_location,\n                skip_header_lines=skip_header_lines,\n                compression_type=compression_type,\n            )\n            | \"DecodeData\"\n            &gt;&gt; csv_decoder.DecodeCSV(\n                column_names=column_names,\n                delimiter=delimiter,\n                schema=stats_options.schema\n                if stats_options.infer_type_from_schema\n                else None,\n                desired_batch_size=batch_size,\n            )\n            | \"GenerateStatistics\" &gt;&gt; stats_api.GenerateStatistics(stats_options)\n            | \"WriteStatsOutput\" &gt;&gt; stats_api.WriteStatisticsToTFRecord(output_path)\n        )\n    return stats_util.load_statistics(output_path)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.generate_statistics_from_dataframe","title":"generate_statistics_from_dataframe","text":"<pre><code>generate_statistics_from_dataframe(\n    dataframe: DataFrame,\n    stats_options: StatsOptions = StatsOptions(),\n    n_jobs: int = 1,\n) -&gt; DatasetFeatureStatisticsList\n</code></pre> <p>Compute data statistics for the input pandas DataFrame.</p> <p>This is a utility function for users with in-memory data represented as a pandas DataFrame.</p> <p>This function supports only DataFrames with columns of primitive string or numeric types. DataFrames with multivalent features or holding non-string object types are not supported.</p> <p>dataframe: Input pandas DataFrame.   stats_options: <code>tfdv.StatsOptions</code> for generating data statistics.   n_jobs: Number of processes to run (defaults to 1). If -1 is provided,     uses the same number of processes as the number of CPU cores.</p> <p>A DatasetFeatureStatisticsList proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_gen_lib.py</code> <pre><code>def generate_statistics_from_dataframe(\n    dataframe: DataFrame,\n    stats_options: options.StatsOptions = options.StatsOptions(),\n    n_jobs: int = 1,\n) -&gt; statistics_pb2.DatasetFeatureStatisticsList:\n    \"\"\"Compute data statistics for the input pandas DataFrame.\n\n    This is a utility function for users with in-memory data represented\n    as a pandas DataFrame.\n\n    This function supports only DataFrames with columns of primitive string or\n    numeric types. DataFrames with multivalent features or holding non-string\n    object types are not supported.\n\n    Args:\n    ----\n      dataframe: Input pandas DataFrame.\n      stats_options: `tfdv.StatsOptions` for generating data statistics.\n      n_jobs: Number of processes to run (defaults to 1). If -1 is provided,\n        uses the same number of processes as the number of CPU cores.\n\n    Returns:\n    -------\n      A DatasetFeatureStatisticsList proto.\n    \"\"\"\n    if not isinstance(dataframe, DataFrame):\n        raise TypeError(\n            f\"dataframe argument is of type {type(dataframe).__name__}. Must be a \"\n            \"pandas DataFrame.\"\n        )\n\n    stats_generators = cast(\n        List[stats_generator.CombinerStatsGenerator],\n        stats_impl.get_generators(stats_options, in_memory=True),\n    )\n    if n_jobs &lt; -1 or n_jobs == 0:\n        raise ValueError(\n            f\"Invalid n_jobs parameter {n_jobs}. Should be either \" \" -1 or &gt;= 1.\"\n        )\n\n    if n_jobs == -1:\n        n_jobs = multiprocessing.cpu_count()\n    n_jobs = max(min(n_jobs, multiprocessing.cpu_count()), 1)\n\n    if n_jobs == 1:\n        merged_partial_stats = _generate_partial_statistics_from_df(\n            dataframe, stats_options, stats_generators\n        )\n    else:\n        # TODO(b/144580609): Consider using Beam for inmemory mode as well.\n        splits = np.array_split(dataframe, n_jobs)\n        partial_stats = Parallel(n_jobs=n_jobs)(\n            delayed(_generate_partial_statistics_from_df)(\n                splits[i], stats_options, stats_generators\n            )\n            for i in range(n_jobs)\n        )\n        merged_partial_stats = [\n            gen.merge_accumulators(stats)\n            for gen, stats in zip(stats_generators, zip(*partial_stats))\n        ]\n    return stats_impl.extract_statistics_output(merged_partial_stats, stats_generators)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.generate_statistics_from_tfrecord","title":"generate_statistics_from_tfrecord","text":"<pre><code>generate_statistics_from_tfrecord(\n    data_location: str,\n    output_path: Optional[bytes] = None,\n    stats_options: StatsOptions = StatsOptions(),\n    pipeline_options: Optional[PipelineOptions] = None,\n) -&gt; DatasetFeatureStatisticsList\n</code></pre> <p>Compute data statistics from TFRecord files containing TFExamples.</p> <p>Runs a Beam pipeline to compute the data statistics and return the result data statistics proto.</p> <p>This is a convenience method for users with data in TFRecord format. Users with data in unsupported file/data formats, or users who wish to create their own Beam pipelines need to use the 'GenerateStatistics' PTransform API directly instead.</p> <p>data_location: The location of the input data files.   output_path: The file path to output data statistics result to. If None, we     use a temporary directory. It will be a TFRecord file containing a single     data statistics proto, and can be read with the 'load_statistics' API.     If you run this function on Google Cloud, you must specify an     output_path. Specifying None may cause an error.   stats_options: <code>tfdv.StatsOptions</code> for generating data statistics.   pipeline_options: Optional beam pipeline options. This allows users to     specify various beam pipeline execution parameters like pipeline runner     (DirectRunner or DataflowRunner), cloud dataflow service project id, etc.     See https://cloud.google.com/dataflow/pipelines/specifying-exec-params for     more details.</p> <p>A DatasetFeatureStatisticsList proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_gen_lib.py</code> <pre><code>def generate_statistics_from_tfrecord(\n    data_location: str,\n    output_path: Optional[bytes] = None,\n    stats_options: options.StatsOptions = options.StatsOptions(),\n    pipeline_options: Optional[PipelineOptions] = None,\n) -&gt; statistics_pb2.DatasetFeatureStatisticsList:\n    \"\"\"Compute data statistics from TFRecord files containing TFExamples.\n\n    Runs a Beam pipeline to compute the data statistics and return the result\n    data statistics proto.\n\n    This is a convenience method for users with data in TFRecord format.\n    Users with data in unsupported file/data formats, or users who wish\n    to create their own Beam pipelines need to use the 'GenerateStatistics'\n    PTransform API directly instead.\n\n    Args:\n    ----\n      data_location: The location of the input data files.\n      output_path: The file path to output data statistics result to. If None, we\n        use a temporary directory. It will be a TFRecord file containing a single\n        data statistics proto, and can be read with the 'load_statistics' API.\n        If you run this function on Google Cloud, you must specify an\n        output_path. Specifying None may cause an error.\n      stats_options: `tfdv.StatsOptions` for generating data statistics.\n      pipeline_options: Optional beam pipeline options. This allows users to\n        specify various beam pipeline execution parameters like pipeline runner\n        (DirectRunner or DataflowRunner), cloud dataflow service project id, etc.\n        See https://cloud.google.com/dataflow/pipelines/specifying-exec-params for\n        more details.\n\n    Returns:\n    -------\n      A DatasetFeatureStatisticsList proto.\n    \"\"\"\n    if output_path is None:\n        output_path = os.path.join(tempfile.mkdtemp(), \"data_stats.tfrecord\")\n    output_dir_path = os.path.dirname(output_path)\n    if not tf.io.gfile.exists(output_dir_path):\n        tf.io.gfile.makedirs(output_dir_path)\n\n    batch_size = stats_options.desired_batch_size\n    # PyLint doesn't understand Beam PTransforms.\n    # pylint: disable=no-value-for-parameter\n    with beam.Pipeline(options=pipeline_options) as p:\n        # Auto detect tfrecord file compression format based on input data\n        # path suffix.\n        _ = (\n            p\n            | \"ReadData\"\n            &gt;&gt; (\n                tf_example_record.TFExampleRecord(\n                    file_pattern=data_location,\n                    schema=None,\n                    telemetry_descriptors=[\"tfdv\", \"generate_statistics_from_tfrecord\"],\n                ).BeamSource(batch_size)\n            )\n            | \"GenerateStatistics\" &gt;&gt; stats_api.GenerateStatistics(stats_options)\n            | \"WriteStatsOutput\" &gt;&gt; (stats_api.WriteStatisticsToTFRecord(output_path))\n        )\n    return stats_util.load_statistics(output_path)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.get_confusion_count_dataframes","title":"get_confusion_count_dataframes","text":"<pre><code>get_confusion_count_dataframes(\n    confusion: Iterable[ConfusionCount],\n) -&gt; Dict[str, DataFrame]\n</code></pre> <p>Returns a pandas dataframe representation of a sequence of ConfusionCount.</p> <p>confusion: An interable over ConfusionCount protos. Returns: A map from feature name to a pandas dataframe containing match counts   along with base and test counts for all unequal value pairs in the input.</p> Source code in <code>tensorflow_data_validation/utils/display_util.py</code> <pre><code>def get_confusion_count_dataframes(\n    confusion: Iterable[feature_skew_results_pb2.ConfusionCount],\n) -&gt; Dict[str, pd.DataFrame]:\n    \"\"\"Returns a pandas dataframe representation of a sequence of ConfusionCount.\n\n    Args:\n    ----\n      confusion: An interable over ConfusionCount protos.\n    Returns: A map from feature name to a pandas dataframe containing match counts\n      along with base and test counts for all unequal value pairs in the input.\n    \"\"\"\n    confusion = list(confusion)\n    confusion_per_feature = collections.defaultdict(list)\n    for c in confusion:\n        confusion_per_feature[c.feature_name].append(c)\n\n    def _build_df(confusion):\n        base_count_per_value = collections.defaultdict(lambda: 0)\n        test_count_per_value = collections.defaultdict(lambda: 0)\n        value_counts = []\n        for c in confusion:\n            base_count_per_value[c.base.bytes_value] += c.count\n            test_count_per_value[c.test.bytes_value] += c.count\n            value_counts.append((c.base.bytes_value, c.test.bytes_value, c.count))\n        df = pd.DataFrame(\n            value_counts, columns=(\"Base value\", \"Test value\", \"Pair count\")\n        )\n        df[\"Base count\"] = df[\"Base value\"].apply(lambda x: base_count_per_value[x])\n        df[\"Test count\"] = df[\"Test value\"].apply(lambda x: test_count_per_value[x])\n        df[\"Fraction of base\"] = df[\"Pair count\"] / df[\"Base count\"]\n        df = (\n            df[df[\"Base value\"] != df[\"Test value\"]]\n            .sort_values([\"Base value\", \"Fraction of base\"])\n            .reset_index(drop=True)\n        )\n        return df[\n            [\"Base value\", \"Test value\", \"Pair count\", \"Base count\", \"Test count\"]\n        ]\n\n    return {k: _build_df(v) for k, v in confusion_per_feature.items()}\n</code></pre>"},{"location":"api/#tensorflow_data_validation.get_domain","title":"get_domain","text":"<pre><code>get_domain(\n    schema: Schema,\n    feature_path: Union[FeatureName, FeaturePath],\n) -&gt; Any\n</code></pre> <p>Get the domain associated with the input feature from the schema.</p> <p>schema: A Schema protocol buffer.   feature_path: The path of the feature whose domain needs to be found. If a     FeatureName is passed, a one-step FeaturePath will be constructed and     used. For example, \"my_feature\" -&gt; types.FeaturePath([\"my_feature\"])</p> <p>The domain protocol buffer associated with the input feature.</p> <p>TypeError: If the input schema is not of the expected type.   ValueError: If the input feature is not found in the schema or there is       no domain associated with the feature.</p> Source code in <code>tensorflow_data_validation/utils/schema_util.py</code> <pre><code>def get_domain(\n    schema: schema_pb2.Schema, feature_path: Union[types.FeatureName, types.FeaturePath]\n) -&gt; Any:\n    \"\"\"Get the domain associated with the input feature from the schema.\n\n    Args:\n    ----\n      schema: A Schema protocol buffer.\n      feature_path: The path of the feature whose domain needs to be found. If a\n        FeatureName is passed, a one-step FeaturePath will be constructed and\n        used. For example, \"my_feature\" -&gt; types.FeaturePath([\"my_feature\"])\n\n    Returns:\n    -------\n      The domain protocol buffer associated with the input feature.\n\n    Raises:\n    ------\n      TypeError: If the input schema is not of the expected type.\n      ValueError: If the input feature is not found in the schema or there is\n          no domain associated with the feature.\n    \"\"\"\n    if not isinstance(schema, schema_pb2.Schema):\n        raise TypeError(\n            \"schema is of type %s, should be a Schema proto.\" % type(schema).__name__\n        )\n\n    feature = get_feature(schema, feature_path)\n    domain_info = feature.WhichOneof(\"domain_info\")\n\n    if domain_info is None:\n        raise ValueError(\"Feature %s has no domain associated with it.\" % feature_path)\n\n    if domain_info != \"domain\":\n        return getattr(feature, domain_info)\n    for domain in schema.string_domain:\n        if domain.name == feature.domain:\n            return domain\n\n    raise ValueError(\n        \"Feature %s has an unsupported domain %s.\" % (feature_path, domain_info)\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation.get_feature","title":"get_feature","text":"<pre><code>get_feature(\n    schema: Schema,\n    feature_path: Union[FeatureName, FeaturePath],\n) -&gt; Feature\n</code></pre> <p>Get a feature from the schema.</p> <p>schema: A Schema protocol buffer.   feature_path: The path of the feature to obtain from the schema. If a     FeatureName is passed, a one-step FeaturePath will be constructed and     used. For example, \"my_feature\" -&gt; types.FeaturePath([\"my_feature\"])</p> <p>A Feature protocol buffer.</p> <p>TypeError: If the input schema is not of the expected type.   ValueError: If the input feature is not found in the schema.</p> Source code in <code>tensorflow_data_validation/utils/schema_util.py</code> <pre><code>def get_feature(\n    schema: schema_pb2.Schema, feature_path: Union[types.FeatureName, types.FeaturePath]\n) -&gt; schema_pb2.Feature:\n    \"\"\"Get a feature from the schema.\n\n    Args:\n    ----\n      schema: A Schema protocol buffer.\n      feature_path: The path of the feature to obtain from the schema. If a\n        FeatureName is passed, a one-step FeaturePath will be constructed and\n        used. For example, \"my_feature\" -&gt; types.FeaturePath([\"my_feature\"])\n\n    Returns:\n    -------\n      A Feature protocol buffer.\n\n    Raises:\n    ------\n      TypeError: If the input schema is not of the expected type.\n      ValueError: If the input feature is not found in the schema.\n    \"\"\"\n    if not isinstance(schema, schema_pb2.Schema):\n        raise TypeError(\n            \"schema is of type %s, should be a Schema proto.\" % type(schema).__name__\n        )\n\n    if not isinstance(feature_path, types.FeaturePath):\n        feature_path = types.FeaturePath([feature_path])\n\n    feature_container = schema.feature\n    parent = feature_path.parent()\n    if parent:\n        for step in parent.steps():\n            f = look_up_feature(step, feature_container)\n            if f is None:\n                raise ValueError(\"Feature %s not found in the schema.\" % feature_path)\n            if f.type != schema_pb2.STRUCT:\n                raise ValueError(\n                    \"Step %s in feature %s does not refer to a valid STRUCT feature\"\n                    % (step, feature_path)\n                )\n            feature_container = f.struct_domain.feature\n\n    feature = look_up_feature(feature_path.steps()[-1], feature_container)\n    if feature is None:\n        raise ValueError(\"Feature %s not found in the schema.\" % feature_path)\n    return feature\n</code></pre>"},{"location":"api/#tensorflow_data_validation.get_feature_stats","title":"get_feature_stats","text":"<pre><code>get_feature_stats(\n    stats: DatasetFeatureStatistics,\n    feature_path: FeaturePath,\n) -&gt; FeatureNameStatistics\n</code></pre> <p>Get feature statistics from the dataset statistics.</p> <p>stats: A DatasetFeatureStatistics protocol buffer.   feature_path: The path of the feature whose statistics to obtain from the     dataset statistics.</p> <p>A FeatureNameStatistics protocol buffer.</p> <p>TypeError: If the input statistics is not of the expected type.   ValueError: If the input feature is not found in the dataset statistics.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def get_feature_stats(\n    stats: statistics_pb2.DatasetFeatureStatistics, feature_path: types.FeaturePath\n) -&gt; statistics_pb2.FeatureNameStatistics:\n    \"\"\"Get feature statistics from the dataset statistics.\n\n    Args:\n    ----\n      stats: A DatasetFeatureStatistics protocol buffer.\n      feature_path: The path of the feature whose statistics to obtain from the\n        dataset statistics.\n\n    Returns:\n    -------\n      A FeatureNameStatistics protocol buffer.\n\n    Raises:\n    ------\n      TypeError: If the input statistics is not of the expected type.\n      ValueError: If the input feature is not found in the dataset statistics.\n    \"\"\"\n    if not isinstance(stats, statistics_pb2.DatasetFeatureStatistics):\n        raise TypeError(\n            \"statistics is of type %s, should be a \"\n            \"DatasetFeatureStatistics proto.\" % type(stats).__name__\n        )\n\n    for feature_stats in stats.features:\n        if feature_path == types.FeaturePath.from_proto(feature_stats.path):\n            return feature_stats\n\n    raise ValueError(\"Feature %s not found in the dataset statistics.\" % feature_path)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.get_match_stats_dataframe","title":"get_match_stats_dataframe","text":"<pre><code>get_match_stats_dataframe(\n    match_stats: MatchStats,\n) -&gt; DataFrame\n</code></pre> <p>Formats MatchStats as a pandas dataframe.</p> Source code in <code>tensorflow_data_validation/utils/display_util.py</code> <pre><code>def get_match_stats_dataframe(\n    match_stats: feature_skew_results_pb2.MatchStats,\n) -&gt; pd.DataFrame:\n    \"\"\"Formats MatchStats as a pandas dataframe.\"\"\"\n    return pd.DataFrame.from_dict(\n        {\n            \"base_with_id_count\": [match_stats.base_with_id_count],\n            \"test_with_id_count\": [match_stats.test_with_id_count],\n            \"identifiers_count\": [match_stats.identifiers_count],\n            \"ids_missing_in_base_count\": [match_stats.ids_missing_in_base_count],\n            \"ids_missing_in_test_count\": [match_stats.ids_missing_in_test_count],\n            \"matching_pairs_count\": [match_stats.matching_pairs_count],\n            \"base_missing_id_count\": [match_stats.base_missing_id_count],\n            \"test_missing_id_count\": [match_stats.test_missing_id_count],\n            \"duplicate_id_count\": [match_stats.duplicate_id_count],\n        }\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation.get_skew_result_dataframe","title":"get_skew_result_dataframe","text":"<pre><code>get_skew_result_dataframe(\n    skew_results: Iterable[FeatureSkew],\n) -&gt; DataFrame\n</code></pre> <p>Formats FeatureSkew results as a pandas dataframe.</p> Source code in <code>tensorflow_data_validation/utils/display_util.py</code> <pre><code>def get_skew_result_dataframe(\n    skew_results: Iterable[feature_skew_results_pb2.FeatureSkew],\n) -&gt; pd.DataFrame:\n    \"\"\"Formats FeatureSkew results as a pandas dataframe.\"\"\"\n    result = []\n    for feature_skew in skew_results:\n        result.append(\n            (\n                feature_skew.feature_name,\n                feature_skew.base_count,\n                feature_skew.test_count,\n                feature_skew.match_count,\n                feature_skew.base_only,\n                feature_skew.test_only,\n                feature_skew.mismatch_count,\n                feature_skew.diff_count,\n            )\n        )\n    # Preserve deterministic order from the proto.\n    columns = [\n        \"feature_name\",\n        \"base_count\",\n        \"test_count\",\n        \"match_count\",\n        \"base_only\",\n        \"test_only\",\n        \"mismatch_count\",\n        \"diff_count\",\n    ]\n    return (\n        pd.DataFrame(result, columns=columns)\n        .sort_values(\"feature_name\")\n        .reset_index(drop=True)\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation.get_slice_stats","title":"get_slice_stats","text":"<pre><code>get_slice_stats(\n    stats: DatasetFeatureStatisticsList, slice_key: str\n) -&gt; DatasetFeatureStatisticsList\n</code></pre> <p>Get statistics associated with a specific slice.</p> <p>stats: A DatasetFeatureStatisticsList protocol buffer.   slice_key: Slice key of the slice.</p> <p>Statistics of the specific slice.</p> <p>ValueError: If the input statistics proto does not have the specified slice     statistics.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def get_slice_stats(\n    stats: statistics_pb2.DatasetFeatureStatisticsList, slice_key: str\n) -&gt; statistics_pb2.DatasetFeatureStatisticsList:\n    \"\"\"Get statistics associated with a specific slice.\n\n    Args:\n    ----\n      stats: A DatasetFeatureStatisticsList protocol buffer.\n      slice_key: Slice key of the slice.\n\n    Returns:\n    -------\n      Statistics of the specific slice.\n\n    Raises:\n    ------\n      ValueError: If the input statistics proto does not have the specified slice\n        statistics.\n    \"\"\"\n    for slice_stats in stats.datasets:\n        if slice_stats.name == slice_key:\n            result = statistics_pb2.DatasetFeatureStatisticsList()\n            result.datasets.add().CopyFrom(slice_stats)\n            return result\n    raise ValueError(\"Invalid slice key.\")\n</code></pre>"},{"location":"api/#tensorflow_data_validation.get_statistics_html","title":"get_statistics_html","text":"<pre><code>get_statistics_html(\n    lhs_statistics: DatasetFeatureStatisticsList,\n    rhs_statistics: Optional[\n        DatasetFeatureStatisticsList\n    ] = None,\n    lhs_name: str = \"lhs_statistics\",\n    rhs_name: str = \"rhs_statistics\",\n    allowlist_features: Optional[List[FeaturePath]] = None,\n    denylist_features: Optional[List[FeaturePath]] = None,\n) -&gt; str\n</code></pre> <p>Build the HTML for visualizing the input statistics using Facets.</p> <p>lhs_statistics: A DatasetFeatureStatisticsList protocol buffer.   rhs_statistics: An optional DatasetFeatureStatisticsList protocol buffer to     compare with lhs_statistics.   lhs_name: Name to use for the lhs_statistics dataset if a name is not     already provided within the protocol buffer.   rhs_name: Name to use for the rhs_statistics dataset if a name is not     already provided within the protocol buffer.   allowlist_features: Set of features to be visualized.   denylist_features: Set of features to ignore for visualization.</p> <p>HTML to be embedded for visualization.</p> <p>TypeError: If the input argument is not of the expected type.   ValueError: If the input statistics protos does not have only one dataset.</p> Source code in <code>tensorflow_data_validation/utils/display_util.py</code> <pre><code>def get_statistics_html(\n    lhs_statistics: statistics_pb2.DatasetFeatureStatisticsList,\n    rhs_statistics: Optional[statistics_pb2.DatasetFeatureStatisticsList] = None,\n    lhs_name: str = \"lhs_statistics\",\n    rhs_name: str = \"rhs_statistics\",\n    allowlist_features: Optional[List[types.FeaturePath]] = None,\n    denylist_features: Optional[List[types.FeaturePath]] = None,\n) -&gt; str:\n    \"\"\"Build the HTML for visualizing the input statistics using Facets.\n\n    Args:\n    ----\n      lhs_statistics: A DatasetFeatureStatisticsList protocol buffer.\n      rhs_statistics: An optional DatasetFeatureStatisticsList protocol buffer to\n        compare with lhs_statistics.\n      lhs_name: Name to use for the lhs_statistics dataset if a name is not\n        already provided within the protocol buffer.\n      rhs_name: Name to use for the rhs_statistics dataset if a name is not\n        already provided within the protocol buffer.\n      allowlist_features: Set of features to be visualized.\n      denylist_features: Set of features to ignore for visualization.\n\n    Returns:\n    -------\n      HTML to be embedded for visualization.\n\n    Raises:\n    ------\n      TypeError: If the input argument is not of the expected type.\n      ValueError: If the input statistics protos does not have only one dataset.\n    \"\"\"\n    combined_statistics = _get_combined_statistics(\n        lhs_statistics,\n        rhs_statistics,\n        lhs_name,\n        rhs_name,\n        allowlist_features,\n        denylist_features,\n    )\n    if (\n        len(combined_statistics.datasets) == 1\n        and combined_statistics.datasets[0].num_examples == 0\n    ):\n        return \"&lt;p&gt;Empty dataset.&lt;/p&gt;\"\n\n    protostr = base64.b64encode(combined_statistics.SerializeToString()).decode(\"utf-8\")\n\n    # pylint: disable=line-too-long,anomalous-backslash-in-string\n    # Note that in the html template we currently assign a temporary id to the\n    # facets element and then remove it once we have appended the serialized proto\n    # string to the element. We do this to avoid any collision of ids when\n    # displaying multiple facets output in the notebook.\n    #\n    # Note that a string literal including '&lt;/script&gt;' in a &lt;script&gt; tag needs to\n    # escape it as &lt;\\/script&gt; to avoid early closing the wrapping &lt;script&gt; tag.\n    html_template = r\"\"\"&lt;iframe id='facets-iframe' width=\"100%\" height=\"500px\"&gt;&lt;/iframe&gt;\n        &lt;script&gt;\n        facets_iframe = document.getElementById('facets-iframe');\n        facets_html = '&lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"&gt;&lt;\\/script&gt;&lt;link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"&gt;&lt;facets-overview proto-input=\"protostr\"&gt;&lt;/facets-overview&gt;';\n        facets_iframe.srcdoc = facets_html;\n         facets_iframe.id = \"\";\n         setTimeout(() =&gt; {\n           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n         }, 1500)\n         &lt;/script&gt;\"\"\"\n    # pylint: enable=line-too-long\n    html = html_template.replace(\"protostr\", protostr)\n\n    return html\n</code></pre>"},{"location":"api/#tensorflow_data_validation.infer_schema","title":"infer_schema","text":"<pre><code>infer_schema(\n    statistics: DatasetFeatureStatisticsList,\n    infer_feature_shape: bool = True,\n    max_string_domain_size: int = 100,\n    schema_transformations: Optional[\n        List[\n            Callable[\n                [Schema, DatasetFeatureStatistics], Schema\n            ]\n        ]\n    ] = None,\n) -&gt; Schema\n</code></pre> <p>Infers schema from the input statistics.</p> <p>statistics: A DatasetFeatureStatisticsList protocol buffer. Schema inference     is currently supported only for lists with a single     DatasetFeatureStatistics proto or lists with multiple     DatasetFeatureStatistics protos corresponding to data slices that include     the default slice (i.e., the slice with all examples). If a list with     multiple DatasetFeatureStatistics protos is used, this function will infer     the schema from the statistics corresponding to the default slice.   infer_feature_shape: A boolean to indicate if shape of the features need to     be inferred from the statistics.   max_string_domain_size: Maximum size of the domain of a string feature in       order to be interpreted as a categorical feature.   schema_transformations: List of transformation functions to apply to the       auto-inferred schema. Each transformation function should take the       schema and statistics as input and should return the transformed schema.       The transformations are applied in the order provided in the list.</p> <p>A Schema protocol buffer.</p> <p>TypeError: If the input argument is not of the expected type.   ValueError: If the input statistics proto contains multiple datasets, none       of which corresponds to the default slice.</p> Source code in <code>tensorflow_data_validation/api/validation_api.py</code> <pre><code>def infer_schema(\n    statistics: statistics_pb2.DatasetFeatureStatisticsList,\n    infer_feature_shape: bool = True,\n    max_string_domain_size: int = 100,\n    schema_transformations: Optional[\n        List[\n            Callable[\n                [schema_pb2.Schema, statistics_pb2.DatasetFeatureStatistics],\n                schema_pb2.Schema,\n            ]\n        ]\n    ] = None,\n) -&gt; schema_pb2.Schema:\n    \"\"\"Infers schema from the input statistics.\n\n    Args:\n    ----\n      statistics: A DatasetFeatureStatisticsList protocol buffer. Schema inference\n        is currently supported only for lists with a single\n        DatasetFeatureStatistics proto or lists with multiple\n        DatasetFeatureStatistics protos corresponding to data slices that include\n        the default slice (i.e., the slice with all examples). If a list with\n        multiple DatasetFeatureStatistics protos is used, this function will infer\n        the schema from the statistics corresponding to the default slice.\n      infer_feature_shape: A boolean to indicate if shape of the features need to\n        be inferred from the statistics.\n      max_string_domain_size: Maximum size of the domain of a string feature in\n          order to be interpreted as a categorical feature.\n      schema_transformations: List of transformation functions to apply to the\n          auto-inferred schema. Each transformation function should take the\n          schema and statistics as input and should return the transformed schema.\n          The transformations are applied in the order provided in the list.\n\n    Returns:\n    -------\n      A Schema protocol buffer.\n\n    Raises:\n    ------\n      TypeError: If the input argument is not of the expected type.\n      ValueError: If the input statistics proto contains multiple datasets, none\n          of which corresponds to the default slice.\n    \"\"\"\n    if not isinstance(statistics, statistics_pb2.DatasetFeatureStatisticsList):\n        raise TypeError(\n            \"statistics is of type %s, should be \"\n            \"a DatasetFeatureStatisticsList proto.\" % type(statistics).__name__\n        )\n\n    # This will raise an exception if there are multiple datasets, none of which\n    # corresponds to the default slice.\n    dataset_statistics = _get_default_dataset_statistics(statistics)\n\n    # dataset_statistics may include stats for composite features like\n    # SparseFeatures and WeightedFeatures. We cannot infer a useful schema from\n    # these stats, so we remove them at the start.\n    dataset_statistics = _remove_features_missing_common_stats(dataset_statistics)\n\n    schema_proto_string = pywrap_tensorflow_data_validation.InferSchema(\n        tf.compat.as_bytes(dataset_statistics.SerializeToString()),\n        max_string_domain_size,\n        infer_feature_shape,\n    )\n\n    # Parse the serialized Schema proto.\n    result = schema_pb2.Schema()\n    result.ParseFromString(schema_proto_string)\n\n    _may_be_set_legacy_flag(result)\n\n    if schema_transformations is not None:\n        for transformation_fn in schema_transformations:\n            result = transformation_fn(result, statistics.datasets[0])\n    return result\n</code></pre>"},{"location":"api/#tensorflow_data_validation.load_anomalies_text","title":"load_anomalies_text","text":"<pre><code>load_anomalies_text(input_path: str) -&gt; Anomalies\n</code></pre> <p>Loads the Anomalies proto stored in text format in the input path.</p> <p>input_path: File path from which to load the Anomalies proto.</p> <p>An Anomalies protocol buffer.</p> Source code in <code>tensorflow_data_validation/utils/anomalies_util.py</code> <pre><code>def load_anomalies_text(input_path: str) -&gt; anomalies_pb2.Anomalies:\n    \"\"\"Loads the Anomalies proto stored in text format in the input path.\n\n    Args:\n    ----\n      input_path: File path from which to load the Anomalies proto.\n\n    Returns:\n    -------\n      An Anomalies protocol buffer.\n    \"\"\"\n    anomalies = anomalies_pb2.Anomalies()\n    anomalies_text = io_util.read_file_to_string(input_path)\n    text_format.Parse(anomalies_text, anomalies)\n    return anomalies\n</code></pre>"},{"location":"api/#tensorflow_data_validation.load_schema_text","title":"load_schema_text","text":"<pre><code>load_schema_text(input_path: str) -&gt; Schema\n</code></pre> <p>Loads the schema stored in text format in the input path.</p> <p>input_path: File path to load the schema from.</p> <p>A Schema protocol buffer.</p> Source code in <code>tensorflow_data_validation/utils/schema_util.py</code> <pre><code>def load_schema_text(input_path: str) -&gt; schema_pb2.Schema:\n    \"\"\"Loads the schema stored in text format in the input path.\n\n    Args:\n    ----\n      input_path: File path to load the schema from.\n\n    Returns:\n    -------\n      A Schema protocol buffer.\n    \"\"\"\n    schema = schema_pb2.Schema()\n    schema_text = io_util.read_file_to_string(input_path)\n    text_format.Parse(schema_text, schema)\n    return schema\n</code></pre>"},{"location":"api/#tensorflow_data_validation.load_sharded_statistics","title":"load_sharded_statistics","text":"<pre><code>load_sharded_statistics(\n    input_path_prefix: Optional[str] = None,\n    input_paths: Optional[Iterable[str]] = None,\n    io_provider: Optional[StatisticsIOProvider] = None,\n) -&gt; DatasetListView\n</code></pre> <p>Read a sharded DatasetFeatureStatisticsList from disk as a DatasetListView.</p> <p>input_path_prefix: If passed, loads files starting with this prefix and     ending with a pattern corresponding to the output of the provided       io_provider.   input_paths: A list of file paths of files containing sharded     DatasetFeatureStatisticsList protos.   io_provider: Optional StatisticsIOProvider. If unset, a default will be     constructed.</p> <p>A DatasetListView containing the merged proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def load_sharded_statistics(\n    input_path_prefix: Optional[str] = None,\n    input_paths: Optional[Iterable[str]] = None,\n    io_provider: Optional[artifacts_io_impl.StatisticsIOProvider] = None,\n) -&gt; DatasetListView:\n    \"\"\"Read a sharded DatasetFeatureStatisticsList from disk as a DatasetListView.\n\n    Args:\n    ----\n      input_path_prefix: If passed, loads files starting with this prefix and\n        ending with a pattern corresponding to the output of the provided\n          io_provider.\n      input_paths: A list of file paths of files containing sharded\n        DatasetFeatureStatisticsList protos.\n      io_provider: Optional StatisticsIOProvider. If unset, a default will be\n        constructed.\n\n    Returns:\n    -------\n      A DatasetListView containing the merged proto.\n    \"\"\"\n    if input_path_prefix is None == input_paths is None:\n        raise ValueError(\"Must provide one of input_paths_prefix, input_paths.\")\n    if io_provider is None:\n        io_provider = artifacts_io_impl.get_io_provider()\n    if input_path_prefix is not None:\n        input_paths = io_provider.glob(input_path_prefix)\n    if not input_paths:\n        raise ValueError(\n            \"No input paths found paths=%s, pattern=%s\"\n            % (input_paths, input_path_prefix)\n        )\n    acc = statistics.DatasetListAccumulator()\n    stats_iter = io_provider.record_iterator_impl(input_paths)\n    for stats_list in stats_iter:\n        for dataset in stats_list.datasets:\n            acc.MergeDatasetFeatureStatistics(dataset.SerializeToString())\n    stats = statistics_pb2.DatasetFeatureStatisticsList()\n    stats.ParseFromString(acc.Get())\n    return DatasetListView(stats)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.load_statistics","title":"load_statistics","text":"<pre><code>load_statistics(\n    input_path: str,\n) -&gt; DatasetFeatureStatisticsList\n</code></pre> <p>Loads data statistics proto from file.</p> <p>input_path: Data statistics file path. The file should be a one-record     TFRecord file or a plain file containing the statistics proto in Proto     Text Format.</p> <p>A DatasetFeatureStatisticsList proto.</p> <p>IOError: If the input path does not exist.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def load_statistics(input_path: str) -&gt; statistics_pb2.DatasetFeatureStatisticsList:\n    \"\"\"Loads data statistics proto from file.\n\n    Args:\n    ----\n      input_path: Data statistics file path. The file should be a one-record\n        TFRecord file or a plain file containing the statistics proto in Proto\n        Text Format.\n\n    Returns:\n    -------\n      A DatasetFeatureStatisticsList proto.\n\n    Raises:\n    ------\n      IOError: If the input path does not exist.\n    \"\"\"\n    if not tf.io.gfile.exists(input_path):\n        raise OSError(f\"Invalid input path {input_path}.\")\n    try:\n        return load_stats_tfrecord(input_path)\n    except Exception:  # pylint: disable=broad-except\n        logging.info(\n            \"File %s did not look like a TFRecord. Try reading as a plain \" \"file.\",\n            input_path,\n        )\n        return load_stats_text(input_path)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.load_stats_binary","title":"load_stats_binary","text":"<pre><code>load_stats_binary(\n    input_path: str,\n) -&gt; DatasetFeatureStatisticsList\n</code></pre> <p>Loads a serialized DatasetFeatureStatisticsList proto from a file.</p> <p>input_path: File path from which to load the DatasetFeatureStatisticsList     proto.</p> <p>A DatasetFeatureStatisticsList proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def load_stats_binary(input_path: str) -&gt; statistics_pb2.DatasetFeatureStatisticsList:\n    \"\"\"Loads a serialized DatasetFeatureStatisticsList proto from a file.\n\n    Args:\n    ----\n      input_path: File path from which to load the DatasetFeatureStatisticsList\n        proto.\n\n    Returns:\n    -------\n      A DatasetFeatureStatisticsList proto.\n    \"\"\"\n    stats_proto = statistics_pb2.DatasetFeatureStatisticsList()\n    stats_proto.ParseFromString(\n        io_util.read_file_to_string(input_path, binary_mode=True)\n    )\n    return stats_proto\n</code></pre>"},{"location":"api/#tensorflow_data_validation.load_stats_text","title":"load_stats_text","text":"<pre><code>load_stats_text(\n    input_path: str,\n) -&gt; DatasetFeatureStatisticsList\n</code></pre> <p>Loads the specified DatasetFeatureStatisticsList proto stored in text format.</p> <p>input_path: File path from which to load the DatasetFeatureStatisticsList     proto.</p> <p>A DatasetFeatureStatisticsList proto.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def load_stats_text(input_path: str) -&gt; statistics_pb2.DatasetFeatureStatisticsList:\n    \"\"\"Loads the specified DatasetFeatureStatisticsList proto stored in text format.\n\n    Args:\n    ----\n      input_path: File path from which to load the DatasetFeatureStatisticsList\n        proto.\n\n    Returns:\n    -------\n      A DatasetFeatureStatisticsList proto.\n    \"\"\"\n    stats_proto = statistics_pb2.DatasetFeatureStatisticsList()\n    stats_text = io_util.read_file_to_string(input_path)\n    text_format.Parse(stats_text, stats_proto)\n    return stats_proto\n</code></pre>"},{"location":"api/#tensorflow_data_validation.set_domain","title":"set_domain","text":"<pre><code>set_domain(\n    schema: Schema, feature_path: FeaturePath, domain: Any\n) -&gt; None\n</code></pre> <p>Sets the domain for the input feature in the schema.</p> <p>If the input feature already has a domain, it is overwritten with the newly provided input domain. This method cannot be used to add a new global domain.</p> <p>schema: A Schema protocol buffer.   feature_path: The name of the feature whose domain needs to be set. If a     FeatureName is passed, a one-step FeaturePath will be constructed and     used. For example, \"my_feature\" -&gt; types.FeaturePath([\"my_feature\"])   domain: A domain protocol buffer or the name of a global string domain     present in the input schema. Example:  ```python &gt;&gt;&gt; from tensorflow_metadata.proto.v0 import schema_pb2</p> <p>import tensorflow_data_validation as tfdv &gt;&gt;&gt; schema =   schema_pb2.Schema() &gt;&gt;&gt; schema.feature.add(name='feature') # Setting a int   domain. &gt;&gt;&gt; int_domain = schema_pb2.IntDomain(min=3, max=5) &gt;&gt;&gt;   tfdv.set_domain(schema, \"feature\", int_domain) # Setting a string domain. str_domain = schema_pb2.StringDomain(value=['one', 'two', 'three']) &gt;&gt;&gt;   tfdv.set_domain(schema, \"feature\", str_domain) ```</p> <p>TypeError: If the input schema or the domain is not of the expected type.   ValueError: If an invalid global string domain is provided as input.</p> Source code in <code>tensorflow_data_validation/utils/schema_util.py</code> <pre><code>def set_domain(\n    schema: schema_pb2.Schema, feature_path: types.FeaturePath, domain: Any\n) -&gt; None:\n    \"\"\"Sets the domain for the input feature in the schema.\n\n    If the input feature already has a domain, it is overwritten with the newly\n    provided input domain. This method cannot be used to add a new global domain.\n\n    Args:\n    ----\n      schema: A Schema protocol buffer.\n      feature_path: The name of the feature whose domain needs to be set. If a\n        FeatureName is passed, a one-step FeaturePath will be constructed and\n        used. For example, \"my_feature\" -&gt; types.FeaturePath([\"my_feature\"])\n      domain: A domain protocol buffer or the name of a global string domain\n        present in the input schema.\n    Example:  ```python &gt;&gt;&gt; from tensorflow_metadata.proto.v0 import schema_pb2\n      &gt;&gt;&gt; import tensorflow_data_validation as tfdv &gt;&gt;&gt; schema =\n      schema_pb2.Schema() &gt;&gt;&gt; schema.feature.add(name='feature') # Setting a int\n      domain. &gt;&gt;&gt; int_domain = schema_pb2.IntDomain(min=3, max=5) &gt;&gt;&gt;\n      tfdv.set_domain(schema, \"feature\", int_domain) # Setting a string domain.\n      &gt;&gt;&gt; str_domain = schema_pb2.StringDomain(value=['one', 'two', 'three']) &gt;&gt;&gt;\n      tfdv.set_domain(schema, \"feature\", str_domain) ```\n\n    Raises:\n    ------\n      TypeError: If the input schema or the domain is not of the expected type.\n      ValueError: If an invalid global string domain is provided as input.\n    \"\"\"\n    if not isinstance(schema, schema_pb2.Schema):\n        raise TypeError(\n            \"schema is of type %s, should be a Schema proto.\" % type(schema).__name__\n        )\n\n    # Find all fields types and names within domain_info.\n    feature_domains = {}\n    for f in schema_pb2.Feature.DESCRIPTOR.oneofs_by_name[\"domain_info\"].fields:\n        if f.message_type is not None:\n            feature_domains[getattr(schema_pb2, f.message_type.name)] = f.name\n        elif f.type == descriptor.FieldDescriptor.TYPE_STRING:\n            feature_domains[str] = f.name\n        else:\n            raise TypeError(\"Unexpected type within schema.Features.domain_info\")\n    if not isinstance(domain, tuple(feature_domains.keys())):\n        raise TypeError(\n            \"domain is of type %s, should be one of the supported types\"\n            \" in schema.Features.domain_info\" % type(domain).__name__\n        )\n\n    feature = get_feature(schema, feature_path)\n    if feature.type == schema_pb2.STRUCT:\n        raise TypeError(\n            \"Could not set the domain of a STRUCT feature %s.\" % feature_path\n        )\n\n    if feature.WhichOneof(\"domain_info\") is not None:\n        logging.warning('Replacing existing domain of feature \"%s\".', feature_path)\n\n    for d_type, d_name in feature_domains.items():\n        if isinstance(domain, d_type):\n            if d_type is str:\n                found_domain = False\n                for global_domain in schema.string_domain:\n                    if global_domain.name == domain:\n                        found_domain = True\n                        break\n                if not found_domain:\n                    raise ValueError(f'Invalid global string domain \"{domain}\".')\n                feature.domain = domain\n            else:\n                getattr(feature, d_name).CopyFrom(domain)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.update_schema","title":"update_schema","text":"<pre><code>update_schema(\n    schema: Schema,\n    statistics: DatasetFeatureStatisticsList,\n    infer_feature_shape: Optional[bool] = True,\n    max_string_domain_size: Optional[int] = 100,\n) -&gt; Schema\n</code></pre> <p>Updates input schema to conform to the input statistics.</p> <p>schema: A Schema protocol buffer.   statistics: A DatasetFeatureStatisticsList protocol buffer. Schema inference     is currently supported only for lists with a single     DatasetFeatureStatistics proto or lists with multiple     DatasetFeatureStatistics protos corresponding to data slices that include     the default slice (i.e., the slice with all examples). If a list with     multiple DatasetFeatureStatistics protos is used, this function will     update the schema to conform to the statistics corresponding to the     default slice.   infer_feature_shape: DEPRECATED, do not use. If a feature specifies     a shape, the shape will always be validated. If the feature does not     specify a shape, this function will not try inferring a shape from the     given statistics.   max_string_domain_size: Maximum size of the domain of a string feature in     order to be interpreted as a categorical feature.</p> <p>A Schema protocol buffer.</p> <p>TypeError: If the input argument is not of the expected type.   ValueError: If the input statistics proto contains multiple datasets, none       of which corresponds to the default slice.</p> Source code in <code>tensorflow_data_validation/api/validation_api.py</code> <pre><code>def update_schema(\n    schema: schema_pb2.Schema,\n    statistics: statistics_pb2.DatasetFeatureStatisticsList,\n    infer_feature_shape: Optional[bool] = True,\n    max_string_domain_size: Optional[int] = 100,\n) -&gt; schema_pb2.Schema:\n    \"\"\"Updates input schema to conform to the input statistics.\n\n    Args:\n    ----\n      schema: A Schema protocol buffer.\n      statistics: A DatasetFeatureStatisticsList protocol buffer. Schema inference\n        is currently supported only for lists with a single\n        DatasetFeatureStatistics proto or lists with multiple\n        DatasetFeatureStatistics protos corresponding to data slices that include\n        the default slice (i.e., the slice with all examples). If a list with\n        multiple DatasetFeatureStatistics protos is used, this function will\n        update the schema to conform to the statistics corresponding to the\n        default slice.\n      infer_feature_shape: DEPRECATED, do not use. If a feature specifies\n        a shape, the shape will always be validated. If the feature does not\n        specify a shape, this function will not try inferring a shape from the\n        given statistics.\n      max_string_domain_size: Maximum size of the domain of a string feature in\n        order to be interpreted as a categorical feature.\n\n    Returns:\n    -------\n      A Schema protocol buffer.\n\n    Raises:\n    ------\n      TypeError: If the input argument is not of the expected type.\n      ValueError: If the input statistics proto contains multiple datasets, none\n          of which corresponds to the default slice.\n    \"\"\"\n    del infer_feature_shape\n\n    if not isinstance(schema, schema_pb2.Schema):\n        raise TypeError(\n            \"schema is of type %s, should be a Schema proto.\" % type(schema).__name__\n        )\n    if not isinstance(statistics, statistics_pb2.DatasetFeatureStatisticsList):\n        raise TypeError(\n            \"statistics is of type %s, should be \"\n            \"a DatasetFeatureStatisticsList proto.\" % type(statistics).__name__\n        )\n\n    # This will raise an exception if there are multiple datasets, none of which\n    # corresponds to the default slice.\n    dataset_statistics = _get_default_dataset_statistics(statistics)\n\n    schema_proto_string = pywrap_tensorflow_data_validation.UpdateSchema(\n        tf.compat.as_bytes(schema.SerializeToString()),\n        tf.compat.as_bytes(dataset_statistics.SerializeToString()),\n        max_string_domain_size,\n    )\n\n    # Parse the serialized Schema proto.\n    result = schema_pb2.Schema()\n    result.ParseFromString(schema_proto_string)\n\n    return result\n</code></pre>"},{"location":"api/#tensorflow_data_validation.validate_corresponding_slices","title":"validate_corresponding_slices","text":"<pre><code>validate_corresponding_slices(\n    statistics: DatasetFeatureStatisticsList,\n    schema: Schema,\n    environment: Optional[str] = None,\n    previous_statistics: Optional[\n        DatasetFeatureStatisticsList\n    ] = None,\n    serving_statistics: Optional[\n        DatasetFeatureStatisticsList\n    ] = None,\n) -&gt; Anomalies\n</code></pre> <p>Validates corresponding sliced statistics.</p> <p>Sliced statistics are flattened into a single unsliced stats input prior to validation. If multiple statistics are provided, validation is performed on corresponding slices. DatasetConstraints, if present, are applied to the overall slice.</p> <p>Note: This API is experimental and subject to change.</p> <p>statistics: See validate_statistics.   schema: See validate_statistics.   environment: See validate_statistics.   previous_statistics: See validate_statistics.   serving_statistics: See validate_statistics.</p> <p>An Anomalies protocol buffer.</p> <p>TypeError: If any of the input arguments is not of the expected type.</p> Source code in <code>tensorflow_data_validation/api/validation_api.py</code> <pre><code>def validate_corresponding_slices(\n    statistics: statistics_pb2.DatasetFeatureStatisticsList,\n    schema: schema_pb2.Schema,\n    environment: Optional[str] = None,\n    previous_statistics: Optional[statistics_pb2.DatasetFeatureStatisticsList] = None,\n    serving_statistics: Optional[statistics_pb2.DatasetFeatureStatisticsList] = None,\n) -&gt; anomalies_pb2.Anomalies:\n    \"\"\"Validates corresponding sliced statistics.\n\n    Sliced statistics are flattened into a single unsliced stats input prior to\n    validation. If multiple statistics are provided, validation is performed on\n    corresponding slices. DatasetConstraints, if present, are applied to the\n    overall slice.\n\n    Note: This API is experimental and subject to change.\n\n    Args:\n    ----\n      statistics: See validate_statistics.\n      schema: See validate_statistics.\n      environment: See validate_statistics.\n      previous_statistics: See validate_statistics.\n      serving_statistics: See validate_statistics.\n\n    Returns:\n    -------\n      An Anomalies protocol buffer.\n\n    Raises:\n    ------\n      TypeError: If any of the input arguments is not of the expected type.\n    \"\"\"\n    all_slice_keys = set()\n    statistics, keys = _flatten_statistics_for_sliced_validation(statistics)\n    all_slice_keys.update(keys)\n    if previous_statistics:\n        previous_statistics, keys = _flatten_statistics_for_sliced_validation(\n            previous_statistics\n        )\n        all_slice_keys.update(keys)\n    if serving_statistics:\n        serving_statistics, keys = _flatten_statistics_for_sliced_validation(\n            serving_statistics\n        )\n        all_slice_keys.update(keys)\n    schema = _replicate_schema_for_sliced_validation(schema, all_slice_keys)\n    return validate_statistics(\n        statistics, schema, environment, previous_statistics, serving_statistics\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation.validate_examples_in_csv","title":"validate_examples_in_csv","text":"<pre><code>validate_examples_in_csv(\n    data_location: str,\n    stats_options: StatsOptions,\n    column_names: Optional[List[FeatureName]] = None,\n    delimiter: str = \",\",\n    output_path: Optional[str] = None,\n    pipeline_options: Optional[PipelineOptions] = None,\n    num_sampled_examples=0,\n) -&gt; Union[\n    DatasetFeatureStatisticsList,\n    Tuple[\n        DatasetFeatureStatisticsList,\n        Mapping[str, DataFrame],\n    ],\n]\n</code></pre> <p>Validates examples in csv files.</p> <p>Runs a Beam pipeline to detect anomalies on a per-example basis. If this function detects anomalous examples, it generates summary statistics regarding the set of examples that exhibit each anomaly.</p> <p>This is a convenience function for users with data in CSV format. Users with data in unsupported file/data formats, or users who wish to create their own Beam pipelines need to use the 'IdentifyAnomalousExamples' PTransform API directly instead.</p> <p>data_location: The location of the input data files.   stats_options: <code>tfdv.StatsOptions</code> for generating data statistics. This must     contain a schema.   column_names: A list of column names to be treated as the CSV header. Order     must match the order in the input CSV files. If this argument is not     specified, we assume the first line in the input CSV files as the header.     Note that this option is valid only for 'csv' input file format.   delimiter: A one-character string used to separate fields in a CSV file.   output_path: The file path to output data statistics result to. If None, the     function uses a temporary directory. The output will be a TFRecord file     containing a single data statistics list proto, and can be read with the     'load_statistics' function. If you run this function on Google Cloud, you     must specify an output_path. Specifying None may cause an error.   pipeline_options: Optional beam pipeline options. This allows users to     specify various beam pipeline execution parameters like pipeline runner     (DirectRunner or DataflowRunner), cloud dataflow service project id, etc.     See https://cloud.google.com/dataflow/pipelines/specifying-exec-params for       more details.   num_sampled_examples: If set, returns up to this many examples of each     anomaly type as a map from anomaly reason string to pd.DataFrame.</p> <p>If num_sampled_examples is zero, returns a single   DatasetFeatureStatisticsList proto in which each dataset consists of the   set of examples that exhibit a particular anomaly. If   num_sampled_examples is nonzero, returns the same statistics   proto as well as a mapping from anomaly to a pd.DataFrame of CSV rows   exhibiting that anomaly.</p> <p>ValueError: If the specified stats_options does not include a schema.</p> Source code in <code>tensorflow_data_validation/utils/validation_lib.py</code> <pre><code>def validate_examples_in_csv(\n    data_location: str,\n    stats_options: options.StatsOptions,\n    column_names: Optional[List[types.FeatureName]] = None,\n    delimiter: str = \",\",\n    output_path: Optional[str] = None,\n    pipeline_options: Optional[PipelineOptions] = None,\n    num_sampled_examples=0,\n) -&gt; Union[\n    statistics_pb2.DatasetFeatureStatisticsList,\n    Tuple[statistics_pb2.DatasetFeatureStatisticsList, Mapping[str, pd.DataFrame]],\n]:\n    \"\"\"Validates examples in csv files.\n\n    Runs a Beam pipeline to detect anomalies on a per-example basis. If this\n    function detects anomalous examples, it generates summary statistics regarding\n    the set of examples that exhibit each anomaly.\n\n    This is a convenience function for users with data in CSV format.\n    Users with data in unsupported file/data formats, or users who wish\n    to create their own Beam pipelines need to use the 'IdentifyAnomalousExamples'\n    PTransform API directly instead.\n\n    Args:\n    ----\n      data_location: The location of the input data files.\n      stats_options: `tfdv.StatsOptions` for generating data statistics. This must\n        contain a schema.\n      column_names: A list of column names to be treated as the CSV header. Order\n        must match the order in the input CSV files. If this argument is not\n        specified, we assume the first line in the input CSV files as the header.\n        Note that this option is valid only for 'csv' input file format.\n      delimiter: A one-character string used to separate fields in a CSV file.\n      output_path: The file path to output data statistics result to. If None, the\n        function uses a temporary directory. The output will be a TFRecord file\n        containing a single data statistics list proto, and can be read with the\n        'load_statistics' function. If you run this function on Google Cloud, you\n        must specify an output_path. Specifying None may cause an error.\n      pipeline_options: Optional beam pipeline options. This allows users to\n        specify various beam pipeline execution parameters like pipeline runner\n        (DirectRunner or DataflowRunner), cloud dataflow service project id, etc.\n        See https://cloud.google.com/dataflow/pipelines/specifying-exec-params for\n          more details.\n      num_sampled_examples: If set, returns up to this many examples of each\n        anomaly type as a map from anomaly reason string to pd.DataFrame.\n\n    Returns:\n    -------\n      If num_sampled_examples is zero, returns a single\n      DatasetFeatureStatisticsList proto in which each dataset consists of the\n      set of examples that exhibit a particular anomaly. If\n      num_sampled_examples is nonzero, returns the same statistics\n      proto as well as a mapping from anomaly to a pd.DataFrame of CSV rows\n      exhibiting that anomaly.\n\n    Raises:\n    ------\n      ValueError: If the specified stats_options does not include a schema.\n    \"\"\"\n    if stats_options.schema is None:\n        raise ValueError(\"The specified stats_options must include a schema.\")\n    if output_path is None:\n        output_path = os.path.join(tempfile.mkdtemp(), \"anomaly_stats.tfrecord\")\n    output_dir_path = os.path.dirname(output_path)\n    if not tf.io.gfile.exists(output_dir_path):\n        tf.io.gfile.makedirs(output_dir_path)\n    if num_sampled_examples:\n        sample_materializer = io_util.Materializer(output_dir_path)\n\n    # If a header is not provided, assume the first line in a file\n    # to be the header.\n    skip_header_lines = 1 if column_names is None else 0\n    if column_names is None:\n        column_names = stats_gen_lib.get_csv_header(data_location, delimiter)\n\n    with beam.Pipeline(options=pipeline_options) as p:\n        anomalous_examples = (\n            p\n            | \"ReadData\"\n            &gt;&gt; beam.io.textio.ReadFromText(\n                file_pattern=data_location, skip_header_lines=skip_header_lines\n            )\n            | \"DecodeData\"\n            &gt;&gt; csv_decoder.DecodeCSV(\n                column_names=column_names,\n                delimiter=delimiter,\n                schema=stats_options.schema\n                if stats_options.infer_type_from_schema\n                else None,\n                desired_batch_size=1,\n            )\n            | \"DetectAnomalies\"\n            &gt;&gt; validation_api.IdentifyAnomalousExamples(stats_options)\n        )\n        _ = (\n            anomalous_examples\n            | \"GenerateSummaryStatistics\"\n            &gt;&gt; stats_impl.GenerateSlicedStatisticsImpl(\n                stats_options, is_slicing_enabled=True\n            )\n            | \"WriteStatsOutput\" &gt;&gt; stats_api.WriteStatisticsToTFRecord(output_path)\n        )\n        if num_sampled_examples:\n            _ = (\n                anomalous_examples\n                | \"Sample\"\n                &gt;&gt; beam.combiners.Sample.FixedSizePerKey(num_sampled_examples)\n                | \"ToPandas\" &gt;&gt; beam.FlatMap(_encode_pandas_and_key)\n                | \"WriteSamples\" &gt;&gt; sample_materializer.writer()\n            )\n\n    if num_sampled_examples:\n        samples_per_reason_acc = collections.defaultdict(list)\n        for reason, pandas_dataframe in sample_materializer.reader():\n            samples_per_reason_acc[reason].append(pandas_dataframe)\n        samples_per_reason = {}\n        for reason, dataframes in samples_per_reason_acc.items():\n            samples_per_reason[reason] = pd.concat(dataframes)\n        sample_materializer.cleanup()\n        return stats_util.load_statistics(output_path), samples_per_reason\n    return stats_util.load_statistics(output_path)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.validate_examples_in_tfrecord","title":"validate_examples_in_tfrecord","text":"<pre><code>validate_examples_in_tfrecord(\n    data_location: str,\n    stats_options: StatsOptions,\n    output_path: Optional[str] = None,\n    pipeline_options: Optional[PipelineOptions] = None,\n    num_sampled_examples=0,\n) -&gt; Union[\n    DatasetFeatureStatisticsList,\n    Tuple[\n        DatasetFeatureStatisticsList,\n        Mapping[str, List[Example]],\n    ],\n]\n</code></pre> <p>Validates TFExamples in TFRecord files.</p> <p>Runs a Beam pipeline to detect anomalies on a per-example basis. If this function detects anomalous examples, it generates summary statistics regarding the set of examples that exhibit each anomaly.</p> <p>This is a convenience function for users with data in TFRecord format. Users with data in unsupported file/data formats, or users who wish to create their own Beam pipelines need to use the 'IdentifyAnomalousExamples' PTransform API directly instead.</p> <p>data_location: The location of the input data files.   stats_options: <code>tfdv.StatsOptions</code> for generating data statistics. This must     contain a schema.   output_path: The file path to output data statistics result to. If None, the     function uses a temporary directory. The output will be a TFRecord file     containing a single data statistics list proto, and can be read with the     'load_statistics' function.     If you run this function on Google Cloud, you must specify an     output_path. Specifying None may cause an error.   pipeline_options: Optional beam pipeline options. This allows users to     specify various beam pipeline execution parameters like pipeline runner     (DirectRunner or DataflowRunner), cloud dataflow service project id, etc.     See https://cloud.google.com/dataflow/pipelines/specifying-exec-params for     more details.   num_sampled_examples: If set, returns up to this many examples     of each anomaly type as a map from anomaly reason string to a list of     tf.Examples.</p> <p>If num_sampled_examples is zero, returns a single   DatasetFeatureStatisticsList proto in which each dataset consists of the   set of examples that exhibit a particular anomaly. If   num_sampled_examples is nonzero, returns the same statistics   proto as well as a mapping from anomaly to a list of tf.Examples that   exhibited that anomaly.</p> <p>ValueError: If the specified stats_options does not include a schema.</p> Source code in <code>tensorflow_data_validation/utils/validation_lib.py</code> <pre><code>def validate_examples_in_tfrecord(\n    data_location: str,\n    stats_options: options.StatsOptions,\n    output_path: Optional[str] = None,\n    pipeline_options: Optional[PipelineOptions] = None,\n    num_sampled_examples=0,\n) -&gt; Union[\n    statistics_pb2.DatasetFeatureStatisticsList,\n    Tuple[\n        statistics_pb2.DatasetFeatureStatisticsList,\n        Mapping[str, List[tf.train.Example]],\n    ],\n]:\n    \"\"\"Validates TFExamples in TFRecord files.\n\n    Runs a Beam pipeline to detect anomalies on a per-example basis. If this\n    function detects anomalous examples, it generates summary statistics regarding\n    the set of examples that exhibit each anomaly.\n\n    This is a convenience function for users with data in TFRecord format.\n    Users with data in unsupported file/data formats, or users who wish\n    to create their own Beam pipelines need to use the 'IdentifyAnomalousExamples'\n    PTransform API directly instead.\n\n    Args:\n    ----\n      data_location: The location of the input data files.\n      stats_options: `tfdv.StatsOptions` for generating data statistics. This must\n        contain a schema.\n      output_path: The file path to output data statistics result to. If None, the\n        function uses a temporary directory. The output will be a TFRecord file\n        containing a single data statistics list proto, and can be read with the\n        'load_statistics' function.\n        If you run this function on Google Cloud, you must specify an\n        output_path. Specifying None may cause an error.\n      pipeline_options: Optional beam pipeline options. This allows users to\n        specify various beam pipeline execution parameters like pipeline runner\n        (DirectRunner or DataflowRunner), cloud dataflow service project id, etc.\n        See https://cloud.google.com/dataflow/pipelines/specifying-exec-params for\n        more details.\n      num_sampled_examples: If set, returns up to this many examples\n        of each anomaly type as a map from anomaly reason string to a list of\n        tf.Examples.\n\n    Returns:\n    -------\n      If num_sampled_examples is zero, returns a single\n      DatasetFeatureStatisticsList proto in which each dataset consists of the\n      set of examples that exhibit a particular anomaly. If\n      num_sampled_examples is nonzero, returns the same statistics\n      proto as well as a mapping from anomaly to a list of tf.Examples that\n      exhibited that anomaly.\n\n    Raises:\n    ------\n      ValueError: If the specified stats_options does not include a schema.\n    \"\"\"\n    if stats_options.schema is None:\n        raise ValueError(\"The specified stats_options must include a schema.\")\n    if output_path is None:\n        output_path = os.path.join(tempfile.mkdtemp(), \"anomaly_stats.tfrecord\")\n    output_dir_path = os.path.dirname(output_path)\n    if not tf.io.gfile.exists(output_dir_path):\n        tf.io.gfile.makedirs(output_dir_path)\n    with io_util.Materializer(output_dir_path) as sample_materializer:\n        with beam.Pipeline(options=pipeline_options) as p:\n            anomalous_examples = (\n                p\n                | \"ReadData\"\n                &gt;&gt; (\n                    tf_example_record.TFExampleRecord(\n                        file_pattern=data_location,\n                        schema=None,\n                        telemetry_descriptors=[\"tfdv\", \"validate_examples_in_tfrecord\"],\n                    ).BeamSource(batch_size=1)\n                )\n                | \"DetectAnomalies\"\n                &gt;&gt; validation_api.IdentifyAnomalousExamples(stats_options)\n            )\n            _ = (\n                anomalous_examples\n                | \"GenerateSummaryStatistics\"\n                &gt;&gt; stats_impl.GenerateSlicedStatisticsImpl(\n                    stats_options, is_slicing_enabled=True\n                )\n                | \"WriteStatsOutput\" &gt;&gt; stats_api.WriteStatisticsToTFRecord(output_path)\n            )\n            if num_sampled_examples:\n                # TODO(b/68154497): Relint\n                # pylint: disable=no-value-for-parameter\n                _ = (\n                    anomalous_examples\n                    | \"Sample\"\n                    &gt;&gt; beam.combiners.Sample.FixedSizePerKey(num_sampled_examples)\n                    | \"ToExample\"\n                    &gt;&gt; _record_batch_to_example_fn(\n                        example_coder.RecordBatchToExamplesEncoder(stats_options.schema)\n                    )\n                    | \"WriteSamples\" &gt;&gt; sample_materializer.writer()\n                )\n                # pylint: enable=no-value-for-parameter\n        if num_sampled_examples:\n            samples_per_reason = collections.defaultdict(list)\n            for reason, serialized_example in sample_materializer.reader():\n                samples_per_reason[reason].append(\n                    tf.train.Example.FromString(serialized_example)\n                )\n            return stats_util.load_statistics(output_path), samples_per_reason\n    return stats_util.load_statistics(output_path)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.validate_statistics","title":"validate_statistics","text":"<pre><code>validate_statistics(\n    statistics: DatasetFeatureStatisticsList,\n    schema: Schema,\n    environment: Optional[str] = None,\n    previous_statistics: Optional[\n        DatasetFeatureStatisticsList\n    ] = None,\n    serving_statistics: Optional[\n        DatasetFeatureStatisticsList\n    ] = None,\n) -&gt; Anomalies\n</code></pre> <p>Validates the input statistics against the provided input schema.</p> <p>This method validates the <code>statistics</code> against the <code>schema</code>. If an optional <code>environment</code> is specified, the <code>schema</code> is filtered using the <code>environment</code> and the <code>statistics</code> is validated against the filtered schema. The optional <code>previous_statistics</code> and <code>serving_statistics</code> are the statistics computed over the control data for drift- and skew-detection, respectively.</p> <p>If drift- or skew-detection is conducted, then the raw skew/drift measurements for each feature that is compared will be recorded in the <code>drift_skew_info</code> field in the returned <code>Anomalies</code> proto.</p> <p>statistics: A DatasetFeatureStatisticsList protocol buffer denoting the      statistics computed over the current data. Validation is currently      supported only for lists with a single DatasetFeatureStatistics proto or      lists with multiple DatasetFeatureStatistics protos corresponding to data      slices that include the default slice (i.e., the slice with all      examples). If a list with multiple DatasetFeatureStatistics protos is      used, this function will validate the statistics corresponding to the      default slice.   schema: A Schema protocol buffer.      Note that TFDV does not currently support validation of the following      messages/fields in the Schema protocol buffer:      - FeaturePresenceWithinGroup      - Schema-level FloatDomain and IntDomain (validation is supported for        Feature-level FloatDomain and IntDomain)   environment: An optional string denoting the validation environment.       Must be one of the default environments specified in the schema.       By default, validation assumes that all Examples in a pipeline adhere       to a single schema. In some cases introducing slight schema variations       is necessary, for instance features used as labels are required during       training (and should be validated), but are missing during serving.       Environments can be used to express such requirements. For example,       assume a feature named 'LABEL' is required for training, but is expected       to be missing from serving. This can be expressed by defining two       distinct environments in schema: [\"SERVING\", \"TRAINING\"] and       associating 'LABEL' only with environment \"TRAINING\".   previous_statistics: An optional DatasetFeatureStatisticsList protocol       buffer denoting the statistics computed over an earlier data (for       example, previous day's data). If provided, the <code>validate_statistics</code>       method will detect if there exists drift between current data and       previous data. Configuration for drift detection can be done by       specifying a <code>drift_comparator</code> in the schema.   serving_statistics: An optional DatasetFeatureStatisticsList protocol       buffer denoting the statistics computed over the serving data. If       provided, the <code>validate_statistics</code> method will identify if there exists       distribution skew between current data and serving data. Configuration       for skew detection can be done by specifying a <code>skew_comparator</code> in the       schema.</p> <p>An Anomalies protocol buffer.</p> <p>TypeError: If any of the input arguments is not of the expected type.   ValueError: If the input statistics proto contains multiple datasets, none       of which corresponds to the default slice.</p> Source code in <code>tensorflow_data_validation/api/validation_api.py</code> <pre><code>def validate_statistics(\n    statistics: statistics_pb2.DatasetFeatureStatisticsList,\n    schema: schema_pb2.Schema,\n    environment: Optional[str] = None,\n    previous_statistics: Optional[statistics_pb2.DatasetFeatureStatisticsList] = None,\n    serving_statistics: Optional[statistics_pb2.DatasetFeatureStatisticsList] = None,\n) -&gt; anomalies_pb2.Anomalies:\n    \"\"\"Validates the input statistics against the provided input schema.\n\n    This method validates the `statistics` against the `schema`. If an optional\n    `environment` is specified, the `schema` is filtered using the\n    `environment` and the `statistics` is validated against the filtered schema.\n    The optional `previous_statistics` and `serving_statistics` are the statistics\n    computed over the control data for drift- and skew-detection, respectively.\n\n    If drift- or skew-detection is conducted, then the raw skew/drift measurements\n    for each feature that is compared will be recorded in the `drift_skew_info`\n    field in the returned `Anomalies` proto.\n\n    Args:\n    ----\n      statistics: A DatasetFeatureStatisticsList protocol buffer denoting the\n         statistics computed over the current data. Validation is currently\n         supported only for lists with a single DatasetFeatureStatistics proto or\n         lists with multiple DatasetFeatureStatistics protos corresponding to data\n         slices that include the default slice (i.e., the slice with all\n         examples). If a list with multiple DatasetFeatureStatistics protos is\n         used, this function will validate the statistics corresponding to the\n         default slice.\n      schema: A Schema protocol buffer.\n         Note that TFDV does not currently support validation of the following\n         messages/fields in the Schema protocol buffer:\n         - FeaturePresenceWithinGroup\n         - Schema-level FloatDomain and IntDomain (validation is supported for\n           Feature-level FloatDomain and IntDomain)\n      environment: An optional string denoting the validation environment.\n          Must be one of the default environments specified in the schema.\n          By default, validation assumes that all Examples in a pipeline adhere\n          to a single schema. In some cases introducing slight schema variations\n          is necessary, for instance features used as labels are required during\n          training (and should be validated), but are missing during serving.\n          Environments can be used to express such requirements. For example,\n          assume a feature named 'LABEL' is required for training, but is expected\n          to be missing from serving. This can be expressed by defining two\n          distinct environments in schema: [\"SERVING\", \"TRAINING\"] and\n          associating 'LABEL' only with environment \"TRAINING\".\n      previous_statistics: An optional DatasetFeatureStatisticsList protocol\n          buffer denoting the statistics computed over an earlier data (for\n          example, previous day's data). If provided, the `validate_statistics`\n          method will detect if there exists drift between current data and\n          previous data. Configuration for drift detection can be done by\n          specifying a `drift_comparator` in the schema.\n      serving_statistics: An optional DatasetFeatureStatisticsList protocol\n          buffer denoting the statistics computed over the serving data. If\n          provided, the `validate_statistics` method will identify if there exists\n          distribution skew between current data and serving data. Configuration\n          for skew detection can be done by specifying a `skew_comparator` in the\n          schema.\n\n    Returns:\n    -------\n      An Anomalies protocol buffer.\n\n    Raises:\n    ------\n      TypeError: If any of the input arguments is not of the expected type.\n      ValueError: If the input statistics proto contains multiple datasets, none\n          of which corresponds to the default slice.\n    \"\"\"\n    # This check is added here because the arguments name for previous_statistics\n    # is different in TFX::OSS and TFX internal. It is preferred to report the\n    # error with the name used in the API.\n    if previous_statistics is not None:\n        if not isinstance(\n            previous_statistics, statistics_pb2.DatasetFeatureStatisticsList\n        ):\n            raise TypeError(\n                \"previous_statistics is of type %s, should be \"\n                \"a DatasetFeatureStatisticsList proto.\"\n                % type(previous_statistics).__name__\n            )\n\n    return validate_statistics_internal(\n        statistics,\n        schema,\n        environment,\n        previous_statistics,\n        serving_statistics,\n        None,\n        None,\n        False,\n    )\n</code></pre>"},{"location":"api/#tensorflow_data_validation.visualize_statistics","title":"visualize_statistics","text":"<pre><code>visualize_statistics(\n    lhs_statistics: DatasetFeatureStatisticsList,\n    rhs_statistics: Optional[\n        DatasetFeatureStatisticsList\n    ] = None,\n    lhs_name: str = \"lhs_statistics\",\n    rhs_name: str = \"rhs_statistics\",\n    allowlist_features: Optional[List[FeaturePath]] = None,\n    denylist_features: Optional[List[FeaturePath]] = None,\n) -&gt; None\n</code></pre> <p>Visualize the input statistics using Facets.</p> <p>lhs_statistics: A DatasetFeatureStatisticsList protocol buffer.   rhs_statistics: An optional DatasetFeatureStatisticsList protocol buffer to     compare with lhs_statistics.   lhs_name: Name to use for the lhs_statistics dataset if a name is not     already provided within the protocol buffer.   rhs_name: Name to use for the rhs_statistics dataset if a name is not     already provided within the protocol buffer.   allowlist_features: Set of features to be visualized.   denylist_features: Set of features to ignore for visualization.</p> <p>TypeError: If the input argument is not of the expected type.   ValueError: If the input statistics protos does not have only one dataset.</p> Source code in <code>tensorflow_data_validation/utils/display_util.py</code> <pre><code>def visualize_statistics(\n    lhs_statistics: statistics_pb2.DatasetFeatureStatisticsList,\n    rhs_statistics: Optional[statistics_pb2.DatasetFeatureStatisticsList] = None,\n    lhs_name: str = \"lhs_statistics\",\n    rhs_name: str = \"rhs_statistics\",\n    allowlist_features: Optional[List[types.FeaturePath]] = None,\n    denylist_features: Optional[List[types.FeaturePath]] = None,\n) -&gt; None:\n    \"\"\"Visualize the input statistics using Facets.\n\n    Args:\n    ----\n      lhs_statistics: A DatasetFeatureStatisticsList protocol buffer.\n      rhs_statistics: An optional DatasetFeatureStatisticsList protocol buffer to\n        compare with lhs_statistics.\n      lhs_name: Name to use for the lhs_statistics dataset if a name is not\n        already provided within the protocol buffer.\n      rhs_name: Name to use for the rhs_statistics dataset if a name is not\n        already provided within the protocol buffer.\n      allowlist_features: Set of features to be visualized.\n      denylist_features: Set of features to ignore for visualization.\n\n    Raises:\n    ------\n      TypeError: If the input argument is not of the expected type.\n      ValueError: If the input statistics protos does not have only one dataset.\n    \"\"\"\n    assert (\n        not allowlist_features or not denylist_features\n    ), \"Only specify one of allowlist_features and denylist_features.\"\n    html = get_statistics_html(\n        lhs_statistics,\n        rhs_statistics,\n        lhs_name,\n        rhs_name,\n        allowlist_features,\n        denylist_features,\n    )\n    display(HTML(html))\n</code></pre>"},{"location":"api/#tensorflow_data_validation.write_anomalies_text","title":"write_anomalies_text","text":"<pre><code>write_anomalies_text(\n    anomalies: Anomalies, output_path: str\n) -&gt; None\n</code></pre> <p>Writes the Anomalies proto to a file in text format.</p> <p>anomalies: An Anomalies protocol buffer.   output_path: File path to which to write the Anomalies proto.</p> <p>TypeError: If the input Anomalies proto is not of the expected type.</p> Source code in <code>tensorflow_data_validation/utils/anomalies_util.py</code> <pre><code>def write_anomalies_text(anomalies: anomalies_pb2.Anomalies, output_path: str) -&gt; None:\n    \"\"\"Writes the Anomalies proto to a file in text format.\n\n    Args:\n    ----\n      anomalies: An Anomalies protocol buffer.\n      output_path: File path to which to write the Anomalies proto.\n\n    Raises:\n    ------\n      TypeError: If the input Anomalies proto is not of the expected type.\n    \"\"\"\n    if not isinstance(anomalies, anomalies_pb2.Anomalies):\n        raise TypeError(\n            \"anomalies is of type %s; should be an Anomalies proto.\"\n            % type(anomalies).__name__\n        )\n\n    anomalies_text = text_format.MessageToString(anomalies)\n    io_util.write_string_to_file(output_path, anomalies_text)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.write_schema_text","title":"write_schema_text","text":"<pre><code>write_schema_text(schema: Schema, output_path: str) -&gt; None\n</code></pre> <p>Writes input schema to a file in text format.</p> <p>schema: A Schema protocol buffer.   output_path: File path to write the input schema.</p> <p>TypeError: If the input schema is not of the expected type.</p> Source code in <code>tensorflow_data_validation/utils/schema_util.py</code> <pre><code>def write_schema_text(schema: schema_pb2.Schema, output_path: str) -&gt; None:\n    \"\"\"Writes input schema to a file in text format.\n\n    Args:\n    ----\n      schema: A Schema protocol buffer.\n      output_path: File path to write the input schema.\n\n    Raises:\n    ------\n      TypeError: If the input schema is not of the expected type.\n    \"\"\"\n    if not isinstance(schema, schema_pb2.Schema):\n        raise TypeError(\n            \"schema is of type %s, should be a Schema proto.\" % type(schema).__name__\n        )\n\n    schema_text = text_format.MessageToString(schema)\n    io_util.write_string_to_file(output_path, schema_text)\n</code></pre>"},{"location":"api/#tensorflow_data_validation.write_stats_text","title":"write_stats_text","text":"<pre><code>write_stats_text(\n    stats: DatasetFeatureStatisticsList, output_path: str\n) -&gt; None\n</code></pre> <p>Writes a DatasetFeatureStatisticsList proto to a file in text format.</p> <p>stats: A DatasetFeatureStatisticsList proto.   output_path: File path to write the DatasetFeatureStatisticsList proto.</p> <p>TypeError: If the input proto is not of the expected type.</p> Source code in <code>tensorflow_data_validation/utils/stats_util.py</code> <pre><code>def write_stats_text(\n    stats: statistics_pb2.DatasetFeatureStatisticsList, output_path: str\n) -&gt; None:\n    \"\"\"Writes a DatasetFeatureStatisticsList proto to a file in text format.\n\n    Args:\n    ----\n      stats: A DatasetFeatureStatisticsList proto.\n      output_path: File path to write the DatasetFeatureStatisticsList proto.\n\n    Raises:\n    ------\n      TypeError: If the input proto is not of the expected type.\n    \"\"\"\n    if not isinstance(stats, statistics_pb2.DatasetFeatureStatisticsList):\n        raise TypeError(\n            \"stats is of type %s, should be a \"\n            \"DatasetFeatureStatisticsList proto.\" % type(stats).__name__\n        )\n\n    stats_proto_text = text_format.MessageToString(stats)\n    io_util.write_string_to_file(output_path, stats_proto_text)\n</code></pre>"},{"location":"custom_data_validation/","title":"Custom Data Validation","text":"<p>TFDV supports custom data validation using SQL. You can run custom data validation using validate_statistics or custom_validate_statistics. Use <code>validate_statistics</code> to run standard, schema-based data validation along with custom validation. Use <code>custom_validate_statistics</code> to run only custom validation.</p>"},{"location":"custom_data_validation/#configuring-custom-data-validation","title":"Configuring Custom Data Validation","text":"<p>Use the CustomValidationConfig to define custom validations to run. For each validation, provide an SQL expression, which returns a boolean value. Each SQL expression is run against the summary statistics for the specified feature. If the expression returns false, TFDV generates a custom anomaly using the provided severity and anomaly description.</p> <p>You may configure custom validations that run against individual features or feature pairs. For each feature, specify both the dataset (i.e., slice) and the feature path to use, though you may leave the dataset name blank if you want to validate the default slice (i.e., all examples). For single feature validations, the feature statistics are bound to <code>feature</code>. For feature pair validations, the test feature statistics are bound to <code>feature_test</code> and the base feature statistics are bound to <code>feature_base</code>. See the section below for example queries.</p> <p>If a custom validation triggers an anomaly, TFDV will return an Anomalies proto with the reason(s) for the anomaly. Each reason will have a short description, which is user configured, and a description with the query that caused the anomaly, the dataset names on which the query was run, and the base feature path (if running a feature-pair validation). See the section below for example results of custom validation.</p> <p>See the documentation in the <code>CustomValidationConfig</code> proto for example configurations.</p>"},{"location":"get_started/","title":"Get started with TensorFlow Data Validation","text":"<p>TensorFlow Data Validation (TFDV) can analyze training and serving data to:</p> <ul> <li> <p>compute descriptive     statistics,</p> </li> <li> <p>infer a     schema,</p> </li> <li> <p>detect     data anomalies.</p> </li> </ul> <p>The core API supports each piece of functionality, with convenience methods that build on top and can be called in the context of notebooks.</p>"},{"location":"get_started/#computing-descriptive-data-statistics","title":"Computing descriptive data statistics","text":"<p>TFDV can compute descriptive statistics that provide a quick overview of the data in terms of the features that are present and the shapes of their value distributions. Tools such as Facets Overview can provide a succinct visualization of these statistics for easy browsing.</p> <p>For example, suppose that <code>path</code> points to a file in the <code>TFRecord</code> format (which holds records of type <code>tensorflow.Example</code>). The following snippet illustrates the computation of statistics using TFDV:</p> <pre><code>    stats = tfdv.generate_statistics_from_tfrecord(data_location=path)\n</code></pre> <p>The returned value is a DatasetFeatureStatisticsList protocol buffer. The example notebook contains a visualization of the statistics using Facets Overview:</p> <pre><code>    tfdv.visualize_statistics(stats)\n</code></pre> <p></p> <p>The previous example assumes that the data is stored in a <code>TFRecord</code> file. TFDV also supports CSV input format, with extensibility for other common formats. You can find the available data decoders here. In addition, TFDV provides the <code>tfdv.generate_statistics_from_dataframe</code> utility function for users with in-memory data represented as a pandas DataFrame.</p> <p>In addition to computing a default set of data statistics, TFDV can also compute statistics for semantic domains (e.g., images, text). To enable computation of semantic domain statistics, pass a tfdv.StatsOptions object with <code>enable_semantic_domain_stats</code> set to True to <code>tfdv.generate_statistics_from_tfrecord</code>.</p>"},{"location":"get_started/#running-on-google-cloud","title":"Running on Google Cloud","text":"<p>Internally, TFDV uses Apache Beam's data-parallel processing framework to scale the computation of statistics over large datasets. For applications that wish to integrate deeper with TFDV (e.g. attach statistics generation at the end of a data-generation pipeline, generate statistics for data in custom format), the API also exposes a Beam PTransform for statistics generation.</p> <p>To run TFDV on Google Cloud, the TFDV wheel file must be downloaded and provided to the Dataflow workers. Download the wheel file to the current directory as follows:</p> <pre><code>pip download tensorflow_data_validation \\\n  --no-deps \\\n  --platform manylinux2010_x86_64 \\\n  --only-binary=:all:\n</code></pre> <p>The following snippet shows an example usage of TFDV on Google Cloud:</p> <pre><code>import tensorflow_data_validation as tfdv\nfrom apache_beam.options.pipeline_options import PipelineOptions, GoogleCloudOptions, StandardOptions, SetupOptions\n\nPROJECT_ID = ''\nJOB_NAME = ''\nGCS_STAGING_LOCATION = ''\nGCS_TMP_LOCATION = ''\nGCS_DATA_LOCATION = ''\n# GCS_STATS_OUTPUT_PATH is the file path to which to output the data statistics\n# result.\nGCS_STATS_OUTPUT_PATH = ''\n\nPATH_TO_WHL_FILE = ''\n\n\n# Create and set your PipelineOptions.\noptions = PipelineOptions()\n\n# For Cloud execution, set the Cloud Platform project, job_name,\n# staging location, temp_location and specify DataflowRunner.\ngoogle_cloud_options = options.view_as(GoogleCloudOptions)\ngoogle_cloud_options.project = PROJECT_ID\ngoogle_cloud_options.job_name = JOB_NAME\ngoogle_cloud_options.staging_location = GCS_STAGING_LOCATION\ngoogle_cloud_options.temp_location = GCS_TMP_LOCATION\noptions.view_as(StandardOptions).runner = 'DataflowRunner'\n\nsetup_options = options.view_as(SetupOptions)\n# PATH_TO_WHL_FILE should point to the downloaded tfdv wheel file.\nsetup_options.extra_packages = [PATH_TO_WHL_FILE]\n\ntfdv.generate_statistics_from_tfrecord(GCS_DATA_LOCATION,\n                                       output_path=GCS_STATS_OUTPUT_PATH,\n                                       pipeline_options=options)\n</code></pre> <p>In this case, the generated statistics proto is stored in a TFRecord file written to <code>GCS_STATS_OUTPUT_PATH</code>.</p> <p>NOTE When calling any of the <code>tfdv.generate_statistics_...</code> functions (e.g., <code>tfdv.generate_statistics_from_tfrecord</code>) on Google Cloud, you must provide an <code>output_path</code>. Specifying None may cause an error.</p>"},{"location":"get_started/#inferring-a-schema-over-the-data","title":"Inferring a schema over the data","text":"<p>The schema describes the expected properties of the data. Some of these properties are:</p> <ul> <li>which features are expected to be present</li> <li>their type</li> <li>the number of values for a feature in each example</li> <li>the presence of each feature across all examples</li> <li>the expected domains of features.</li> </ul> <p>In short, the schema describes the expectations for \"correct\" data and can thus be used to detect errors in the data (described below). Moreover, the same schema can be used to set up TensorFlow Transform for data transformations. Note that the schema is expected to be fairly static, e.g., several datasets can conform to the same schema, whereas statistics (described above) can vary per dataset.</p> <p>Since writing a schema can be a tedious task, especially for datasets with lots of features, TFDV provides a method to generate an initial version of the schema based on the descriptive statistics:</p> <pre><code>    schema = tfdv.infer_schema(stats)\n</code></pre> <p>In general, TFDV uses conservative heuristics to infer stable data properties from the statistics in order to avoid overfitting the schema to the specific dataset. It is strongly advised to review the inferred schema and refine it as needed, to capture any domain knowledge about the data that TFDV's heuristics might have missed.</p> <p>By default, <code>tfdv.infer_schema</code> infers the shape of each required feature, if <code>value_count.min</code> equals <code>value_count.max</code> for the feature. Set the <code>infer_feature_shape</code> argument to False to disable shape inference.</p> <p>The schema itself is stored as a Schema protocol buffer and can thus be updated/edited using the standard protocol-buffer API. TFDV also provides a few utility methods  to make these updates easier. For instance, suppose that the schema contains the following stanza to describe a required string feature <code>payment_type</code> that takes a single value:</p> <pre><code>feature {\n  name: \"payment_type\"\n  value_count {\n    min: 1\n    max: 1\n  }\n  type: BYTES\n  domain: \"payment_type\"\n  presence {\n    min_fraction: 1.0\n    min_count: 1\n  }\n}\n</code></pre> <p>To mark that the feature should be populated in at least 50% of the examples:</p> <pre><code>    tfdv.get_feature(schema, 'payment_type').presence.min_fraction = 0.5\n</code></pre> <p>The example notebook contains a simple visualization of the schema as a table, listing each feature and its main characteristics as encoded in the schema.</p> <p></p>"},{"location":"get_started/#checking-the-data-for-errors","title":"Checking the data for errors","text":"<p>Given a schema, it is possible to check whether a dataset conforms to the expectations set in the schema or whether there exist any [data anomalies] (https://github.com/tensorflow/data-validation/blob/master/g3doc/anomalies.md). You can check your data for errors (a) in the aggregate across an entire dataset by matching the statistics of the dataset against the schema, or (b) by checking for errors on a per-example basis.</p>"},{"location":"get_started/#matching-the-statistics-of-the-dataset-against-a-schema","title":"Matching the statistics of the dataset against a schema","text":"<p>To check for errors in the aggregate, TFDV matches the statistics of the dataset against the schema and marks any discrepancies. For example:</p> <pre><code>    # Assume that other_path points to another TFRecord file\n    other_stats = tfdv.generate_statistics_from_tfrecord(data_location=other_path)\n    anomalies = tfdv.validate_statistics(statistics=other_stats, schema=schema)\n</code></pre> <p>The result is an instance of the Anomalies protocol buffer and describes any errors where the statistics do not agree with the schema. For example, suppose that the data at <code>other_path</code> contains examples with values for the feature <code>payment_type</code> outside the domain specified in the schema.</p> <p>This produces an anomaly</p> <pre><code>   payment_type  Unexpected string values  Examples contain values missing from the schema: Prcard (&lt;1%).\n</code></pre> <p>indicating that an out of domain value was found in the stats in &lt; 1% of the feature values.</p> <p>If this was expected, then the schema can be updated as follows:</p> <pre><code>   tfdv.get_domain(schema, 'payment_type').value.append('Prcard')\n</code></pre> <p>If the anomaly truly indicates a data error, then the underlying data should be fixed before using it for training.</p> <p>The various anomaly types that can be detected by this module are listed here.</p> <p>The example notebook contains a simple visualization of the anomalies as a table, listing the features where errors are detected and a short description of each error.</p> <p></p>"},{"location":"get_started/#checking-for-errors-on-a-per-example-basis","title":"Checking for errors on a per-example basis","text":"<p>TFDV also provides the option to validate data on a per-example basis, instead of comparing dataset-wide statistics against the schema. TFDV provides functions for validating data on a per-example basis and then generating summary statistics for the anomalous examples found. For example:</p> <pre><code>   options = tfdv.StatsOptions(schema=schema)\n   anomalous_example_stats = tfdv.validate_examples_in_tfrecord(\n       data_location=input, stats_options=options)\n</code></pre> <p>The <code>anomalous_example_stats</code> that <code>validate_examples_in_tfrecord</code> returns is a DatasetFeatureStatisticsList protocol buffer in which each dataset consists of the set of examples that exhibit a particular anomaly. You can use this to determine the number of examples in your dataset that exhibit a given anomaly and the characteristics of those examples.</p>"},{"location":"get_started/#schema-environments","title":"Schema Environments","text":"<p>By default, validations assume that all datasets in a pipeline adhere to a single schema. In some cases introducing slight schema variations is necessary, for instance features used as labels are required during training (and should be validated), but are missing during serving.</p> <p>Environments can be used to express such requirements. In particular, features in schema can be associated with a set of environments using default_environment, in_environment and not_in_environment.</p> <p>For example, if the tips feature is being used as the label in training, but missing in the serving data. Without environment specified, it will show up as an anomaly.</p> <pre><code>    serving_stats = tfdv.generate_statistics_from_tfrecord(data_location=serving_data_path)\n    serving_anomalies = tfdv.validate_statistics(serving_stats, schema)\n</code></pre> <p></p> <p>To fix this, we need to set the default environment for all features to be both 'TRAINING' and 'SERVING', and exclude the 'tips' feature from SERVING environment.</p> <pre><code>    # All features are by default in both TRAINING and SERVING environments.\n    schema.default_environment.append('TRAINING')\n    schema.default_environment.append('SERVING')\n\n    # Specify that 'tips' feature is not in SERVING environment.\n    tfdv.get_feature(schema, 'tips').not_in_environment.append('SERVING')\n\n    serving_anomalies_with_env = tfdv.validate_statistics(\n        serving_stats, schema, environment='SERVING')\n</code></pre>"},{"location":"get_started/#checking-data-skew-and-drift","title":"Checking data skew and drift","text":"<p>In addition to checking whether a dataset conforms to the expectations set in the schema, TFDV also provides functionalities to detect:</p> <ul> <li>skew between training and serving data</li> <li>drift between different days of training data</li> </ul> <p>TFDV performs this check by comparing the statistics of different datasets based on the drift/skew comparators specified in the schema. For example, to check if there is any skew between 'payment_type' feature within training and serving dataset:</p> <pre><code>    # Assume we have already generated the statistics of training dataset, and\n    # inferred a schema from it.\n    serving_stats = tfdv.generate_statistics_from_tfrecord(data_location=serving_data_path)\n    # Add a skew comparator to schema for 'payment_type' and set the threshold\n    # of L-infinity norm for triggering skew anomaly to be 0.01.\n    tfdv.get_feature(schema, 'payment_type').skew_comparator.infinity_norm.threshold = 0.01\n    skew_anomalies = tfdv.validate_statistics(\n        statistics=train_stats, schema=schema, serving_statistics=serving_stats)\n</code></pre> <p>NOTE L-infinity norm will only detect skew for the categorical features. Instead of specifying an <code>infinity_norm</code> threshold, specifying a <code>jensen_shannon_divergence</code> threshold in the <code>skew_comparator</code> would detect skew for both numeric and categorical features.</p> <p>Same with checking whether a dataset conform to the expectations set in the schema, the result is also an instance of the Anomalies protocol buffer and describes any skew between the training and serving datasets. For example, suppose the serving data contains significantly more examples with feature <code>payement_type</code> having value <code>Cash</code>, this produces a skew anomaly</p> <pre><code>   payment_type  High L-infinity distance between serving and training  The L-infinity distance between serving and training is 0.0435984 (up to six significant digits), above the threshold 0.01. The feature value with maximum difference is: Cash\n</code></pre> <p>If the anomaly truly indicates a skew between training and serving data, then further investigation is necessary as this could have a direct impact on model performance.</p> <p>The example notebook contains a simple example of checking for skew-based anomalies.</p> <p>Detecting drift between different days of training data can be done in a similar way</p> <pre><code>    # Assume we have already generated the statistics of training dataset for\n    # day 2, and inferred a schema from it.\n    train_day1_stats = tfdv.generate_statistics_from_tfrecord(data_location=train_day1_data_path)\n    # Add a drift comparator to schema for 'payment_type' and set the threshold\n    # of L-infinity norm for triggering drift anomaly to be 0.01.\n    tfdv.get_feature(schema, 'payment_type').drift_comparator.infinity_norm.threshold = 0.01\n    drift_anomalies = tfdv.validate_statistics(\n        statistics=train_day2_stats, schema=schema, previous_statistics=train_day1_stats)\n</code></pre> <p>NOTE L-infinity norm will only detect skew for the categorical features. Instead of specifying an <code>infinity_norm</code> threshold, specifying a <code>jensen_shannon_divergence</code> threshold in the <code>skew_comparator</code> would detect skew for both numeric and categorical features.</p>"},{"location":"get_started/#writing-custom-data-connector","title":"Writing custom data connector","text":"<p>To compute data statistics, TFDV provides several convenient methods for handling input data in various formats (e.g. <code>TFRecord</code> of tf.train.Example, CSV, etc). If your data format is not in this list, you need to write a custom data connector for reading input data, and connect it with the TFDV core API for computing data statistics.</p> <p>The TFDV core API for computing data statistics is a Beam PTransform that takes a PCollection of batches of input examples (a batch of input examples is represented as an Arrow RecordBatch), and outputs a PCollection containing a single <code>DatasetFeatureStatisticsList</code> protocol buffer.</p> <p>Once you have implemented the custom data connector that batches your input examples in an Arrow RecordBatch, you need to connect it with the <code>tfdv.GenerateStatistics</code> API for computing the data statistics. Take <code>TFRecord</code> of <code>tf.train.Example</code>'s for example. <code>tfx_bsl</code> provides the TFExampleRecord data connector, and below is an example of how to connect it with the <code>tfdv.GenerateStatistics</code> API.</p> <pre><code>import tensorflow_data_validation as tfdv\nfrom tfx_bsl.public import tfxio\nimport apache_beam as beam\nfrom tensorflow_metadata.proto.v0 import statistics_pb2\n\nDATA_LOCATION = ''\nOUTPUT_LOCATION = ''\n\nwith beam.Pipeline() as p:\n    _ = (\n    p\n    # 1. Read and decode the data with tfx_bsl.\n    | 'TFXIORead' &gt;&gt; (\n          tfxio.TFExampleRecord(\n              file_pattern=[DATA_LOCATION],\n              telemetry_descriptors=['my', 'tfdv']).BeamSource())\n    # 2. Invoke TFDV `GenerateStatistics` API to compute the data statistics.\n    | 'GenerateStatistics' &gt;&gt; tfdv.GenerateStatistics()\n    # 3. Materialize the generated data statistics.\n    | 'WriteStatsOutput' &gt;&gt; WriteStatisticsToTFRecord(OUTPUT_LOCATION))\n</code></pre>"},{"location":"get_started/#computing-statistics-over-slices-of-data","title":"Computing statistics over slices of data","text":"<p>TFDV can be configured to compute statistics over slices of data. Slicing can be enabled by providing slicing functions which take in an Arrow <code>RecordBatch</code> and output a sequence of tuples of form <code>(slice key, record batch)</code>. TFDV provides an easy way to generate feature value based slicing functions which can be provided as part of <code>tfdv.StatsOptions</code> when computing statistics.</p> <p>When slicing is enabled, the output DatasetFeatureStatisticsList proto contains multiple DatasetFeatureStatistics protos, one for each slice. Each slice is identified by a unique name which is set as the dataset name in the DatasetFeatureStatistics proto. By default TFDV computes statistics for the overall dataset in addition to the configured slices.</p> <pre><code>import tensorflow_data_validation as tfdv\nfrom tensorflow_data_validation.utils import slicing_util\n\n# Slice on country feature (i.e., every unique value of the feature).\nslice_fn1 = slicing_util.get_feature_value_slicer(features={'country': None})\n\n# Slice on the cross of country and state feature (i.e., every unique pair of\n# values of the cross).\nslice_fn2 = slicing_util.get_feature_value_slicer(\n    features={'country': None, 'state': None})\n\n# Slice on specific values of a feature.\nslice_fn3 = slicing_util.get_feature_value_slicer(\n    features={'age': [10, 50, 70]})\n\nstats_options = tfdv.StatsOptions(\n    slice_functions=[slice_fn1, slice_fn2, slice_fn3])\n</code></pre>"},{"location":"install/","title":"TensorFlow Data Validation","text":"<p>TensorFlow Data Validation (TFDV) is a library for exploring and validating machine learning data. It is designed to be highly scalable and to work well with TensorFlow and TensorFlow Extended (TFX).</p> <p>TF Data Validation includes:</p> <ul> <li>Scalable calculation of summary statistics of training and test data.</li> <li>Integration with a viewer for data distributions and statistics, as well      as faceted comparison of pairs of features (Facets)</li> <li>Automated data-schema      generation to describe expectations about data      like required values, ranges, and vocabularies</li> <li>A schema viewer to help you inspect the schema.</li> <li>Anomaly detection to identify anomalies, such as missing features,      out-of-range values, or wrong feature types, to name a few.</li> <li>An anomalies viewer so that you can see what features have anomalies and      learn more in order to correct them.</li> </ul> <p>For instructions on using TFDV, see the get started guide and try out the example notebook. Some of the techniques implemented in TFDV are described in a technical paper published in SysML'19.</p> <p>Caution: TFDV may be backwards incompatible before version 1.0.</p>"},{"location":"install/#installing-from-pypi","title":"Installing from PyPI","text":"<p>The recommended way to install TFDV is using the PyPI package:</p> <pre><code>pip install tensorflow-data-validation\n</code></pre>"},{"location":"install/#nightly-packages","title":"Nightly Packages","text":"<p>TFDV also hosts nightly packages on Google Cloud. To install the latest nightly package, please use the following command:</p> <pre><code>export TFX_DEPENDENCY_SELECTOR=NIGHTLY\npip install --extra-index-url https://pypi-nightly.tensorflow.org/simple tensorflow-data-validation\n</code></pre> <p>This will install the nightly packages for the major dependencies of TFDV such as TensorFlow Metadata (TFMD) and TFX Basic Shared Libraries (TFX-BSL).</p> <p>Sometimes TFDV uses those dependencies' most recent changes, which are not yet released. Because of this, it is safer to use nightly versions of those dependent libraries when using nightly TFDV. Export the <code>TFX_DEPENDENCY_SELECTOR</code> environment variable to do so.</p> <p>Note: These nightly packages are unstable and breakages are likely to happen. The fix could often take a week or more depending on the complexity involved.</p>"},{"location":"install/#build-with-docker","title":"Build with Docker","text":"<p>This is the recommended way to build TFDV under Linux, and is continuously tested at Google.</p>"},{"location":"install/#1-install-docker","title":"1. Install Docker","text":"<p>Please first install <code>docker</code> and <code>docker-compose</code> by following the directions: docker; docker-compose.</p>"},{"location":"install/#2-clone-the-tfdv-repository","title":"2. Clone the TFDV repository","text":"<pre><code>git clone https://github.com/tensorflow/data-validation\ncd data-validation\n</code></pre> <p>Note that these instructions will install the latest master branch of TensorFlow Data Validation. If you want to install a specific branch (such as a release branch), pass <code>-b &lt;branchname&gt;</code> to the <code>git clone</code> command.</p>"},{"location":"install/#3-build-the-pip-package","title":"3. Build the pip package","text":"<p>Then, run the following at the project root:</p> <pre><code>sudo docker-compose build manylinux2010\nsudo docker-compose run -e PYTHON_VERSION=${PYTHON_VERSION} manylinux2010\n</code></pre> <p>where <code>PYTHON_VERSION</code> is one of <code>{39, 310, 311}</code>.</p> <p>A wheel will be produced under <code>dist/</code>.</p>"},{"location":"install/#4-install-the-pip-package","title":"4. Install the pip package","text":"<pre><code>pip install dist/*.whl\n</code></pre>"},{"location":"install/#build-from-source","title":"Build from source","text":""},{"location":"install/#1-prerequisites","title":"1. Prerequisites","text":"<p>To compile and use TFDV, you need to set up some prerequisites.</p>"},{"location":"install/#install-numpy","title":"Install NumPy","text":"<p>If NumPy is not installed on your system, install it now by following these directions.</p>"},{"location":"install/#install-bazel","title":"Install Bazel","text":"<p>If Bazel is not installed on your system, install it now by following these directions.</p>"},{"location":"install/#2-clone-the-tfdv-repository_1","title":"2. Clone the TFDV repository","text":"<pre><code>git clone https://github.com/tensorflow/data-validation\ncd data-validation\n</code></pre> <p>Note that these instructions will install the latest master branch of TensorFlow Data Validation. If you want to install a specific branch (such as a release branch), pass <code>-b &lt;branchname&gt;</code> to the <code>git clone</code> command.</p>"},{"location":"install/#3-build-the-pip-package_1","title":"3. Build the pip package","text":"<p><code>TFDV</code> wheel is Python version dependent -- to build the pip package that works for a specific Python version, use that Python binary to run:</p> <pre><code>python setup.py bdist_wheel\n</code></pre> <p>You can find the generated <code>.whl</code> file in the <code>dist</code> subdirectory.</p>"},{"location":"install/#4-install-the-pip-package_1","title":"4. Install the pip package","text":"<pre><code>pip install dist/*.whl\n</code></pre>"},{"location":"install/#supported-platforms","title":"Supported platforms","text":"<p>TFDV is tested on the following 64-bit operating systems:</p> <ul> <li>macOS 12.5 (Monterey) or later.</li> <li>Ubuntu 20.04 or later.</li> </ul>"},{"location":"install/#notable-dependencies","title":"Notable Dependencies","text":"<p>TensorFlow is required.</p> <p>Apache Beam is required; it's the way that efficient distributed computation is supported. By default, Apache Beam runs in local mode but can also run in distributed mode using Google Cloud Dataflow and other Apache Beam runners.</p> <p>Apache Arrow is also required. TFDV uses Arrow to represent data internally in order to make use of vectorized numpy functions.</p>"},{"location":"install/#compatible-versions","title":"Compatible versions","text":"<p>The following table shows the  package versions that are compatible with each other. This is determined by our testing framework, but other untested combinations may also work.</p> tensorflow-data-validation apache-beam[gcp] pyarrow tensorflow tensorflow-metadata tensorflow-transform tfx-bsl GitHub master 2.65.0 10.0.1 nightly (1.x/2.x) 1.17.1 n/a 1.17.1 1.17.0 2.65.0 10.0.1 2.17 1.17.1 n/a 1.17.1 1.16.1 2.59.0 10.0.1 2.16 1.16.1 n/a 1.16.1 1.16.0 2.59.0 10.0.1 2.16 1.16.0 n/a 1.16.0 1.15.1 2.47.0 10.0.0 2.15 1.15.0 n/a 1.15.1 1.15.0 2.47.0 10.0.0 2.15 1.15.0 n/a 1.15.0 1.14.0 2.47.0 10.0.0 2.13 1.14.0 n/a 1.14.0 1.13.0 2.40.0 6.0.0 2.12 1.13.1 n/a 1.13.0 1.12.0 2.40.0 6.0.0 2.11 1.12.0 n/a 1.12.0 1.11.0 2.40.0 6.0.0 1.15 / 2.10 1.11.0 n/a 1.11.0 1.10.0 2.40.0 6.0.0 1.15 / 2.9 1.10.0 n/a 1.10.1 1.9.0 2.38.0 5.0.0 1.15 / 2.9 1.9.0 n/a 1.9.0 1.8.0 2.38.0 5.0.0 1.15 / 2.8 1.8.0 n/a 1.8.0 1.7.0 2.36.0 5.0.0 1.15 / 2.8 1.7.0 n/a 1.7.0 1.6.0 2.35.0 5.0.0 1.15 / 2.7 1.6.0 n/a 1.6.0 1.5.0 2.34.0 2.0.0 1.15 / 2.7 1.5.0 n/a 1.5.0 1.4.0 2.32.0 2.0.0 1.15 / 2.6 1.4.0 n/a 1.4.0 1.3.0 2.32.0 2.0.0 1.15 / 2.6 1.2.0 n/a 1.3.0 1.2.0 2.31.0 2.0.0 1.15 / 2.5 1.2.0 n/a 1.2.0 1.1.1 2.29.0 2.0.0 1.15 / 2.5 1.1.0 n/a 1.1.1 1.1.0 2.29.0 2.0.0 1.15 / 2.5 1.1.0 n/a 1.1.0 1.0.0 2.29.0 2.0.0 1.15 / 2.5 1.0.0 n/a 1.0.0 0.30.0 2.28.0 2.0.0 1.15 / 2.4 0.30.0 n/a 0.30.0 0.29.0 2.28.0 2.0.0 1.15 / 2.4 0.29.0 n/a 0.29.0 0.28.0 2.28.0 2.0.0 1.15 / 2.4 0.28.0 n/a 0.28.1 0.27.0 2.27.0 2.0.0 1.15 / 2.4 0.27.0 n/a 0.27.0 0.26.1 2.28.0 0.17.0 1.15 / 2.3 0.26.0 0.26.0 0.26.0 0.26.0 2.25.0 0.17.0 1.15 / 2.3 0.26.0 0.26.0 0.26.0 0.25.0 2.25.0 0.17.0 1.15 / 2.3 0.25.0 0.25.0 0.25.0 0.24.1 2.24.0 0.17.0 1.15 / 2.3 0.24.0 0.24.1 0.24.1 0.24.0 2.23.0 0.17.0 1.15 / 2.3 0.24.0 0.24.0 0.24.0 0.23.1 2.24.0 0.17.0 1.15 / 2.3 0.23.0 0.23.0 0.23.0 0.23.0 2.23.0 0.17.0 1.15 / 2.3 0.23.0 0.23.0 0.23.0 0.22.2 2.20.0 0.16.0 1.15 / 2.2 0.22.0 0.22.0 0.22.1 0.22.1 2.20.0 0.16.0 1.15 / 2.2 0.22.0 0.22.0 0.22.1 0.22.0 2.20.0 0.16.0 1.15 / 2.2 0.22.0 0.22.0 0.22.0 0.21.5 2.17.0 0.15.0 1.15 / 2.1 0.21.0 0.21.1 0.21.3 0.21.4 2.17.0 0.15.0 1.15 / 2.1 0.21.0 0.21.1 0.21.3 0.21.2 2.17.0 0.15.0 1.15 / 2.1 0.21.0 0.21.0 0.21.0 0.21.1 2.17.0 0.15.0 1.15 / 2.1 0.21.0 0.21.0 0.21.0 0.21.0 2.17.0 0.15.0 1.15 / 2.1 0.21.0 0.21.0 0.21.0 0.15.0 2.16.0 0.14.0 1.15 / 2.0 0.15.0 0.15.0 0.15.0 0.14.1 2.14.0 0.14.0 1.14 0.14.0 0.14.0 n/a 0.14.0 2.14.0 0.14.0 1.14 0.14.0 0.14.0 n/a 0.13.1 2.11.0 n/a 1.13 0.12.1 0.13.0 n/a 0.13.0 2.11.0 n/a 1.13 0.12.1 0.13.0 n/a 0.12.0 2.10.0 n/a 1.12 0.12.1 0.12.0 n/a 0.11.0 2.8.0 n/a 1.11 0.9.0 0.11.0 n/a 0.9.0 2.6.0 n/a 1.9 n/a n/a n/a"},{"location":"install/#questions","title":"Questions","text":"<p>Please direct any questions about working with TF Data Validation to Stack Overflow using the tensorflow-data-validation tag.</p>"},{"location":"install/#links","title":"Links","text":"<ul> <li>TensorFlow Data Validation Getting Started Guide</li> <li>TensorFlow Data Validation Notebook</li> <li>TensorFlow Data Validation API Documentation</li> <li>TensorFlow Data Validation Blog Post</li> <li>TensorFlow Data Validation PyPI</li> <li>TensorFlow Data Validation Paper</li> <li>TensorFlow Data Validation Slides</li> </ul>"}]}